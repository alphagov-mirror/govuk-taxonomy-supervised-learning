{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional NN to classify govuk content to level2 taxons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on:\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do:\n",
    "- ~~Consider grouping very small classes (especially if too small for evaluation)~~\n",
    "- ~~Split data into training, validation and test to avoid overfitting validation data during hyperparamter searches & model architecture changes~~\n",
    "- ~~Try learning embeddings~~--\n",
    "- ~~Try changing pos_ratio~~\n",
    "- Try implementing class_weights during model fit (does this do the same as the weighted binary corss entropy?)\n",
    "- Work on tensorboard callbacks\n",
    "- ~~Create dictionary of class indices to taxon names for viewing results~~\n",
    "- ~~Check model architecture~~\n",
    "- ~~consider relationship of training error to validation error - overfitting/bias?~~\n",
    "- ~~train longer~~\n",
    "- Try differnet max_sequence_length\n",
    "- Check batch size is appropriate\n",
    "- Also think about:\n",
    "  - ~~regularization (e.g. dropout)~~ \n",
    "  - fine-tuning the Embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load requirements and data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: edit requirement.txt to include only these packages and do not include tensorflow because this conflicts with tf on AWS when using on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.utils import to_categorical, layer_utils, plot_model\n",
    "\n",
    "from keras.layers import (Embedding, Input, Dense, Dropout, \n",
    "                          Activation, Conv1D, MaxPooling1D, Flatten, concatenate, Reshape)\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.callbacks import TensorBoard, Callback, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score \n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import functools\n",
    "\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environmental vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATADIR=os.getenv('DATADIR')\n",
    "#DATADIR='/data' #this was put in for AWS run but doesn't work locally..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuition for POS_RATIO is that it penalises the prediction of zero for everything, which is attractive to the model because the multilabel y matrix is super sparse. \n",
    "\n",
    "Increasing POS_RATIO should penalise predicting zeros more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MAX_NB_WORDS\n",
    "MAX_SEQUENCE_LENGTH =1000\n",
    "EMBEDDING_DIM = 100 # keras embedding layer output_dim = Dimension of the dense embedding\n",
    "P_THRESHOLD = 0.5 #Threshold for probability of being assigned to class\n",
    "POS_RATIO = 0.5 #ratio of positive to negative for each class in weighted binary cross entropy loss function\n",
    "NUM_WORDS=20000 #keras tokenizer num_words: None or int. Maximum number of words to work with \n",
    "#(if set, tokenization will be restricted to the top num_words most common words in the dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data\n",
    "Content items tagged to level 2 taxons or lower in the topic taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labelled_level2 = pd.read_csv(os.path.join(DATADIR, 'labelled_level2.csv.gz'), dtype=object, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173560, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_level2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114048"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_level2['content_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DON'T Collapse taxons with insufficient support for predictions (will need to be manually tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#count the number of taxons per content item into new column\n",
    "#labelled_level2['num_content_per_taxon'] = labelled_level2.groupby([\"level2taxon\"])['level2taxon'].transform(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#COLLAPSE level2taxons with too few content items into \"toosmall\" category\n",
    "#labelled_level2.loc[labelled_level2['num_content_per_taxon'] < 10, 'level2taxon'] = 'TOO_SMALL'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean up any World taxons leftover despite dropping relevant doctypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#COLLAPSE World level2taxons\n",
    "labelled_level2.loc[labelled_level2['level1taxon'] == 'World', 'level2taxon'] = 'world_level1'\n",
    "\n",
    "#creating categorical variable for level2taxons from values\n",
    "labelled_level2['level2taxon'] = labelled_level2['level2taxon'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#count the number of content items per taxon into new column\n",
    "labelled_level2['num_content_per_taxon'] = labelled_level2.groupby([\"level2taxon\"])['level2taxon'].transform(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    173560.000000\n",
       "mean       4574.207145\n",
       "std        3682.635048\n",
       "min           1.000000\n",
       "25%        1500.000000\n",
       "50%        3780.000000\n",
       "75%        6156.000000\n",
       "max       11717.000000\n",
       "Name: num_content_per_taxon, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_level2['num_content_per_taxon'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11717"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of rows in biggest level2 taxon -this is the target size for all other level2 taxons in resampling\n",
    "max_content_freq = max(labelled_level2['num_content_per_taxon'])\n",
    "max_content_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173560, 24)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_level2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3927, 24)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_level2[(labelled_level2['document_type'] == 'world_news_story')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33214, 24)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_level2[(labelled_level2['document_type'] == 'news_story')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nonews = labelled_level2[(labelled_level2['document_type'] != 'news_story')]\n",
    "\n",
    "nonews = nonews[nonews['document_type'] != 'world_news_story']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136419, 24)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary mapping taxon codes to string labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'Administrative justice reform',\n",
       " 2: 'Adoption, fostering and surrogacy',\n",
       " 3: 'Afghanistan',\n",
       " 4: 'Armed Forces Covenant',\n",
       " 5: 'Armed forces',\n",
       " 6: 'Armed forces and Ministry of Defence reform',\n",
       " 7: 'Armed forces support for activities in the UK',\n",
       " 8: 'Arts and culture',\n",
       " 9: 'Assessing environmental impact',\n",
       " 10: 'Asylum',\n",
       " 11: 'Attorney General guidance to the legal profession',\n",
       " 12: 'Aviation',\n",
       " 13: 'Benefits entitlement',\n",
       " 14: 'Benefits for families',\n",
       " 15: 'Biodiversity and ecosystems',\n",
       " 16: 'Boating and inland waterways',\n",
       " 17: 'Brexit',\n",
       " 18: 'Brexit and the EU',\n",
       " 19: 'British citizenship ',\n",
       " 20: 'British nationals overseas',\n",
       " 21: 'Business and enterprise',\n",
       " 22: 'Business and the environment',\n",
       " 23: 'Business tax',\n",
       " 24: 'Byelaws',\n",
       " 25: 'Carers and disability benefits',\n",
       " 26: \"Carers' health\",\n",
       " 27: 'Certificates, register offices, changes of name or gender',\n",
       " 28: 'Charities, volunteering and honours',\n",
       " 29: 'Child Benefit',\n",
       " 30: 'Child maintenance reform',\n",
       " 31: 'Childcare and early years',\n",
       " 32: \"Children's health and welfare\",\n",
       " 33: 'Civil justice reform',\n",
       " 34: 'Civil service reform',\n",
       " 35: 'Climate change and energy',\n",
       " 36: 'Commercial fishing and fisheries',\n",
       " 37: 'Community and society',\n",
       " 38: 'Conflict in fragile states',\n",
       " 39: 'Constitutional affairs',\n",
       " 40: 'Consumer rights and issues',\n",
       " 41: 'Content and publishing',\n",
       " 42: 'Counter-terrorism',\n",
       " 43: 'Court claims, debt and bankruptcy',\n",
       " 44: 'Courts, sentencing and tribunals',\n",
       " 45: 'Crime prevention',\n",
       " 46: 'Criminal justice reform',\n",
       " 47: 'Criminal record disclosure',\n",
       " 48: 'Cyber security',\n",
       " 49: 'Dealing with HMRC',\n",
       " 50: 'Death and benefits',\n",
       " 51: 'Death and bereavement',\n",
       " 52: 'Deficit reduction',\n",
       " 53: 'Devolution',\n",
       " 54: 'Diplomats',\n",
       " 55: 'Disabled people',\n",
       " 56: 'Divorce, separation and legal issues',\n",
       " 57: 'Domestic violence',\n",
       " 58: 'Driving and road transport',\n",
       " 59: 'Education of disadvantaged children',\n",
       " 60: 'Emergency preparation, response and recovery',\n",
       " 61: 'Employing people',\n",
       " 62: 'End of life care',\n",
       " 63: 'Environmental permits',\n",
       " 64: 'Environmental quality',\n",
       " 65: 'Environmental risk management',\n",
       " 66: 'Equality, rights and citizenship',\n",
       " 67: 'European Union laws and regulation',\n",
       " 68: 'European funds',\n",
       " 69: 'European single market',\n",
       " 70: 'Expenses and employee benefits',\n",
       " 71: 'Family justice system',\n",
       " 72: 'Financial help if you have children',\n",
       " 73: 'Financial services',\n",
       " 74: 'Fire prevention and rescue',\n",
       " 75: 'Flooding and coastal change',\n",
       " 76: 'Food and farming',\n",
       " 77: 'Forced marriage',\n",
       " 78: 'Foreign affairs',\n",
       " 79: 'Freight and cargo',\n",
       " 80: 'Funding and finance for students',\n",
       " 81: 'Further and higher education, skills and vocational training',\n",
       " 82: 'Government efficiency, transparency and accountability',\n",
       " 83: 'Government graduate schemes',\n",
       " 84: 'Government spending',\n",
       " 85: 'HS2 and the environment',\n",
       " 86: 'Having a child, parenting and adoption',\n",
       " 87: 'Health and safety reform',\n",
       " 88: 'Health protection',\n",
       " 89: 'Heating and housing benefits',\n",
       " 90: 'Housing',\n",
       " 91: 'Housing planning and building',\n",
       " 92: 'Human rights internationally',\n",
       " 93: 'Immigration rules and enforcement',\n",
       " 94: 'Industrial strategy',\n",
       " 95: 'Inspections and performance of education providers',\n",
       " 96: 'International aid and development',\n",
       " 97: 'International defence commitments',\n",
       " 98: \"Jobseeker's Allowance and low income benefits\",\n",
       " 99: 'Justice system transparency',\n",
       " 100: 'Knife, gun and gang crime',\n",
       " 101: 'Labour market reform',\n",
       " 102: 'Land Registration Data ',\n",
       " 103: 'Land management',\n",
       " 104: 'Land registration',\n",
       " 105: 'Lasting power of attorney, being in care and your financial affairs',\n",
       " 106: 'Law and practice',\n",
       " 107: 'Legal aid',\n",
       " 108: 'Legal aid reform',\n",
       " 109: 'Legislative process',\n",
       " 110: 'Living abroad',\n",
       " 111: 'Living in the UK, government and democracy',\n",
       " 112: 'Local councils and services',\n",
       " 113: 'Local government',\n",
       " 114: 'Local government spending',\n",
       " 115: 'Local transport',\n",
       " 116: 'Localism',\n",
       " 117: 'Major project management',\n",
       " 118: 'Marine',\n",
       " 119: 'Maritime',\n",
       " 120: 'Marriage, civil partnership and divorce',\n",
       " 121: 'Media and communications',\n",
       " 122: 'Medical certification and advice',\n",
       " 123: 'Medicines, medical devices and blood regulation and safety',\n",
       " 124: 'Military awards and commemorations',\n",
       " 125: 'Military equipment, logistics and technology',\n",
       " 126: 'Military recruitment, training and operations',\n",
       " 127: 'Ministry of Defence estate',\n",
       " 128: 'Money laundering regulations',\n",
       " 129: 'National Health Service',\n",
       " 130: 'National events and ceremonies',\n",
       " 131: 'National security',\n",
       " 132: 'Northern Ireland',\n",
       " 133: 'Nuclear disarmament',\n",
       " 134: 'Oil and gas',\n",
       " 135: 'Passports',\n",
       " 136: 'Passports and travel documents for foreign nationals',\n",
       " 137: 'Payroll',\n",
       " 138: 'Peace and stability in the Middle East and North Africa',\n",
       " 139: 'Pensions and ageing society',\n",
       " 140: 'Permanent stay in the UK',\n",
       " 141: 'Personal tax',\n",
       " 142: 'Policing',\n",
       " 143: 'Population screening programmes',\n",
       " 144: 'Postal service reform',\n",
       " 145: 'Pregnancy and birth',\n",
       " 146: 'Prisons and probation',\n",
       " 147: 'Public health',\n",
       " 148: 'Public sector land use',\n",
       " 149: 'Public services',\n",
       " 150: 'Pupil wellbeing, behaviour and attendance',\n",
       " 151: 'Rail',\n",
       " 152: 'Regulation reform',\n",
       " 153: 'Reoffending and rehabilitation',\n",
       " 154: 'Reporting crimes and getting compensation',\n",
       " 155: 'Road infrastructure',\n",
       " 156: 'Running and managing a school',\n",
       " 157: 'Rural and countryside',\n",
       " 158: 'Safeguarding and social care for children',\n",
       " 159: 'School and academy financial management and assurance',\n",
       " 160: 'School and academy funding',\n",
       " 161: 'School curriculum',\n",
       " 162: 'Science and innovation',\n",
       " 163: 'Scotland',\n",
       " 164: 'Screening and quality assurance (all programmes)',\n",
       " 165: 'Secondments with government',\n",
       " 166: 'Self-employment',\n",
       " 167: 'Sentencing reform',\n",
       " 168: 'Social care',\n",
       " 169: 'Special educational needs and disability (SEND) and high needs',\n",
       " 170: 'Sports and leisure',\n",
       " 171: 'Starting and attending school',\n",
       " 172: 'Statutory rights',\n",
       " 173: 'Support services for military and defence personnel and their families',\n",
       " 174: 'Support services for veterans and their families',\n",
       " 175: 'Sustainable development',\n",
       " 176: 'Tax credits',\n",
       " 177: 'Tax evasion and avoidance',\n",
       " 178: 'Teaching and leadership',\n",
       " 179: 'The Commonwealth',\n",
       " 180: 'Tourism',\n",
       " 181: 'Trade and investment',\n",
       " 182: 'Transport accessibility and mobility',\n",
       " 183: 'Transport corporate and transparency',\n",
       " 184: 'Transport modelling and appraisal',\n",
       " 185: 'Transport planning',\n",
       " 186: 'Transport research and evaluation',\n",
       " 187: 'Transport security',\n",
       " 188: 'Transport statistics',\n",
       " 189: 'Travel abroad',\n",
       " 190: 'UK border control',\n",
       " 191: 'UK economy',\n",
       " 192: 'UK nuclear deterrent',\n",
       " 193: 'UK prosperity and security: Asia, Latin America and Africa',\n",
       " 194: 'Universal Credit',\n",
       " 195: 'Victims of crime',\n",
       " 196: 'Violence against women and girls',\n",
       " 197: 'Visas',\n",
       " 198: 'Voting',\n",
       " 199: 'Wales',\n",
       " 200: 'Waste and recycling',\n",
       " 201: 'Water industry',\n",
       " 202: 'Weapons proliferation',\n",
       " 203: 'What you can bring to the UK',\n",
       " 204: 'Wildlife and animal welfare',\n",
       " 205: 'Work and disabled people',\n",
       " 206: 'Working, jobs and pensions',\n",
       " 207: 'Young people and the law',\n",
       " 208: 'Your rights and the law',\n",
       " 209: 'Youth employment and social issues',\n",
       " 210: 'world_level1'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the category numeric values (codes) and avoid zero-indexing\n",
    "labels = nonews['level2taxon'].cat.codes + 1\n",
    "\n",
    "#create dictionary of taxon category code to string label for use in model evaluation\n",
    "labels_index = dict(zip((labels), nonews['level2taxon']))\n",
    "labels_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210\n"
     ]
    }
   ],
   "source": [
    "print(len(labels_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create target/Y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: when using the categorical_crossentropy loss, your targets should be in categorical format (e.g. if you have 10 classes, the target for each sample should be a 10-dimensional vector that is all-zeros expect for a 1 at the index corresponding to the class of the sample)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In multilabel learning, the joint set of binary classification tasks is expressed with label binary indicator array: each sample is one row of a 2d array of shape (n_samples, n_classes) with binary values:  \n",
    "the one, i.e. the non zero elements, corresponds to the subset of labels.  \n",
    "An array such as np.array([[1, 0, 0], [0, 1, 1], [0, 0, 0]]) represents label 0 in the first sample, labels 1 and 2 in the second sample, and no labels in the third sample.  \n",
    "Producing multilabel data as a list of sets of labels may be more intuitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  First reshape wide to get columns for each level2taxon and row number = number unique urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique level2taxons: 210\n"
     ]
    }
   ],
   "source": [
    "#get a smaller copy of data for pivoting ease (think you can work from full data actually and other cols get droopedauto)\n",
    "\n",
    "level2_reduced = nonews[['content_id', \n",
    "                         'level2taxon', \n",
    "                         'combined_text', \n",
    "                         'title', \n",
    "                         'description',\n",
    "                         'document_type', \n",
    "                            'first_published_at', \n",
    "                            'publishing_app', \n",
    "                            'primary_publishing_organisation']].copy()\n",
    "\n",
    "#how many level2taxons are there?\n",
    "print('Number of unique level2taxons: {}'.format(level2_reduced.level2taxon.nunique()))\n",
    "\n",
    "#count the number of taxons per content item into new column\n",
    "level2_reduced['num_taxon_per_content'] = level2_reduced.groupby([\"content_id\"])['content_id'].transform(\"count\")\n",
    "\n",
    "#Add 1 because of zero-indexing to get 1-number of level2taxons as numerical targets\n",
    "level2_reduced['level2taxon_code'] = level2_reduced.level2taxon.astype('category').cat.codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique level2taxons: 210\n"
     ]
    }
   ],
   "source": [
    "#how many level2taxons are there?\n",
    "print('Number of unique level2taxons: {}'.format(labelled_level2.level2taxon.nunique()))\n",
    "\n",
    "#count the number of taxons per content item into new column\n",
    "labelled_level2['num_taxon_per_content'] = labelled_level2.groupby([\"content_id\"])['content_id'].transform(\"count\")\n",
    "\n",
    "#Add 1 because of zero-indexing to get 1-number of level2taxons as numerical targets\n",
    "labelled_level2['level2taxon_code'] = labelled_level2.level2taxon.astype('category').cat.codes + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level2reduced shape: (136419, 11)\n",
      "pivot table shape (no duplicates): (92338, 210) \n"
     ]
    }
   ],
   "source": [
    "#reshape to wide per taxon and keep the combined text so indexing is consistent when splitting X from Y\n",
    "\n",
    "multilabel = (level2_reduced.pivot_table(index=['content_id', \n",
    "                                                'combined_text', \n",
    "                                                'title', \n",
    "                                                'description' \n",
    "                                                ] , columns='level2taxon_code', values='num_taxon_per_content'))\n",
    "print('level2reduced shape: {}'.format(level2_reduced.shape))\n",
    "print('pivot table shape (no duplicates): {} '.format(multilabel.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
       "            ...\n",
       "            201, 202, 203, 204, 205, 206, 207, 208, 209, 210],\n",
       "           dtype='int64', name='level2taxon_code', length=210)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10',\n",
       "       ...\n",
       "       '201', '202', '203', '204', '205', '206', '207', '208', '209', '210'],\n",
       "      dtype='object', name='level2taxon_code', length=210)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel.columns.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#THIS IS WHY INDEXING IS NOT ZERO-BASED\n",
    "#convert the number_of_taxons_per_content values to 1, meaning there was an entry for this taxon and this content_id, 0 otherwise\n",
    "binary_multilabel = multilabel.notnull().astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsample minority classes to address imbalance leading to ~2, 465, 570 rows of data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92338,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_multilabel[binary_multilabel.columns[1]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_multilabel.columns = binary_multilabel.columns.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10',\n",
       "       ...\n",
       "       '201', '202', '203', '204', '205', '206', '207', '208', '209', '210'],\n",
       "      dtype='object', name='level2taxon_code', length=210)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_multilabel.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "del binary_multilabel.columns.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenList(['content_id', 'combined_text', 'title', 'description'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_multilabel.index.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(92838, 210)\n",
      "2\n",
      "(93338, 210)\n",
      "3\n",
      "(93838, 210)\n",
      "4\n",
      "(94338, 210)\n",
      "5\n",
      "(94838, 210)\n",
      "6\n",
      "(95338, 210)\n",
      "7\n",
      "(95838, 210)\n",
      "8\n",
      "(96338, 210)\n",
      "9\n",
      "(96838, 210)\n",
      "10\n",
      "(97338, 210)\n",
      "11\n",
      "(97838, 210)\n",
      "12\n",
      "(98338, 210)\n",
      "13\n",
      "(98838, 210)\n",
      "14\n",
      "(99338, 210)\n",
      "15\n",
      "(99838, 210)\n",
      "16\n",
      "(100338, 210)\n",
      "17\n",
      "(100838, 210)\n",
      "18\n",
      "(101338, 210)\n",
      "19\n",
      "(101838, 210)\n",
      "20\n",
      "(102338, 210)\n",
      "21\n",
      "(102838, 210)\n",
      "22\n",
      "(103338, 210)\n",
      "23\n",
      "(103838, 210)\n",
      "24\n",
      "(104338, 210)\n",
      "25\n",
      "(104838, 210)\n",
      "26\n",
      "(105338, 210)\n",
      "27\n",
      "(105838, 210)\n",
      "28\n",
      "(106338, 210)\n",
      "29\n",
      "(106838, 210)\n",
      "30\n",
      "(107338, 210)\n",
      "31\n",
      "(107838, 210)\n",
      "32\n",
      "(108338, 210)\n",
      "33\n",
      "(108838, 210)\n",
      "34\n",
      "(109338, 210)\n",
      "35\n",
      "(109838, 210)\n",
      "36\n",
      "(110338, 210)\n",
      "37\n",
      "(110838, 210)\n",
      "38\n",
      "(111338, 210)\n",
      "39\n",
      "(111838, 210)\n",
      "40\n",
      "(112338, 210)\n",
      "41\n",
      "(112838, 210)\n",
      "42\n",
      "(113338, 210)\n",
      "43\n",
      "(113838, 210)\n",
      "44\n",
      "(114338, 210)\n",
      "45\n",
      "(114838, 210)\n",
      "46\n",
      "(115338, 210)\n",
      "47\n",
      "(115838, 210)\n",
      "48\n",
      "(116338, 210)\n",
      "49\n",
      "(116838, 210)\n",
      "50\n",
      "(117338, 210)\n",
      "51\n",
      "(117838, 210)\n",
      "52\n",
      "(118338, 210)\n",
      "53\n",
      "(118838, 210)\n",
      "54\n",
      "(119338, 210)\n",
      "55\n",
      "(119838, 210)\n",
      "56\n",
      "(120338, 210)\n",
      "57\n",
      "(120838, 210)\n",
      "58\n",
      "(121338, 210)\n",
      "59\n",
      "(121838, 210)\n",
      "60\n",
      "(122338, 210)\n",
      "61\n",
      "(122838, 210)\n",
      "62\n",
      "(123338, 210)\n",
      "63\n",
      "(123838, 210)\n",
      "64\n",
      "(124338, 210)\n",
      "65\n",
      "(124838, 210)\n",
      "66\n",
      "(125338, 210)\n",
      "67\n",
      "(125838, 210)\n",
      "68\n",
      "(126338, 210)\n",
      "69\n",
      "(126838, 210)\n",
      "70\n",
      "(127338, 210)\n",
      "71\n",
      "(127838, 210)\n",
      "72\n",
      "(128338, 210)\n",
      "73\n",
      "(128838, 210)\n",
      "74\n",
      "(129338, 210)\n",
      "75\n",
      "(129838, 210)\n",
      "76\n",
      "(130338, 210)\n",
      "77\n",
      "(130838, 210)\n",
      "78\n",
      "(131338, 210)\n",
      "79\n",
      "(131838, 210)\n",
      "80\n",
      "(132338, 210)\n",
      "81\n",
      "(132838, 210)\n",
      "82\n",
      "(133338, 210)\n",
      "83\n",
      "(133838, 210)\n",
      "84\n",
      "(134338, 210)\n",
      "85\n",
      "(134838, 210)\n",
      "86\n",
      "(135338, 210)\n",
      "87\n",
      "(135838, 210)\n",
      "88\n",
      "(136338, 210)\n",
      "89\n",
      "(136838, 210)\n",
      "90\n",
      "(137338, 210)\n",
      "91\n",
      "(137838, 210)\n",
      "92\n",
      "(138338, 210)\n",
      "93\n",
      "(138838, 210)\n",
      "94\n",
      "(139338, 210)\n",
      "95\n",
      "(139838, 210)\n",
      "96\n",
      "(140338, 210)\n",
      "97\n",
      "(140838, 210)\n",
      "98\n",
      "(141338, 210)\n",
      "99\n",
      "(141838, 210)\n",
      "100\n",
      "(142338, 210)\n",
      "101\n",
      "(142838, 210)\n",
      "102\n",
      "(143338, 210)\n",
      "103\n",
      "(143838, 210)\n",
      "104\n",
      "(144338, 210)\n",
      "105\n",
      "(144838, 210)\n",
      "106\n",
      "(145338, 210)\n",
      "107\n",
      "(145838, 210)\n",
      "108\n",
      "(146338, 210)\n",
      "109\n",
      "(146838, 210)\n",
      "110\n",
      "(147338, 210)\n",
      "111\n",
      "(147838, 210)\n",
      "112\n",
      "(148338, 210)\n",
      "113\n",
      "(148838, 210)\n",
      "114\n",
      "(149338, 210)\n",
      "115\n",
      "(149838, 210)\n",
      "116\n",
      "(150338, 210)\n",
      "117\n",
      "(150838, 210)\n",
      "118\n",
      "(151338, 210)\n",
      "119\n",
      "(151838, 210)\n",
      "120\n",
      "(152338, 210)\n",
      "121\n",
      "(152838, 210)\n",
      "122\n",
      "(153338, 210)\n",
      "123\n",
      "(153838, 210)\n",
      "124\n",
      "(154338, 210)\n",
      "125\n",
      "(154838, 210)\n",
      "126\n",
      "(155338, 210)\n",
      "127\n",
      "(155838, 210)\n",
      "128\n",
      "(156338, 210)\n",
      "129\n",
      "(156838, 210)\n",
      "130\n",
      "(157338, 210)\n",
      "131\n",
      "(157838, 210)\n",
      "132\n",
      "(158338, 210)\n",
      "133\n",
      "(158838, 210)\n",
      "134\n",
      "(159338, 210)\n",
      "135\n",
      "(159838, 210)\n",
      "136\n",
      "(160338, 210)\n",
      "137\n",
      "(160838, 210)\n",
      "138\n",
      "(161338, 210)\n",
      "139\n",
      "(161838, 210)\n",
      "140\n",
      "(162338, 210)\n",
      "141\n",
      "(162838, 210)\n",
      "142\n",
      "(163338, 210)\n",
      "143\n",
      "(163838, 210)\n",
      "144\n",
      "(164338, 210)\n",
      "145\n",
      "(164838, 210)\n",
      "146\n",
      "(165338, 210)\n",
      "147\n",
      "(165838, 210)\n",
      "148\n",
      "(166338, 210)\n",
      "149\n",
      "(166838, 210)\n",
      "150\n",
      "(167338, 210)\n",
      "151\n",
      "(167838, 210)\n",
      "152\n",
      "(168338, 210)\n",
      "153\n",
      "(168838, 210)\n",
      "154\n",
      "(169338, 210)\n",
      "155\n",
      "(169838, 210)\n",
      "156\n",
      "(170338, 210)\n",
      "157\n",
      "(170838, 210)\n",
      "158\n",
      "(171338, 210)\n",
      "159\n",
      "(171838, 210)\n",
      "160\n",
      "(172338, 210)\n",
      "161\n",
      "(172838, 210)\n",
      "162\n",
      "(173338, 210)\n",
      "163\n",
      "(173838, 210)\n",
      "164\n",
      "(174338, 210)\n",
      "165\n",
      "(174838, 210)\n",
      "166\n",
      "(175338, 210)\n",
      "167\n",
      "(175838, 210)\n",
      "168\n",
      "(176338, 210)\n",
      "169\n",
      "(176838, 210)\n",
      "170\n",
      "(177338, 210)\n",
      "171\n",
      "(177838, 210)\n",
      "172\n",
      "(178338, 210)\n",
      "173\n",
      "(178838, 210)\n",
      "174\n",
      "(179338, 210)\n",
      "175\n",
      "(179838, 210)\n",
      "176\n",
      "(180338, 210)\n",
      "177\n",
      "(180838, 210)\n",
      "178\n",
      "(181338, 210)\n",
      "179\n",
      "(181838, 210)\n",
      "180\n",
      "(182338, 210)\n",
      "181\n",
      "(182838, 210)\n",
      "182\n",
      "(183338, 210)\n",
      "183\n",
      "(183838, 210)\n",
      "184\n",
      "(184338, 210)\n",
      "185\n",
      "(184838, 210)\n",
      "186\n",
      "(185338, 210)\n",
      "187\n",
      "(185838, 210)\n",
      "188\n",
      "(186338, 210)\n",
      "189\n",
      "(186838, 210)\n",
      "190\n",
      "(187338, 210)\n",
      "191\n",
      "(187838, 210)\n",
      "192\n",
      "(188338, 210)\n",
      "193\n",
      "(188838, 210)\n",
      "194\n",
      "(189338, 210)\n",
      "195\n",
      "(189838, 210)\n",
      "196\n",
      "(190338, 210)\n",
      "197\n",
      "(190838, 210)\n",
      "198\n",
      "(191338, 210)\n",
      "199\n",
      "(191838, 210)\n",
      "200\n",
      "(192338, 210)\n",
      "201\n",
      "(192838, 210)\n",
      "202\n",
      "(193338, 210)\n",
      "203\n",
      "(193838, 210)\n",
      "204\n",
      "(194338, 210)\n",
      "205\n",
      "(194838, 210)\n",
      "206\n",
      "(195338, 210)\n",
      "207\n",
      "(195838, 210)\n",
      "208\n",
      "(196338, 210)\n",
      "209\n",
      "(196838, 210)\n",
      "210\n",
      "(197338, 210)\n"
     ]
    }
   ],
   "source": [
    "#TAKES FOREVER TO RUN!\n",
    "\n",
    "from sklearn.utils import resample\n",
    "balanced_df = binary_multilabel\n",
    "for taxon in range(1, binary_multilabel.shape[1] +1):\n",
    "    taxon = str(taxon)\n",
    "    print(taxon)\n",
    "    # Separate majority and minority classes\n",
    "    df_minority = binary_multilabel[binary_multilabel[taxon]==1]\n",
    " \n",
    "    # Upsample minority class\n",
    "    df_minority_upsampled = resample(df_minority, \n",
    "                                         replace=True,     # sample with replacement\n",
    "                                         n_samples=(500),    # to match majority class, switch to max_content_freq if works\n",
    "                                         random_state=123) # reproducible results\n",
    "    \n",
    "    # Combine majority class with upsampled minority class\n",
    "    balanced_df = pd.concat([balanced_df, df_minority_upsampled])\n",
    " \n",
    "    # Display new shape\n",
    "    print(balanced_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "balanced_df.to_csv(os.path.join(DATADIR, 'balanced_level2_500.csv.gz'), compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "balanced_df = pd.read_csv(os.path.join(DATADIR, 'balanced_level2_500.csv.gz'), dtype=object, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197338, 214)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y multilabel array before train/val/test split:(197338, 214)\n"
     ]
    }
   ],
   "source": [
    "#will convert columns to an array of shape\n",
    "print('Shape of Y multilabel array before train/val/test split:{}'.format(balanced_df[list(balanced_df.columns)].values.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['content_id', 'combined_text', 'title', 'description', '1', '2', '3',\n",
       "       '4', '5', '6',\n",
       "       ...\n",
       "       '201', '202', '203', '204', '205', '206', '207', '208', '209', '210'],\n",
       "      dtype='object', length=214)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after saving out and reading in the indexes have been converted to columns\n",
    "balanced_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont' overwirte blanced_df as it take sages to read in\n",
    "balanced_df_taxons = balanced_df.iloc[: ,  4:215]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df_taxons.columns = balanced_df_taxons.columns.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df_taxons = balanced_df_taxons.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example row of multilabel array [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#convert columns to an array. Each row represents a content item, each column an individual taxon\n",
    "binary_multilabel = balanced_df_taxons[list(balanced_df_taxons.columns)].values\n",
    "print('Example row of multilabel array {}'.format(binary_multilabel[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(binary_multilabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format metadata/X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114048"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# THESE DICTS NEED TO BE CREATED IN ALL DATA, OR DOC TYPES NOT PRESENT IN TRAINING MUST BE DELETED FROM NEW\n",
    "#create dictionary of document type to content_id\n",
    "doctype_dict = dict(zip(labelled_level2['content_id'], labelled_level2['document_type']))\n",
    "frstpub_dict = dict(zip(labelled_level2['content_id'], labelled_level2['first_published_at']))\n",
    "pubapp_dict = dict(zip(labelled_level2['content_id'], labelled_level2['publishing_app']))\n",
    "puborg_dict = dict(zip(labelled_level2['content_id'], labelled_level2['primary_publishing_organisation']))\n",
    "len(doctype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None]\n",
      "Index(['content_id', 'combined_text', 'title', 'description', '1', '2', '3',\n",
      "       '4', '5', '6',\n",
      "       ...\n",
      "       '201', '202', '203', '204', '205', '206', '207', '208', '209', '210'],\n",
      "      dtype='object', length=214)\n"
     ]
    }
   ],
   "source": [
    "#the pivot table has two indices\n",
    "print(balanced_df.index.names)\n",
    "print(balanced_df.columns)\n",
    "#print(multilabel.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#extract content_id index to df\n",
    "meta1 = pd.DataFrame(balanced_df['content_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00029fa4-9b60-4285-898c-85ae8a6367f5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00037b70-5b08-44c2-bf0a-fa8eb636a60b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00037ee5-7b5e-452d-a233-af2c134f5bce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004c63d-ae16-432a-bb35-c0f949b1e27c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005ac76-50fe-42f1-8168-8b6fc046e40f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             content_id\n",
       "0  00029fa4-9b60-4285-898c-85ae8a6367f5\n",
       "1  00037b70-5b08-44c2-bf0a-fa8eb636a60b\n",
       "2  00037ee5-7b5e-452d-a233-af2c134f5bce\n",
       "3  0004c63d-ae16-432a-bb35-c0f949b1e27c\n",
       "4  0005ac76-50fe-42f1-8168-8b6fc046e40f"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>doctype</th>\n",
       "      <th>first_published_at</th>\n",
       "      <th>pub_app</th>\n",
       "      <th>prim_pub_org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00029fa4-9b60-4285-898c-85ae8a6367f5</td>\n",
       "      <td>document_collection</td>\n",
       "      <td>2017-01-11T10:18:00.000+00:00</td>\n",
       "      <td>whitehall</td>\n",
       "      <td>{'title': 'Crown Commercial Service'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00037b70-5b08-44c2-bf0a-fa8eb636a60b</td>\n",
       "      <td>promotional</td>\n",
       "      <td>2015-05-11T10:41:00.000+00:00</td>\n",
       "      <td>whitehall</td>\n",
       "      <td>{'title': 'Department for International Trade'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00037ee5-7b5e-452d-a233-af2c134f5bce</td>\n",
       "      <td>official_statistics</td>\n",
       "      <td>2016-11-24T09:30:13.000+00:00</td>\n",
       "      <td>whitehall</td>\n",
       "      <td>{'title': 'Department for Communities (Norther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004c63d-ae16-432a-bb35-c0f949b1e27c</td>\n",
       "      <td>official_statistics</td>\n",
       "      <td>2016-10-20T08:30:09.000+00:00</td>\n",
       "      <td>whitehall</td>\n",
       "      <td>{'title': 'Welsh Government'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005ac76-50fe-42f1-8168-8b6fc046e40f</td>\n",
       "      <td>guidance</td>\n",
       "      <td>2017-08-02T17:29:00.000+00:00</td>\n",
       "      <td>whitehall</td>\n",
       "      <td>{'title': 'Department for Communities and Loca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             content_id              doctype  \\\n",
       "0  00029fa4-9b60-4285-898c-85ae8a6367f5  document_collection   \n",
       "1  00037b70-5b08-44c2-bf0a-fa8eb636a60b          promotional   \n",
       "2  00037ee5-7b5e-452d-a233-af2c134f5bce  official_statistics   \n",
       "3  0004c63d-ae16-432a-bb35-c0f949b1e27c  official_statistics   \n",
       "4  0005ac76-50fe-42f1-8168-8b6fc046e40f             guidance   \n",
       "\n",
       "              first_published_at    pub_app  \\\n",
       "0  2017-01-11T10:18:00.000+00:00  whitehall   \n",
       "1  2015-05-11T10:41:00.000+00:00  whitehall   \n",
       "2  2016-11-24T09:30:13.000+00:00  whitehall   \n",
       "3  2016-10-20T08:30:09.000+00:00  whitehall   \n",
       "4  2017-08-02T17:29:00.000+00:00  whitehall   \n",
       "\n",
       "                                        prim_pub_org  \n",
       "0              {'title': 'Crown Commercial Service'}  \n",
       "1    {'title': 'Department for International Trade'}  \n",
       "2  {'title': 'Department for Communities (Norther...  \n",
       "3                      {'title': 'Welsh Government'}  \n",
       "4  {'title': 'Department for Communities and Loca...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply meta data to content\n",
    "meta1['doctype'] = meta1['content_id'].map(doctype_dict).copy()\n",
    "meta1['first_published_at'] = meta1['content_id'].map(frstpub_dict).copy()\n",
    "meta1['pub_app'] = meta1['content_id'].map(pubapp_dict).copy()\n",
    "meta1['prim_pub_org'] = meta1['content_id'].map(puborg_dict).copy()\n",
    "\n",
    "meta1 = meta1.replace(np.nan, '', regex=True) #conver nans to empty strings for labelencoder types\n",
    "meta1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#encode strings as integers\n",
    "#doctype\n",
    "doctype_encoder = LabelEncoder()\n",
    "meta1['doctype_cat'] = doctype_encoder.fit_transform(meta1['doctype']) #fit the label encoder on all data then transform on individual data sets\n",
    "\n",
    "# print(len(meta1['doctype_cat'].unique()))\n",
    "# print(meta1['doctype_cat'].unique())\n",
    "\n",
    "# primary publishing org\n",
    "pub_org_encoder = LabelEncoder()\n",
    "meta1['prim_pub_org_cat'] = doctype_encoder.fit_transform(meta1['prim_pub_org']) \n",
    "\n",
    "# print(len(meta1['prim_pub_org_cat'].unique()))\n",
    "# print(meta1['prim_pub_org_cat'].unique())\n",
    "\n",
    "#publishing application\n",
    "\n",
    "pub_app_encoder = LabelEncoder()\n",
    "meta1['pub_app_cat'] = doctype_encoder.fit_transform(meta1['pub_app'])\n",
    "\n",
    "# print(len(meta1['pub_app_cat'].unique()))\n",
    "# print(meta1['pub_app_cat'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(197338, 56)\n",
      "(197338, 366)\n",
      "(197338, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot encode integers\n",
    "encoded_doctype = to_categorical(meta1['doctype_cat'])\n",
    "print(encoded_doctype.shape)\n",
    "\n",
    "encoded_prim_pub_org = to_categorical(meta1['prim_pub_org_cat'])\n",
    "print(encoded_prim_pub_org.shape)\n",
    "\n",
    "encoded_pub_app = to_categorical(meta1['pub_app_cat'])\n",
    "print(encoded_pub_app.shape)\n",
    "type(encoded_pub_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(197338,)\n",
      "datetime64[ns]\n",
      "0\n",
      "(197338, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta1['first_published_at'] = pd.to_datetime(meta1['first_published_at']) \n",
    "\n",
    "# print(meta['first_published_at'][0].Timestamp())\n",
    "# for index, row in meta.iterrows():\n",
    "#     row['first_published_at_ts'] = row['first_published_at'].timestamp()\n",
    "#     print(row['first_published_at_ts'])\n",
    "\n",
    "print(meta1['first_published_at'].shape)\n",
    "\n",
    "first_published = np.array(meta1['first_published_at']).reshape(meta1['first_published_at'].shape[0], 1).copy()\n",
    "\n",
    "print(first_published.dtype)\n",
    "print(np.argmax(first_published.argmax))\n",
    "#scale first published at to 0 and 1\n",
    "print(first_published.shape)\n",
    "type(first_published)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(197338, 431)\n",
      "431\n",
      "(197338, 431)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "meta = np.concatenate((encoded_doctype, \n",
    "                           encoded_prim_pub_org, \n",
    "                           encoded_pub_app), #error when adding date...\n",
    "                          axis=1)\n",
    "\n",
    "print(meta.shape)\n",
    "nb_metavars = meta.shape[1]\n",
    "print(nb_metavars)\n",
    "print(meta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create combined_text data/X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "format our text samples and labels into tensors that can be fed into a neural network. To do this, we will rely on Keras utilities keras.preprocessing.text.Tokenizer and keras.preprocessing.sequence.pad_sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197338,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract combined text index to array\n",
    "texts = balanced_df['combined_text']\n",
    "texts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess title data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197338,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = balanced_df['title']\n",
    "titles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess description data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197338,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descs = balanced_df['description']\n",
    "descs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize combined text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer = Class for vectorizing texts, or/and turning texts into sequences (=list of word indexes, where the word of rank i in the dataset (starting at 1) has index i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 171379 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# Bag of words method\n",
    "tokenizer = Tokenizer(num_words=NUM_WORDS) #num_words: None or int. Maximum number of words to work with \n",
    "# (if set, tokenization will be restricted to the top num_words most common words in the dataset).\n",
    "\n",
    "# apply tokenizer to our text data\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# list of word indexes, where the word of rank i in the dataset (starting at 1) has index i\n",
    "sequences = tokenizer.texts_to_sequences(texts) #yield one sequence per input text\n",
    "\n",
    "# dictionary mapping words (str) to their rank/index (int).\n",
    "word_index = tokenizer.word_index  # Only set after fit_on_texts was called.\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen= MAX_SEQUENCE_LENGTH) #MAX_SEQUENCE_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File(\"tokenized_combined_text.hdf5\", \"w\")\n",
    "h5f.create_dataset('tokenized_combined_text', data=data)\n",
    "h5f.close()\n",
    "# data = pd.read_pickle(os.path.join(DATADIR, 'tokenized_combined_text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (197338, 210)\n",
      "Shape of data tensor: (197338, 1000)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of label tensor:', binary_multilabel.shape)\n",
    "print('Shape of data tensor:', data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize title text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bag of words method\n",
    "tokenizer_tit = Tokenizer(num_words=10000) #num_words: None or int. Maximum number of words to work with \n",
    "# (if set, tokenization will be restricted to the top num_words most common words in the dataset).\n",
    "\n",
    "# apply tokenizer to our text data\n",
    "tokenizer_tit.fit_on_texts(titles)\n",
    "\n",
    "# list of word indexes, where the word of rank i in the dataset (starting at 1) has index i\n",
    "sequences_tit = tokenizer_tit.texts_to_sequences(titles) #yield one sequence per input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "onehot_tit = tokenizer_tit.sequences_to_matrix(sequences_tit) #yield one sequence per input text\n",
    "\n",
    "# dictionary mapping words (str) to their rank/index (int).\n",
    "word_index_tit = tokenizer_tit.word_index  # Only set after fit_on_texts was called.\n",
    "\n",
    "#NOTE THERE ARE LOTS OF NUMBERS IN HERE THAT SHOULD BE STRIPPED?\n",
    "\n",
    "# print('Found %s unique tokens.' % len(word_index_tit))\n",
    "\n",
    "# title_data = pad_sequences(sequences_tit, maxlen= 50) #mean/median=8 max = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197338, 10000)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_tit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 47981),\n",
       " ('to', 39568),\n",
       " ('of', 37421),\n",
       " ('the', 34535),\n",
       " ('for', 31460),\n",
       " ('in', 19519),\n",
       " ('a', 14681),\n",
       " ('on', 12884),\n",
       " ('uk', 10669),\n",
       " ('2015', 9555),\n",
       " ('2014', 8035),\n",
       " ('2016', 7847),\n",
       " ('report', 7029),\n",
       " ('government', 6942),\n",
       " ('2017', 5636),\n",
       " ('2013', 5538),\n",
       " ('guidance', 5005),\n",
       " ('new', 4795),\n",
       " ('statistics', 4755),\n",
       " ('tax', 4738),\n",
       " ('data', 4513),\n",
       " ('review', 4470),\n",
       " ('with', 4424),\n",
       " ('from', 4134),\n",
       " ('or', 4110),\n",
       " ('england', 4087),\n",
       " ('local', 4002),\n",
       " ('at', 3968),\n",
       " ('your', 3947),\n",
       " ('service', 3867),\n",
       " ('national', 3795),\n",
       " ('information', 3641),\n",
       " ('by', 3565),\n",
       " ('health', 3403),\n",
       " ('child', 3336),\n",
       " ('support', 3276),\n",
       " ('2012', 3265),\n",
       " ('business', 3218),\n",
       " ('statement', 3189),\n",
       " ('scheme', 3173),\n",
       " ('assessment', 3049),\n",
       " ('2010', 2965),\n",
       " ('services', 2924),\n",
       " ('an', 2902),\n",
       " ('march', 2882),\n",
       " ('how', 2878),\n",
       " ('land', 2827),\n",
       " ('2011', 2819),\n",
       " ('public', 2795),\n",
       " ('apply', 2790),\n",
       " ('speech', 2703),\n",
       " ('school', 2656),\n",
       " ('notice', 2500),\n",
       " ('office', 2489),\n",
       " ('secretary', 2484),\n",
       " ('programme', 2470),\n",
       " ('june', 2455),\n",
       " ('foreign', 2442),\n",
       " ('response', 2432),\n",
       " ('management', 2429),\n",
       " ('july', 2423),\n",
       " ('policy', 2420),\n",
       " ('april', 2378),\n",
       " ('september', 2338),\n",
       " ('press', 2313),\n",
       " ('care', 2279),\n",
       " ('1', 2273),\n",
       " ('council', 2264),\n",
       " ('security', 2243),\n",
       " ('january', 2229),\n",
       " ('guide', 2188),\n",
       " ('british', 2187),\n",
       " ('minister', 2124),\n",
       " ('as', 2122),\n",
       " ('wales', 2121),\n",
       " ('act', 2111),\n",
       " ('if', 2096),\n",
       " ('application', 2067),\n",
       " ('october', 2039),\n",
       " ('fund', 2027),\n",
       " ('funding', 2027),\n",
       " ('annual', 2027),\n",
       " ('december', 2006),\n",
       " ('environmental', 1993),\n",
       " ('help', 1956),\n",
       " ('work', 1945),\n",
       " ('plan', 1935),\n",
       " ('impact', 1929),\n",
       " ('education', 1927),\n",
       " ('energy', 1905),\n",
       " ('register', 1889),\n",
       " ('–', 1881),\n",
       " ('over', 1875),\n",
       " ('regulations', 1857),\n",
       " ('you', 1857),\n",
       " ('children', 1853),\n",
       " ('pension', 1842),\n",
       " ('civil', 1838),\n",
       " ('get', 1838),\n",
       " ('financial', 1833),\n",
       " ('transport', 1822),\n",
       " ('schools', 1821),\n",
       " ('form', 1817),\n",
       " ('conference', 1805),\n",
       " ('social', 1794),\n",
       " ('eu', 1790),\n",
       " ('survey', 1776),\n",
       " ('screening', 1760),\n",
       " ('forces', 1758),\n",
       " ('risk', 1733),\n",
       " ('rights', 1720),\n",
       " ('briefing', 1711),\n",
       " ('release', 1709),\n",
       " ('foi', 1705),\n",
       " ('reform', 1704),\n",
       " ('nhs', 1702),\n",
       " ('strategy', 1693),\n",
       " ('northern', 1692),\n",
       " ('year', 1656),\n",
       " ('consultation', 1650),\n",
       " ('future', 1642),\n",
       " ('2', 1633),\n",
       " ('trade', 1608),\n",
       " ('ireland', 1603),\n",
       " ('hs2', 1599),\n",
       " ('company', 1568),\n",
       " ('justice', 1551),\n",
       " ('international', 1546),\n",
       " ('safety', 1531),\n",
       " ('violence', 1530),\n",
       " ('defence', 1526),\n",
       " ('research', 1521),\n",
       " ('people', 1502),\n",
       " ('million', 1491),\n",
       " ('pay', 1486),\n",
       " ('update', 1473),\n",
       " ('change', 1456),\n",
       " ('special', 1440),\n",
       " ('non', 1434),\n",
       " ('bill', 1415),\n",
       " ('pm', 1409),\n",
       " ('quarterly', 1395),\n",
       " ('decision', 1390),\n",
       " ('community', 1390),\n",
       " ('letter', 1384),\n",
       " ('legal', 1384),\n",
       " ('list', 1381),\n",
       " ('road', 1373),\n",
       " ('authority', 1371),\n",
       " ('system', 1361),\n",
       " ('armed', 1355),\n",
       " ('credit', 1349),\n",
       " ('european', 1346),\n",
       " ('sector', 1337),\n",
       " ('into', 1328),\n",
       " ('practice', 1327),\n",
       " ('may', 1324),\n",
       " ('maintenance', 1319),\n",
       " ('000', 1318),\n",
       " ('benefits', 1312),\n",
       " ('use', 1306),\n",
       " ('prime', 1305),\n",
       " ('changes', 1287),\n",
       " ('development', 1281),\n",
       " ('about', 1274),\n",
       " ('investment', 1273),\n",
       " ('domestic', 1273),\n",
       " ('planning', 1268),\n",
       " ('flood', 1261),\n",
       " ('benefit', 1260),\n",
       " ('crime', 1257),\n",
       " ('housing', 1240),\n",
       " ('home', 1240),\n",
       " ('framework', 1237),\n",
       " ('action', 1218),\n",
       " ('economic', 1210),\n",
       " ('evaluation', 1188),\n",
       " ('november', 1185),\n",
       " ('aid', 1182),\n",
       " ('general', 1170),\n",
       " ('out', 1169),\n",
       " ('panel', 1165),\n",
       " ('reports', 1161),\n",
       " ('first', 1161),\n",
       " ('scotland', 1154),\n",
       " ('spend', 1145),\n",
       " ('appeal', 1140),\n",
       " ('teacher', 1138),\n",
       " ('access', 1133),\n",
       " ('16', 1132),\n",
       " ('schemes', 1128),\n",
       " ('water', 1124),\n",
       " ('nuclear', 1120),\n",
       " ('training', 1113),\n",
       " ('3', 1108),\n",
       " ('money', 1101),\n",
       " ('study', 1099),\n",
       " ('protection', 1094),\n",
       " ('spending', 1089),\n",
       " ('outcome', 1086),\n",
       " ('duty', 1078),\n",
       " ('applications', 1076),\n",
       " ('code', 1076),\n",
       " ('analysis', 1073),\n",
       " ('court', 1070),\n",
       " ('allowance', 1069),\n",
       " ('travel', 1064),\n",
       " ('committee', 1064),\n",
       " ('police', 1060),\n",
       " ('property', 1051),\n",
       " ('employment', 1049),\n",
       " ('state', 1049),\n",
       " ('north', 1043),\n",
       " ('agency', 1040),\n",
       " ('export', 1032),\n",
       " ('under', 1031),\n",
       " ('phase', 1031),\n",
       " ('ending', 1031),\n",
       " ('standards', 1029),\n",
       " ('quality', 1029),\n",
       " ('overseas', 1025),\n",
       " ('registration', 1025),\n",
       " ('customs', 1021),\n",
       " ('10', 1019),\n",
       " ('market', 1019),\n",
       " ('call', 1011),\n",
       " ('order', 1010),\n",
       " ('hm', 1009),\n",
       " ('high', 992),\n",
       " ('progress', 991),\n",
       " ('find', 991),\n",
       " ('rail', 987),\n",
       " ('draft', 986),\n",
       " ('dfid', 986),\n",
       " ('abroad', 985),\n",
       " ('tribunal', 983),\n",
       " ('agreement', 983),\n",
       " ('up', 982),\n",
       " ('index', 979),\n",
       " ('morning', 971),\n",
       " ('february', 969),\n",
       " ('businesses', 969),\n",
       " ('working', 964),\n",
       " ('evidence', 964),\n",
       " ('waste', 964),\n",
       " ('commission', 961),\n",
       " ('advice', 945),\n",
       " ('london', 942),\n",
       " ('passport', 942),\n",
       " ('life', 942),\n",
       " ('payment', 941),\n",
       " ('east', 940),\n",
       " ('britain', 939),\n",
       " ('environment', 931),\n",
       " ('technical', 931),\n",
       " ('claim', 928),\n",
       " ('part', 927),\n",
       " ('august', 926),\n",
       " ('south', 921),\n",
       " ('meetings', 918),\n",
       " ('family', 918),\n",
       " ('young', 914),\n",
       " ('abuse', 911),\n",
       " ('plans', 907),\n",
       " ('disabled', 907),\n",
       " ('projects', 897),\n",
       " ('monthly', 895),\n",
       " ('licence', 895),\n",
       " ('settlement', 894),\n",
       " ('case', 891),\n",
       " ('house', 889),\n",
       " ('rules', 889),\n",
       " ('procurement', 884),\n",
       " ('boost', 884),\n",
       " ('marriage', 882),\n",
       " ('fire', 881),\n",
       " ('industry', 879),\n",
       " ('be', 878),\n",
       " ('west', 877),\n",
       " ('accounts', 877),\n",
       " ('law', 875),\n",
       " ('more', 875),\n",
       " ('one', 873),\n",
       " ('vat', 873),\n",
       " ('final', 868),\n",
       " ('trust', 865),\n",
       " ('misconduct', 864),\n",
       " ('summary', 862),\n",
       " ('2018', 858),\n",
       " ('open', 857),\n",
       " ('legislation', 856),\n",
       " ('5', 855),\n",
       " ('meeting', 853),\n",
       " ('medical', 848),\n",
       " ('food', 846),\n",
       " ('gas', 844),\n",
       " ('goods', 840),\n",
       " ('2009', 840),\n",
       " ('4', 839),\n",
       " ('families', 836),\n",
       " ('board', 834),\n",
       " ('dft', 833),\n",
       " ('ministerial', 832),\n",
       " ('request', 828),\n",
       " ('rates', 823),\n",
       " ('test', 821),\n",
       " ('free', 821),\n",
       " ('project', 820),\n",
       " ('performance', 819),\n",
       " ('hmrc', 819),\n",
       " ('check', 817),\n",
       " ('paper', 814),\n",
       " ('climate', 811),\n",
       " ('what', 808),\n",
       " ('standard', 807),\n",
       " ('£25', 803),\n",
       " ('level', 803),\n",
       " ('is', 802),\n",
       " ('payments', 802),\n",
       " ('after', 799),\n",
       " ('e', 797),\n",
       " ('growth', 797),\n",
       " ('limited', 791),\n",
       " ('independent', 791),\n",
       " ('partnership', 790),\n",
       " ('self', 789),\n",
       " ('commonwealth', 788),\n",
       " ('building', 787),\n",
       " ('bulletin', 786),\n",
       " ('post', 785),\n",
       " ('regulation', 782),\n",
       " ('digital', 781),\n",
       " ('river', 780),\n",
       " ('universal', 780),\n",
       " ('staff', 779),\n",
       " ('day', 774),\n",
       " ('have', 774),\n",
       " ('group', 773),\n",
       " ('areas', 773),\n",
       " ('tariff', 772),\n",
       " ('visa', 771),\n",
       " ('authorities', 766),\n",
       " ('equality', 764),\n",
       " ('documents', 763),\n",
       " ('great', 762),\n",
       " ('results', 762),\n",
       " ('air', 759),\n",
       " ('companies', 756),\n",
       " ('31', 755),\n",
       " ('registry', 754),\n",
       " ('anti', 753),\n",
       " ('revenue', 752),\n",
       " ('income', 748),\n",
       " ('years', 743),\n",
       " ('process', 743),\n",
       " ('certificate', 740),\n",
       " ('make', 738),\n",
       " ('forms', 737),\n",
       " ('disposal', 735),\n",
       " ('vehicle', 732),\n",
       " ('science', 730),\n",
       " ('finance', 727),\n",
       " ('fees', 725),\n",
       " ('unit', 725),\n",
       " ('number', 725),\n",
       " ('against', 724),\n",
       " ('between', 723),\n",
       " ('primary', 720),\n",
       " ('expenses', 720),\n",
       " ('£500', 719),\n",
       " ('end', 719),\n",
       " ('grant', 716),\n",
       " ('15', 715),\n",
       " ('provisional', 709),\n",
       " ('royal', 709),\n",
       " ('department', 706),\n",
       " ('major', 703),\n",
       " ('brief', 702),\n",
       " ('need', 701),\n",
       " ('when', 701),\n",
       " ('early', 700),\n",
       " ('green', 699),\n",
       " ('key', 699),\n",
       " ('approved', 694),\n",
       " ('human', 694),\n",
       " ('visits', 692),\n",
       " ('military', 692),\n",
       " ('fco', 690),\n",
       " ('marine', 690),\n",
       " ('oil', 686),\n",
       " ('sustainable', 685),\n",
       " ('area', 682),\n",
       " ('competition', 677),\n",
       " ('can', 673),\n",
       " ('it', 673),\n",
       " ('reporting', 672),\n",
       " ('transfer', 672),\n",
       " ('pack', 665),\n",
       " ('17', 665),\n",
       " ('control', 664),\n",
       " ('monitoring', 660),\n",
       " ('regulatory', 659),\n",
       " ('skills', 659),\n",
       " ('improving', 659),\n",
       " ('will', 658),\n",
       " ('who', 657),\n",
       " ('right', 657),\n",
       " ('capital', 656),\n",
       " ('forced', 652),\n",
       " ('someone', 648),\n",
       " ('issue', 646),\n",
       " ('strategic', 645),\n",
       " ('welsh', 642),\n",
       " ('construction', 641),\n",
       " ('licensing', 641),\n",
       " ('deal', 639),\n",
       " ('official', 638),\n",
       " ('power', 638),\n",
       " ('global', 637),\n",
       " ('english', 637),\n",
       " ('expenditure', 636),\n",
       " ('return', 633),\n",
       " ('costs', 633),\n",
       " ('women', 633),\n",
       " ('world', 630),\n",
       " ('apprenticeship', 629),\n",
       " ('devolution', 628),\n",
       " ('leave', 627),\n",
       " ('time', 626),\n",
       " ('registered', 626),\n",
       " ('delivery', 623),\n",
       " ('proposals', 622),\n",
       " ('byelaws', 621),\n",
       " ('technology', 620),\n",
       " ('youth', 620),\n",
       " ('outcomes', 618),\n",
       " ('30', 616),\n",
       " ('hospitality', 612),\n",
       " ('united', 612),\n",
       " ('powers', 612),\n",
       " ('small', 606),\n",
       " ('measures', 606),\n",
       " ('homes', 604),\n",
       " ('funds', 603),\n",
       " ('permit', 598),\n",
       " ('note', 598),\n",
       " ('mr', 596),\n",
       " ('union', 596),\n",
       " ('11', 596),\n",
       " ('credits', 596),\n",
       " ('model', 595),\n",
       " ('through', 591),\n",
       " ('investigation', 590),\n",
       " ('innovation', 589),\n",
       " ('cost', 589),\n",
       " (\"you're\", 589),\n",
       " ('mgn', 586),\n",
       " ('workforce', 583),\n",
       " ('their', 583),\n",
       " ('loans', 582),\n",
       " ('visit', 581),\n",
       " ('criminal', 581),\n",
       " ('design', 579),\n",
       " ('fuel', 577),\n",
       " ('needs', 577),\n",
       " ('insurance', 575),\n",
       " ('enforcement', 574),\n",
       " ('traffic', 572),\n",
       " ('requirements', 569),\n",
       " ('works', 565),\n",
       " ('senior', 564),\n",
       " ('statutory', 564),\n",
       " ('centre', 564),\n",
       " ('private', 563),\n",
       " ('summit', 562),\n",
       " ('operational', 562),\n",
       " ('online', 561),\n",
       " ('childcare', 560),\n",
       " ('vehicles', 559),\n",
       " ('import', 558),\n",
       " ('supporting', 555),\n",
       " ('organisations', 552),\n",
       " ('regional', 548),\n",
       " ('badge', 547),\n",
       " ('stop', 546),\n",
       " ('joint', 546),\n",
       " ('sea', 544),\n",
       " ('names', 544),\n",
       " ('laundering', 544),\n",
       " ('bus', 543),\n",
       " ('9', 543),\n",
       " ('stage', 543),\n",
       " ('network', 542),\n",
       " ('infrastructure', 542),\n",
       " ('victims', 541),\n",
       " ('learning', 541),\n",
       " ('using', 541),\n",
       " ('price', 540),\n",
       " ('announces', 537),\n",
       " ('secondments', 536),\n",
       " ('disclosure', 535),\n",
       " ('other', 535),\n",
       " ('mark', 534),\n",
       " ('pensions', 533),\n",
       " ('conditions', 532),\n",
       " ('afternoon', 532),\n",
       " ('deputy', 531),\n",
       " ('mental', 530),\n",
       " ('inspection', 528),\n",
       " ('compliance', 528),\n",
       " ('6', 527),\n",
       " ('living', 527),\n",
       " ('dcms', 527),\n",
       " ('terrorism', 525),\n",
       " ('improvement', 524),\n",
       " ('notes', 523),\n",
       " ('patent', 522),\n",
       " ('issues', 520),\n",
       " ('role', 519),\n",
       " ('equipment', 519),\n",
       " ('low', 518),\n",
       " ('14', 517),\n",
       " ('13', 516),\n",
       " ('immigration', 515),\n",
       " ('estate', 514),\n",
       " ('notices', 512),\n",
       " ('18', 512),\n",
       " ('cyber', 512),\n",
       " ('further', 510),\n",
       " ('implementation', 508),\n",
       " ('treatment', 505),\n",
       " ('section', 503),\n",
       " ('better', 502),\n",
       " ('our', 502),\n",
       " ('afghanistan', 502),\n",
       " ('economy', 501),\n",
       " ('pollution', 501),\n",
       " ('communities', 500),\n",
       " ('welcomes', 499),\n",
       " ('7', 499),\n",
       " ('provision', 499),\n",
       " ('12', 498),\n",
       " ('employers', 497),\n",
       " ('making', 497),\n",
       " ('population', 493),\n",
       " ('testing', 493),\n",
       " ('no', 493),\n",
       " ('additional', 492),\n",
       " ('statistical', 490),\n",
       " ('record', 489),\n",
       " ('david', 489),\n",
       " ('programmes', 489),\n",
       " ('2008', 489),\n",
       " ('relief', 488),\n",
       " ('recovered', 488),\n",
       " ('contract', 486),\n",
       " ('charity', 485),\n",
       " ('transparency', 485),\n",
       " ('gifts', 485),\n",
       " ('providers', 485),\n",
       " ('common', 485),\n",
       " ('passenger', 484),\n",
       " ('directive', 484),\n",
       " ('fishing', 483),\n",
       " ('sexual', 483),\n",
       " ('taking', 481),\n",
       " ('off', 481),\n",
       " ('related', 479),\n",
       " ('academy', 478),\n",
       " ('card', 477),\n",
       " ('good', 477),\n",
       " ('8', 476),\n",
       " ('prison', 475),\n",
       " ('ownership', 475),\n",
       " ('interest', 473),\n",
       " ('inspire', 473),\n",
       " ('personal', 472),\n",
       " ('disease', 472),\n",
       " ('document', 472),\n",
       " ('chief', 471),\n",
       " ('ref', 469),\n",
       " ('do', 467),\n",
       " ('proposed', 467),\n",
       " ('send', 467),\n",
       " ('mod', 466),\n",
       " ('disability', 465),\n",
       " ('polygon', 464),\n",
       " ('animal', 463),\n",
       " ('bereavement', 462),\n",
       " (\"minister's\", 461),\n",
       " ('compensation', 458),\n",
       " ('19', 455),\n",
       " ('war', 455),\n",
       " ('minutes', 454),\n",
       " ('attorney', 454),\n",
       " ('emergency', 452),\n",
       " ('inland', 450),\n",
       " ('gcse', 449),\n",
       " ('death', 448),\n",
       " ('indicators', 447),\n",
       " ('dbs', 447),\n",
       " ('products', 446),\n",
       " ('driving', 446),\n",
       " ('cma', 445),\n",
       " ('synopsis', 445),\n",
       " ('causation', 445),\n",
       " ('contracts', 445),\n",
       " ('parliament', 445),\n",
       " ('affairs', 444),\n",
       " ('carers', 443),\n",
       " ('live', 443),\n",
       " ('quarter', 440),\n",
       " ('incident', 440),\n",
       " ('managing', 439),\n",
       " ('that', 438),\n",
       " ('supply', 437),\n",
       " ('country', 437),\n",
       " ('birth', 437),\n",
       " ('issued', 436),\n",
       " ('consumer', 435),\n",
       " ('enterprise', 435),\n",
       " ('arrangements', 435),\n",
       " ('adoption', 435),\n",
       " ('association', 433),\n",
       " ('facilities', 432),\n",
       " ('blue', 429),\n",
       " ('farm', 428),\n",
       " ('directors', 427),\n",
       " ('letters', 427),\n",
       " ('orders', 426),\n",
       " ('capacity', 424),\n",
       " ('estimates', 424),\n",
       " ('members', 424),\n",
       " ('recovery', 424),\n",
       " ('minimum', 423),\n",
       " ('neet', 422),\n",
       " ('appointment', 420),\n",
       " ('2006', 420),\n",
       " ('types', 420),\n",
       " ('residence', 420),\n",
       " ('carbon', 418),\n",
       " ('appeals', 418),\n",
       " ('charities', 417),\n",
       " ('maritime', 416),\n",
       " ('census', 415),\n",
       " ('deaths', 415),\n",
       " ('china', 415),\n",
       " ('cancer', 415),\n",
       " ('greater', 413),\n",
       " ('are', 411),\n",
       " ('legislative', 411),\n",
       " ('efficiency', 409),\n",
       " ('culture', 407),\n",
       " ('opinion', 406),\n",
       " ('budget', 405),\n",
       " ('commercial', 402),\n",
       " ('scottish', 402),\n",
       " ('age', 401),\n",
       " ('employee', 401),\n",
       " ('set', 400),\n",
       " ('value', 400),\n",
       " ('buy', 399),\n",
       " ('times', 399),\n",
       " ('industrial', 399),\n",
       " ('appointments', 399),\n",
       " ('alcohol', 398),\n",
       " ('vote', 398),\n",
       " ('pupil', 397),\n",
       " ('covenant', 397),\n",
       " ('term', 396),\n",
       " ('supervision', 396),\n",
       " ('amendment', 395),\n",
       " ('amendments', 395),\n",
       " ('contact', 394),\n",
       " ('bringing', 393),\n",
       " ('m', 393),\n",
       " ('forum', 393),\n",
       " ('dwp', 393),\n",
       " ('ofsted', 390),\n",
       " ('workers', 389),\n",
       " ('balance', 389),\n",
       " ('start', 389),\n",
       " ('challenge', 387),\n",
       " ('details', 387),\n",
       " ('electricity', 386),\n",
       " ('bis', 386),\n",
       " ('society', 386),\n",
       " ('insolvency', 385),\n",
       " ('asylum', 385),\n",
       " ('foundation', 383),\n",
       " ('rural', 383),\n",
       " ('africa', 383),\n",
       " ('commons', 382),\n",
       " (\"children's\", 382),\n",
       " ('individual', 382),\n",
       " ('assessments', 381),\n",
       " ('systems', 380),\n",
       " ('city', 378),\n",
       " ('treaties', 378),\n",
       " ('bank', 378),\n",
       " ('dumping', 377),\n",
       " ('become', 377),\n",
       " ('revised', 376),\n",
       " ('fisheries', 375),\n",
       " ('improve', 375),\n",
       " ('tourism', 375),\n",
       " ('webtag', 375),\n",
       " ('trainee', 373),\n",
       " ('advisory', 372),\n",
       " ('medicines', 371),\n",
       " ('vessels', 371),\n",
       " ('charges', 371),\n",
       " ('reforms', 371),\n",
       " ('interim', 371),\n",
       " ('prevention', 369),\n",
       " ('offences', 369),\n",
       " ('waters', 368),\n",
       " ('opportunities', 368),\n",
       " ('account', 367),\n",
       " ('waterways', 367),\n",
       " ('permanent', 366),\n",
       " ('claims', 365),\n",
       " ('un', 365),\n",
       " ('second', 364),\n",
       " ('academies', 363),\n",
       " ('deterrent', 363),\n",
       " ('event', 361),\n",
       " ('inquiry', 360),\n",
       " ('healthcare', 360),\n",
       " ('mail', 360),\n",
       " ('noise', 360),\n",
       " ('coast', 359),\n",
       " ('subject', 359),\n",
       " ('tables', 359),\n",
       " ('treasury', 359),\n",
       " ('prices', 358),\n",
       " ('search', 355),\n",
       " ('published', 355),\n",
       " ('operation', 355),\n",
       " ('than', 354),\n",
       " ('status', 354),\n",
       " ('award', 354),\n",
       " ('2020', 353),\n",
       " ('savings', 352),\n",
       " ('all', 351),\n",
       " ('checks', 351),\n",
       " ('reference', 350),\n",
       " ('during', 348),\n",
       " ('drivers', 348),\n",
       " ('rescue', 347),\n",
       " ('aviation', 347),\n",
       " ('voluntary', 346),\n",
       " ('2007', 346),\n",
       " ('emissions', 345),\n",
       " ('appointed', 345),\n",
       " ('behaviour', 345),\n",
       " ('co', 345),\n",
       " ('welfare', 345),\n",
       " ('effects', 344),\n",
       " ('animals', 343),\n",
       " ('manual', 343),\n",
       " ('licences', 342),\n",
       " ('join', 342),\n",
       " ('assurance', 342),\n",
       " ('employer', 341),\n",
       " ('dangerous', 341),\n",
       " ('car', 341),\n",
       " ('electoral', 341),\n",
       " ('restriction', 340),\n",
       " ('calls', 340),\n",
       " ('executive', 340),\n",
       " ('activity', 340),\n",
       " ('reduction', 340),\n",
       " ('transactions', 340),\n",
       " ('smart', 340),\n",
       " ('parents', 337),\n",
       " ('next', 337),\n",
       " ('2005', 335),\n",
       " ('materials', 335),\n",
       " ('maternity', 334),\n",
       " ('charge', 333),\n",
       " ('production', 333),\n",
       " ('guides', 333),\n",
       " ('partnerships', 333),\n",
       " ('content', 330),\n",
       " ('ltd', 330),\n",
       " ('director', 330),\n",
       " ('sport', 330),\n",
       " ('based', 330),\n",
       " ('impacts', 329),\n",
       " ('lord', 329),\n",
       " ('select', 329),\n",
       " ('not', 329),\n",
       " ('president', 328),\n",
       " ('trends', 328),\n",
       " ('educational', 328),\n",
       " ('students', 327),\n",
       " ('activities', 327),\n",
       " ('surveillance', 327),\n",
       " ('veterans', 327),\n",
       " ('waiting', 326),\n",
       " ('india', 326),\n",
       " ('appraisal', 326),\n",
       " ('questionnaire', 325),\n",
       " ('prisoner', 324),\n",
       " ('border', 324),\n",
       " ('criteria', 323),\n",
       " ('cover', 323),\n",
       " (\"uk's\", 322),\n",
       " ('period', 322),\n",
       " ('leaflet', 322),\n",
       " ('freight', 322),\n",
       " ('announced', 321),\n",
       " ('offenders', 320),\n",
       " ('phe', 319),\n",
       " ('codes', 319),\n",
       " ('merger', 319),\n",
       " ('communications', 318),\n",
       " ('professional', 318),\n",
       " ('higher', 316),\n",
       " ('tackle', 316),\n",
       " ('media', 316),\n",
       " ('pupils', 316),\n",
       " ('getting', 315),\n",
       " ('approach', 315),\n",
       " ('pre', 314),\n",
       " ('fraud', 313),\n",
       " ('complaints', 313),\n",
       " ('terms', 312),\n",
       " ('inspections', 312),\n",
       " ('understanding', 311),\n",
       " ('operations', 311),\n",
       " ('records', 311),\n",
       " ('student', 310),\n",
       " ('paye', 310),\n",
       " ('written', 310),\n",
       " ('awards', 309),\n",
       " ('approval', 309),\n",
       " ('two', 309),\n",
       " ('week', 308),\n",
       " ('campaign', 308),\n",
       " ('fish', 308),\n",
       " ('adults', 308),\n",
       " ('launches', 308),\n",
       " ('funeral', 307),\n",
       " ('extension', 307),\n",
       " ('college', 307),\n",
       " ('conflict', 307),\n",
       " ('ministry', 306),\n",
       " ('rate', 305),\n",
       " ('illegal', 305),\n",
       " ('vaccine', 304),\n",
       " ('citizen', 304),\n",
       " ('recommendations', 304),\n",
       " ('vision', 304),\n",
       " ('roads', 303),\n",
       " ('cabinet', 303),\n",
       " ('launch', 303),\n",
       " ('hearing', 302),\n",
       " ('michael', 302),\n",
       " ('tb', 301),\n",
       " ('availability', 301),\n",
       " ('chair', 301),\n",
       " ('name', 301),\n",
       " ('direct', 300),\n",
       " ('declaration', 300),\n",
       " ('condemns', 300),\n",
       " ('sentencing', 300),\n",
       " ('share', 299),\n",
       " ('recommendation', 298),\n",
       " ('offshore', 298),\n",
       " ('commissioner', 298),\n",
       " ('electronic', 298),\n",
       " ('crown', 296),\n",
       " ('adult', 296),\n",
       " ('collection', 296),\n",
       " ('apprenticeships', 295),\n",
       " ('give', 295),\n",
       " ('external', 295),\n",
       " ('launched', 294),\n",
       " ('midlands', 293),\n",
       " ('procedures', 293),\n",
       " ('entry', 292),\n",
       " ('tackling', 292),\n",
       " ('improvements', 292),\n",
       " ('corporation', 291),\n",
       " ('best', 291),\n",
       " ('policing', 291),\n",
       " ('councils', 290),\n",
       " ('force', 290),\n",
       " ('consular', 290),\n",
       " ('permits', 290),\n",
       " ('we', 290),\n",
       " ('convention', 290),\n",
       " ('labour', 289),\n",
       " ('trusts', 288),\n",
       " ('trading', 287),\n",
       " ('academic', 287),\n",
       " ('cases', 287),\n",
       " ('gov', 287),\n",
       " ('countryside', 286),\n",
       " ('agreements', 286),\n",
       " ('courts', 286),\n",
       " ('22', 285),\n",
       " ('publication', 285),\n",
       " ('jobs', 285),\n",
       " ('highways', 284),\n",
       " ('engagement', 284),\n",
       " ('autumn', 284),\n",
       " ('europe', 284),\n",
       " ('avoidance', 284),\n",
       " ('exemption', 283),\n",
       " ('product', 283),\n",
       " ('a1', 283),\n",
       " ('troubled', 281),\n",
       " ('summaries', 281),\n",
       " ('lawyers', 281),\n",
       " ('28', 280),\n",
       " ('residential', 280),\n",
       " ('its', 279),\n",
       " ('newsletter', 279),\n",
       " ('shared', 279),\n",
       " ('20', 278),\n",
       " ('decisions', 278),\n",
       " ('farming', 277),\n",
       " ('centres', 277),\n",
       " ('short', 277),\n",
       " ('stewardship', 276),\n",
       " ('kingdom', 276),\n",
       " ('levels', 276),\n",
       " ('controls', 276),\n",
       " ('employees', 276),\n",
       " ('steps', 275),\n",
       " ('full', 275),\n",
       " ('eligibility', 275),\n",
       " ('nick', 274),\n",
       " ('engineering', 274),\n",
       " ('guidelines', 274),\n",
       " ('competences', 274),\n",
       " ('premium', 273),\n",
       " ('coastal', 273),\n",
       " ('field', 273),\n",
       " ('supplementary', 273),\n",
       " ('calculator', 273),\n",
       " ('transforming', 273),\n",
       " ('patient', 272),\n",
       " ('citizenship', 272),\n",
       " ('airport', 272),\n",
       " ('radioactive', 272),\n",
       " ('has', 271),\n",
       " ('judgement', 270),\n",
       " ('cross', 269),\n",
       " ('proposal', 269),\n",
       " ('applying', 269),\n",
       " ('feasibility', 269),\n",
       " ('female', 268),\n",
       " ('long', 268),\n",
       " ('attitudes', 268),\n",
       " ('personnel', 268),\n",
       " ('experience', 268),\n",
       " ('closures', 266),\n",
       " ('returns', 266),\n",
       " ('diplomats', 266),\n",
       " ('site', 265),\n",
       " ('article', 265),\n",
       " ('gpc', 264),\n",
       " ('person', 264),\n",
       " ('big', 264),\n",
       " ('wage', 264),\n",
       " ('departmental', 263),\n",
       " ('acoba', 262),\n",
       " ('resources', 262),\n",
       " ('reducing', 262),\n",
       " ('25', 261),\n",
       " ('parole', 261),\n",
       " ('petroleum', 261),\n",
       " ('condition', 260),\n",
       " ('initial', 260),\n",
       " ('lending', 260),\n",
       " ('thames', 260),\n",
       " ('agricultural', 260),\n",
       " ('mobility', 260),\n",
       " ('apr', 259),\n",
       " ('governance', 259),\n",
       " ('down', 259),\n",
       " ('overview', 259),\n",
       " ('syria', 259),\n",
       " ('o', 258),\n",
       " ('measure', 257),\n",
       " ('way', 257),\n",
       " ('proliferation', 257),\n",
       " ('copy', 257),\n",
       " ('they', 256),\n",
       " ('mar', 256),\n",
       " ('speed', 256),\n",
       " ('girls', 256),\n",
       " ('parental', 256),\n",
       " ('being', 255),\n",
       " ('heat', 255),\n",
       " ('leadership', 255),\n",
       " ...]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sorted(tokenizer_tit.word_counts.items(), key=lambda x:x[1], reverse=True)\n",
    "#for key, value in sorted(mydict.iteritems(), key=lambda (k,v): (v,k)):\n",
    "    #print \"%s: %s\" % (key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize description text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bag of words method\n",
    "tokenizer_desc = Tokenizer(num_words=10000) #num_words: None or int. Maximum number of words to work with \n",
    "# (if set, tokenization will be restricted to the top num_words most common words in the dataset).\n",
    "\n",
    "# apply tokenizer to our text data\n",
    "tokenizer_desc.fit_on_texts(descs)\n",
    "\n",
    "# list of word indexes, where the word of rank i in the dataset (starting at 1) has index i\n",
    "sequences_desc = tokenizer_desc.texts_to_sequences(descs) #yield one sequence per input text\n",
    "onehot_desc = tokenizer_desc.sequences_to_matrix(sequences_desc) #yield one sequence per input text\n",
    "\n",
    "# dictionary mapping words (str) to their rank/index (int).\n",
    "word_index_desc = tokenizer_desc.word_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197338, 10000)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_desc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split\n",
    "- Training data = 80%\n",
    "- Development data = 10%\n",
    "- Test data = 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0      1      2 ..., 197335 197336 197337]\n",
      "[144789 191618  83576 ..., 117952 173685  43567]\n"
     ]
    }
   ],
   "source": [
    "# shuffle data and standardise indices\n",
    "indices = np.arange(data.shape[0])\n",
    "print(indices)\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data[indices]\n",
    "metadata = meta[indices]\n",
    "title_data = onehot_tit[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "desc_data = onehot_desc[indices]\n",
    "timedata = first_published[indices]\n",
    "\n",
    "\n",
    "labels = binary_multilabel[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_test samples: 19733\n",
      "nb_dev samples: 39467\n",
      "nb_training samples: 157870\n"
     ]
    }
   ],
   "source": [
    "nb_test_samples = int(0.1 * data.shape[0]) #validation split\n",
    "print('nb_test samples:', nb_test_samples)\n",
    "\n",
    "nb_dev_samples = int(0.2 * data.shape[0]) #validation split\n",
    "print('nb_dev samples:', nb_dev_samples)\n",
    "\n",
    "nb_training_samples = int(0.8 * data.shape[0]) #validation split\n",
    "print('nb_training samples:', nb_training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (157871, 1000)\n",
      "Shape of metax_train: (157871, 431)\n",
      "Shape of titlex_train: (157871, 10000)\n",
      "Shape of descx_train: (157871, 10000)\n",
      "Shape of datex_train: (157871, 1)\n",
      "Shape of y_train: (157871, 210)\n"
     ]
    }
   ],
   "source": [
    "x_train = data[:-nb_dev_samples]\n",
    "print('Shape of x_train:', x_train.shape)\n",
    "\n",
    "metax_train = metadata[:-nb_dev_samples]\n",
    "print('Shape of metax_train:', metax_train.shape)\n",
    "\n",
    "titlex_train = title_data[:-nb_dev_samples]\n",
    "print('Shape of titlex_train:', titlex_train.shape)\n",
    "\n",
    "descx_train = desc_data[:-nb_dev_samples]\n",
    "print('Shape of descx_train:', descx_train.shape)\n",
    "\n",
    "datex_train = timedata[:-nb_dev_samples]\n",
    "print('Shape of datex_train:', datex_train.shape)\n",
    "\n",
    "y_train = labels[:-nb_dev_samples]\n",
    "print('Shape of y_train:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_dev: (19734, 1000)\n",
      "Shape of metax_dev: (19734, 431)\n",
      "Shape of titlex_dev: (19734, 10000)\n",
      "Shape of descx_dev: (19734, 10000)\n",
      "Shape of metax_dev: (19734, 1)\n",
      "Shape of y_dev: (19734, 210)\n"
     ]
    }
   ],
   "source": [
    "x_dev = data[-nb_dev_samples:-nb_test_samples]\n",
    "print('Shape of x_dev:', x_dev.shape)\n",
    "\n",
    "metax_dev = metadata[-nb_dev_samples:-nb_test_samples]\n",
    "print('Shape of metax_dev:', metax_dev.shape)\n",
    "\n",
    "titlex_dev = title_data[-nb_dev_samples:-nb_test_samples]\n",
    "print('Shape of titlex_dev:', titlex_dev.shape)\n",
    "\n",
    "descx_dev = desc_data[-nb_dev_samples:-nb_test_samples]\n",
    "print('Shape of descx_dev:', descx_dev.shape)\n",
    "\n",
    "datex_dev = timedata[-nb_dev_samples:-nb_test_samples]\n",
    "print('Shape of metax_dev:', datex_dev.shape)\n",
    "\n",
    "y_dev = labels[-nb_dev_samples:-nb_test_samples]\n",
    "print('Shape of y_dev:', y_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_test: (19733, 1000)\n",
      "Shape of metax_test: (19733, 431)\n",
      "Shape of titlex_test: (19733, 10000)\n",
      "Shape of descx_test: (19733, 10000)\n",
      "Shape of datex_test: (19733, 1)\n",
      "Shape of y_test: (19733, 210)\n"
     ]
    }
   ],
   "source": [
    "x_test = data[-nb_test_samples:]\n",
    "print('Shape of x_test:', x_test.shape)\n",
    "\n",
    "metax_test = metadata[-nb_test_samples:]\n",
    "print('Shape of metax_test:', metax_test.shape)\n",
    "\n",
    "titlex_test = title_data[-nb_test_samples:]\n",
    "print('Shape of titlex_test:', titlex_test.shape)\n",
    "\n",
    "descx_test = desc_data[-nb_test_samples:]\n",
    "print('Shape of descx_test:', descx_test.shape)\n",
    "\n",
    "datex_test = timedata[-nb_test_samples:]\n",
    "print('Shape of datex_test:', datex_test.shape)\n",
    "\n",
    "y_test = labels[-nb_test_samples:]\n",
    "print('Shape of y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing the Embedding layer\n",
    "\n",
    "NB stopwords haven't been removed yet..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1, \n",
    "                            EMBEDDING_DIM, \n",
    "                            input_length=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Embedding layer should be fed sequences of integers, i.e. a 2D input of shape (samples, indices). These input sequences should be padded so that they all have the same length in a batch of input data (although an Embedding layer is capable of processing sequence of heterogenous length, if you don't pass an explicit input_length argument to the layer).\n",
    "\n",
    "All that the Embedding layer does is to map the integer inputs to the vectors found at the corresponding index in the embedding matrix, i.e. the sequence [1, 2] would be converted to [embeddings[1], embeddings[2]]. This means that the output of the Embedding layer will be a 3D tensor of shape (samples, sequence_length, embedding_dim)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate class weights for unbalanced datasets.\n",
    "paramter to model.fit = __class_weight__: Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
    "\n",
    "Implement class_weight from sklearn:\n",
    "\n",
    "- Import the module \n",
    "\n",
    "`from sklearn.utils import class_weight`\n",
    "- calculate the class weight, If ‘balanced’, class weights will be given by n_samples / (n_classes * np.bincount(y)):\n",
    "\n",
    "`class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)`\n",
    "\n",
    "- change it to a dict in order to work with Keras.\n",
    "\n",
    "`class_weight_dict = dict(enumerate(class_weight))`\n",
    "\n",
    "- Add to model fitting\n",
    "\n",
    "`model.fit(X_train, y_train, class_weight=class_weight)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "# class_weight_dict = dict(enumerate(class_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.00756\n",
      "8.01512\n"
     ]
    }
   ],
   "source": [
    "class WeightedBinaryCrossEntropy(object):\n",
    "\n",
    "    def __init__(self, pos_ratio):\n",
    "        neg_ratio = 1. - pos_ratio\n",
    "        #self.pos_ratio = tf.constant(pos_ratio, tf.float32)\n",
    "        self.pos_ratio = pos_ratio\n",
    "        #self.weights = tf.constant(neg_ratio / pos_ratio, tf.float32)\n",
    "        self.weights = neg_ratio / pos_ratio\n",
    "        self.__name__ = \"weighted_binary_crossentropy({0})\".format(pos_ratio)\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        return self.weighted_binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "    def weighted_binary_crossentropy(self, y_true, y_pred):\n",
    "            # Transform to logits\n",
    "            epsilon = tf.convert_to_tensor(K.common._EPSILON, y_pred.dtype.base_dtype)\n",
    "            y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
    "            y_pred = tf.log(y_pred / (1 - y_pred))\n",
    "\n",
    "            cost = tf.nn.weighted_cross_entropy_with_logits(y_true, y_pred, self.weights)\n",
    "            return K.mean(cost * self.pos_ratio, axis=-1)\n",
    "    \n",
    "y_true_arr = np.array([0,1,0,1], dtype=\"float32\")\n",
    "y_pred_arr = np.array([0,0,1,1], dtype=\"float32\")\n",
    "y_true = tf.constant(y_true_arr)\n",
    "y_pred = tf.constant(y_pred_arr)\n",
    "\n",
    "with tf.Session().as_default(): \n",
    "    print(WeightedBinaryCrossEntropy(0.5)(y_true, y_pred).eval())\n",
    "    print(binary_crossentropy(y_true, y_pred).eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### difficulty getting global precision/recall metrics . CAUTION interpreting monitoring metrics\n",
    "fcholltet: \"Basically these are all global metrics that were approximated\n",
    "batch-wise, which is more misleading than helpful. This was mentioned in\n",
    "the docs but it's much cleaner to remove them altogether. It was a mistake\n",
    "to merge them in the first place.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    \"\"\"Use Recall  and precision metrics to calculate harmonic mean (F1 score).\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1 = 2*((precision*recall)/(precision+recall))\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a 1D convnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NB_CLASSES = y_train.shape[1]\n",
    "NB_METAVARS = metax_train.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='wordindex') #MAX_SEQUENCE_LENGTH\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Dropout(0.2, name = 'dropout_embedded')(embedded_sequences)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv0')(x)\n",
    "\n",
    "x = MaxPooling1D(5, name = 'max_pool0')(x)\n",
    "\n",
    "x = Dropout(0.5, name = 'dropout0')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv1')(x)\n",
    "\n",
    "x = MaxPooling1D(5 , name = 'max_pool1')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv2')(x)\n",
    "\n",
    "x = MaxPooling1D(35, name = 'global_max_pool')(x)  # global max pooling\n",
    "\n",
    "x = Flatten()(x) #reduce dimensions from 3 to 2; convert to vector + FULLYCONNECTED\n",
    "\n",
    "meta_input = Input(shape=(NB_METAVARS,), name='meta')\n",
    "meta_hidden = Dense(128, activation='relu', name = 'hidden_meta')(meta_input)\n",
    "meta_hidden = Dropout(0.2, name = 'dropout_meta')(meta_hidden)\n",
    "\n",
    "\n",
    "title_input = Input(shape=(titlex_train.shape[1],), name='titles')\n",
    "title_hidden = Dense(128, activation='relu', name = 'hidden_title')(title_input)\n",
    "title_hidden = Dropout(0.2, name = 'dropout_title')(title_hidden)\n",
    "\n",
    "desc_input = Input(shape=(descx_train.shape[1],), name='descs')\n",
    "desc_hidden = Dense(128, activation='relu', name = 'hidden_desc')(desc_input)\n",
    "desc_hidden = Dropout(0.2, name = 'dropout_desc')(desc_hidden)\n",
    "\n",
    "concatenated = concatenate([meta_hidden, title_hidden, desc_hidden, x])\n",
    "\n",
    "x = Dense(400, activation='relu', name = 'fully_connected0')(concatenated)\n",
    "\n",
    "x = Dropout(0.2, name = 'dropout1')(x)\n",
    "\n",
    "x = Dense(NB_CLASSES, activation='sigmoid', name = 'fully_connected1')(x)\n",
    "\n",
    "# # The Model class turns an input tensor and output tensor into a model\n",
    "# This creates Keras model instance, will use this instance to train/test the model.\n",
    "model = Model(inputs=[meta_input, title_input, desc_input, sequence_input], outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.compile(loss=WeightedBinaryCrossEntropy(POS_RATIO),\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['binary_accuracy', f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric values are recorded at the end of each epoch on the training dataset. If a validation dataset is also provided, then the metric recorded is also calculated for the validation dataset.\n",
    "\n",
    "All metrics are reported in verbose output and in the history object returned from calling the fit() function. In both cases, the name of the metric function is used as the key for the metric values. In the case of metrics for the validation dataset, the “val_” prefix is added to the key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have now built a function to describe your model. To train and test this model, there are four steps in Keras:\n",
    "1. Create the model by calling the function above\n",
    "2. Compile the model by calling `model.compile(optimizer = \"...\", loss = \"...\", metrics = [\"accuracy\"])`\n",
    "3. Train the model on train data by calling `model.fit(x = ..., y = ..., epochs = ..., batch_size = ...)`\n",
    "4. Test the model on test data by calling `model.evaluate(x = ..., y = ...)`\n",
    "\n",
    "If you want to know more about `model.compile()`, `model.fit()`, `model.evaluate()` and their arguments, refer to the official [Keras documentation](https://keras.io/models/model/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "wordindex (InputLayer)          (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 100)    17138000    wordindex[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_embedded (Dropout)      (None, 1000, 100)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv1D)                  (None, 996, 128)     64128       dropout_embedded[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pool0 (MaxPooling1D)        (None, 199, 128)     0           conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout0 (Dropout)              (None, 199, 128)     0           max_pool0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv1D)                  (None, 195, 128)     82048       dropout0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pool1 (MaxPooling1D)        (None, 39, 128)      0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "meta (InputLayer)               (None, 431)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "titles (InputLayer)             (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "descs (InputLayer)              (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv1D)                  (None, 35, 128)      82048       max_pool1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hidden_meta (Dense)             (None, 128)          55296       meta[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "hidden_title (Dense)            (None, 128)          1280128     titles[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "hidden_desc (Dense)             (None, 128)          1280128     descs[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pool (MaxPooling1D)  (None, 1, 128)       0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_meta (Dropout)          (None, 128)          0           hidden_meta[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_title (Dropout)         (None, 128)          0           hidden_title[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_desc (Dropout)          (None, 128)          0           hidden_desc[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           global_max_pool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           dropout_meta[0][0]               \n",
      "                                                                 dropout_title[0][0]              \n",
      "                                                                 dropout_desc[0][0]               \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fully_connected0 (Dense)        (None, 400)          205200      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 400)          0           fully_connected0[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fully_connected1 (Dense)        (None, 210)          84210       dropout1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 20,271,186\n",
      "Trainable params: 20,271,186\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard callbacks /metrics /monitor training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **Size of these files is killing storage during training. Is it histograms?**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tb = TensorBoard(log_dir='./learn_embedding_logs', histogram_freq=1, write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = os.path.join(DATADIR, 'model_checkpoint.hdf5')\n",
    "\n",
    "cp = ModelCheckpoint(\n",
    "                     filepath = CHECKPOINT_PATH, \n",
    "                     monitor='val_loss', \n",
    "                     verbose=0, \n",
    "                     save_best_only=False, \n",
    "                     save_weights_only=False, \n",
    "                     mode='auto', \n",
    "                     period=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class Metrics(Callback):\n",
    "#     def on_train_begin(self, logs={}):\n",
    "#         self.val_f1s = []\n",
    "#         self.val_recalls = []\n",
    "#         self.val_precisions = []\n",
    " \n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#         val_predict = (np.asarray(self.model.predict(self.model.validation_data[0]))).round()\n",
    "#         val_targ = self.model.validation_data[1]\n",
    "        \n",
    "#         self.val_f1s.append(f1_score(val_targ, val_predict, average='micro'))\n",
    "#         self.val_recalls.append(recall_score(val_targ, val_predict))\n",
    "#         self.val_precisions.append(precision_score(val_targ, val_predict))\n",
    "#         print(\"- val_f1: %f — val_precision: %f — val_recall %f\" \n",
    "#                 %(f1_score(val_targ, val_predict, average='micro'), \n",
    "#                   precision_score(val_targ, val_predict),\n",
    "#                    recall_score(val_targ, val_predict)))\n",
    "#         return\n",
    " \n",
    "# metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "#model.fit(x, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 157871 samples, validate on 19734 samples\n",
      "Epoch 1/10\n",
      "157871/157871 [==============================] - 132s 835us/step - loss: 0.0100 - binary_accuracy: 0.9943 - f1: nan - val_loss: 0.0040 - val_binary_accuracy: 0.9973 - val_f1: 0.8343\n",
      "Epoch 2/10\n",
      "157871/157871 [==============================] - 97s 612us/step - loss: 0.0034 - binary_accuracy: 0.9977 - f1: 0.8586 - val_loss: 0.0029 - val_binary_accuracy: 0.9980 - val_f1: 0.8829\n",
      "Epoch 3/10\n",
      "157871/157871 [==============================] - 97s 613us/step - loss: 0.0025 - binary_accuracy: 0.9983 - f1: 0.9000 - val_loss: 0.0025 - val_binary_accuracy: 0.9983 - val_f1: 0.9004\n",
      "Epoch 4/10\n",
      "157871/157871 [==============================] - 97s 613us/step - loss: 0.0020 - binary_accuracy: 0.9987 - f1: 0.9202 - val_loss: 0.0023 - val_binary_accuracy: 0.9985 - val_f1: 0.9138\n",
      "Epoch 5/10\n",
      "157871/157871 [==============================] - 97s 612us/step - loss: 0.0017 - binary_accuracy: 0.9989 - f1: 0.9326 - val_loss: 0.0022 - val_binary_accuracy: 0.9986 - val_f1: 0.9182\n",
      "Epoch 6/10\n",
      "157871/157871 [==============================] - 97s 612us/step - loss: 0.0015 - binary_accuracy: 0.9990 - f1: 0.9405 - val_loss: 0.0021 - val_binary_accuracy: 0.9988 - val_f1: 0.9271\n",
      "Epoch 7/10\n",
      "157871/157871 [==============================] - 97s 612us/step - loss: 0.0014 - binary_accuracy: 0.9991 - f1: 0.9462 - val_loss: 0.0021 - val_binary_accuracy: 0.9988 - val_f1: 0.9298\n",
      "Epoch 8/10\n",
      "157871/157871 [==============================] - 97s 612us/step - loss: 0.0013 - binary_accuracy: 0.9992 - f1: 0.9504 - val_loss: 0.0022 - val_binary_accuracy: 0.9988 - val_f1: 0.9319\n",
      "Epoch 9/10\n",
      "157871/157871 [==============================] - 96s 611us/step - loss: 0.0012 - binary_accuracy: 0.9992 - f1: 0.9535 - val_loss: 0.0022 - val_binary_accuracy: 0.9989 - val_f1: 0.9343\n"
     ]
    }
   ],
   "source": [
    "# metrics callback causes: CCCCCCR55555555511155\n",
    "# So disable for now\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "# Replicates `model` on 8 GPUs.\n",
    "# This assumes that your machine has 8 available GPUs.\n",
    "parallel_model = multi_gpu_model(model, gpus=8)\n",
    "parallel_model.compile(loss=WeightedBinaryCrossEntropy(POS_RATIO),\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['binary_accuracy', f1])\n",
    "\n",
    "# This `fit` call will be distributed on 8 GPUs.\n",
    "# Since the batch size is 256, each GPU will process 32 samples.\n",
    "history = parallel_model.fit(\n",
    "    {'meta': metax_train, 'titles': titlex_train, 'descs': descx_train, 'wordindex': x_train},\n",
    "    y_train, \n",
    "    validation_data=([metax_dev, titlex_dev, descx_dev, x_dev], y_dev), \n",
    "    epochs=10, batch_size=128, callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "\n",
    "# history = model.fit(\n",
    "#     {'meta': metax_train, 'titles': titlex_train, 'descs': descx_train, 'wordindex': x_train},\n",
    "#     y_train, \n",
    "#     validation_data=([metax_dev, titlex_dev, descx_dev, x_dev], y_dev), \n",
    "#     epochs=10, batch_size=128, callbacks=[early_stopping]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_binary_accuracy', 'val_f1', 'loss', 'binary_accuracy', 'f1'])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b4808b048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, 10)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')           \n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')      \n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XecVOXZ//HPRe+giICslKhRQKkb\n0CgqYgySqEF5FAQNKhJ7jzWW8AvBqEFFeYzYQEUIdk2wPYpRYgOkKKCCirCANAtVZeH6/XGfXYZl\nl5kts2d29/t+vea1Z06ba2bgXHOXc9/m7oiIiOxOtbgDEBGRzKdkISIiSSlZiIhIUkoWIiKSlJKF\niIgkpWQhIiJJKVlUEGZW3cw2mlnrstw3Tma2v5mVed9tMzvWzJYkPP/UzHqlsm8JXutBM7u+pMfv\n5rx/MbPxZX3eQl6nWN9Bur6zQl4nx8yOLmJbPTP7t5l9b2aTyiGWtHzHFU2NuAOorMxsY8LTesCP\nwLbo+R/cfWJxzufu24AGZb1vVeDuB5bFecxsGDDE3Y9OOPewsjh3WSoszkrmNGBPoKm755pZK+Af\nQDbQAtjX3XPK6sUy8TuOg0oWaeLuDfIewFLghIR1uyQKM1PiFklNG+BTd8+Nnm8HpgID4gtpZ2ZW\nzcwq1fW1Ur2ZiiSqZvinmU0ysw3AEDM7zMzeM7PvzGylmY0xs5rR/jXMzM2sbfT88Wj7S2a2wcze\nNbN2xd032n68mX0WFevvMbP/mtnQIuJOJcY/mNliM/vWzMYkHFvdzO40s3Vm9gXQdzefzw1mNrnA\nurFmNjpaHmZmC6P383n0a7qoc+VXaURVGI9Fsc0HuhfY909m9kV03vlmdmK0/hDgXqBXVMW3NuGz\nvSXh+POi977OzJ4zs5apfDZFqGtmT0axzIxiKGmc9aLPfmn0Pb9lZrUTzndm9DmtMbNrk8SV+Hk1\nMbNHon8LOWY2IrpQ1jWz9WZ2UMK+Lcxsi5k1jZ6faGZzo39L083s4BRebyRwPTA4en+/d/eV7n4f\nMCvFmIeZ2X+if7vfRd9HTzM7x8yWmdkqMxuSsH/B7/hkM5sTvb/FZnZctH66mf0/M3sX2AS0NrMs\nM/uXmX1jZovM7OzUPtkM5O56pPkBLAGOLbDuL8BPwAmEpF0X+AXQk1A9+DPgM+CiaP8agANto+eP\nA2sJRe+awD+Bx0uw797ABuCkaNsVwFZgaBHvJZUYnwcaA22Bb/LeO3ARMB/IApoCb4V/goW+zs+A\njUD9hHOvBrKj5ydE+xhwDLAF6BRtOxZYknCuHODoaPkO4E1gD8Iv1AUF9j0VaBl9J6dHMTSPtg0D\n3iwQ5+PALdHycVGMXYA6wP8Cb6Ty2RTy/v8SfQ/9o+/lWmAxUKOEcd4PvB4dUx04Ijrv/lFc/4hi\n7kaoMj2giLj2T/zOgBej91kPaE64YJ8TbXsU+HPCvpcC/0r4d7Qq+lsdOBv4HKhV8Dsr4rMZX8j6\nOtF7yUry/3FY9NmeEb32rcBXwBigNtAP+B6oV8h3/EvgO6BP9NnvCxwYbZtO+L/ePvpsawD/Be5J\n+GzXAkfFfU0q0XUs7gCqwoOik8UbSY67CngyWi4sAfwjYd8TgY9LsO/ZwNsJ2wxYSRHJIsUYD03Y\n/gxwVbT8FjAsYVs/ikgW0fb3gNOj5eMJVQ9F7fsv4MJoeXfJYmnidwFckLhvIef9GPhNtJwsWUwA\n/pqwrRGhnSor2WdTyOv+BZie8Lw6IREdVtw4o2N/BDoWclxesmiRsO5DYEARr5OfLIBWhCRdO2H7\nGcBr0XJf4LOEbe8nfJ8PADcXOPfnwOEFv7MiPpvxhawvTrJYmPC8a3Rc04R13wMHF/IdPwTcXsR5\npwM3JTxvR0hK9RPW3Q48mMr/rUx7qBoqXssSn5jZQRZ6eXxtZuuBEcBeuzn+64Tlzey+UbuoffdJ\njCO6ChTZOJhijCm9FuHX3O48AQyKlk+PnufF8Vszez8q3n9H+FW/u88qT8vdxWBmQxOqRr4DDkrx\nvBDeX/753H098C3hopqnON9Z4veyDVgevUZx42wO1CJcjAvl7rvEZTt61eU99ilwWBvCL/FVCXGM\njV4P4P+AJmbW3cz2AzoQSlZ5x16Td1x0bEt2/qxKzcyOToh/bsKmVQnLW4Bt7r6uwLrCvpt92c3n\nyM7/tvYB1rr7poR1X1HG77G8KFnEq2AXxPsJvxD3d/dGwE2EX/rptJLwyxcAMzN2/4+5NDGuJPxn\ny5Osa+8U4FgLvV1OIkoWZlYXeAoYRah6aQK8mmIcXxcVg5n9DLgPOJ/wK7MJ8EnCeZN1GV1BuAjm\nna8hobpreQpxFSY/TguNpa2AFSWIcxWhynO/4ry4u2/zhI4a7r6iwC7LCIllT3dvEj0auXun6Phc\n4ElCwj8deCHhwrmMUEXVJOFRz92nFCfGFN7Dmwnxdy6DUy5j959j4me/AtjLzOonrGtNyf89xErJ\nIrM0JBR/N5lZe+AP5fCa/wK6mdkJFnpkXQo0S1OMU4DLzKxV1Mh5ze52jn7tTgfGE6qgFkWbahN+\nKa8BtpnZbwl1yKnGcH3UMNua0I6SpwHhP/saQt48l/CLPc8qIMuiBv1CTALOMbNOUePxKEIVX0m7\ncfYws5Oi17uK0LY0o7hxRqWS8cBdUSNzdTM7fDfvIyXuvgz4D3CHmTWKGrb3N7MjE3Z7gtDVdaeS\nIaEa6kIz+4UFDaJ/g4kX1pSZWR3CvwuA2pbQeF/GHgKGmVnv6P1mmVmhXbPd/UtgJvBXM6ttZl2A\nswjVWhWOkkVmuRL4PeGicD+hITqt3H0V4T/zaGAd4VfTbEIdd1nHeB+hkfUjwkXvqRSOeYLQBpF/\noXH374DLgWcJjcQDCEkvFTcTSjhLgJcIjbB5551HaIz8INrnQEI9e57XgEWEapfEapu8418mVMs9\nGx3fGhicYlyFeRYYQniPpwEnu3tuCeO8HFhIaID+BvgrZVNqHQLUJ3QU+JZQkmiRsP0dIJfwA+TV\nvJXu/h6hZHRfdNxn0bmKLfqRs4XQ8AyhI8Cmoo8oOXd/BziX0Bj+PTCNnUuqBZ0GHEAo0T4FXO/u\nb6YjtnSzqNFFBAjdWwnF5wHu/nbc8YhIZlDJQjCzvlG1TG3gRkIPjg9iDktEMoiShUDoc/8FoQ78\n10B/dy+qGkpEqiBVQ4mISFIqWYiISFKVZvC6vfbay9u2bRt3GCIiFcqsWbPWuvvuussDlShZtG3b\nlpkzZ8YdhohIhWJmyUZSAFQNJSIiKVCyEBGRpJQsREQkqUrTZlGYrVu3kpOTww8//BB3KFVenTp1\nyMrKombNUg1HJCIxqdTJIicnh4YNG9K2bVvCYKoSB3dn3bp15OTk0K5du+QHiEjGqdTVUD/88ANN\nmzZVooiZmdG0aVOV8ETK2MSJ0LYtVKsW/k6cmL7XqtQlC0CJIkPoexApWxMnwvDhsHlzeP7VV+E5\nwODSjHVchEpdshARqaxuuGFHosizeXNYnw5KFmm0bt06unTpQpcuXWjRogWtWrXKf/7TTz+ldI6z\nzjqLTz/9dLf7jB07lollVP5888036dixY36Mv/71r2nSpAm/+93vyuT8IlI2li4t3vrSqvTVUMUx\ncWLIykuXQuvWMHJk6YpzTZs2Zc6cOQDccsstNGjQgKuuumqnffInQ69WeN5+5JFHkr7OhRdeWPIg\nC3j88ce58cYbGThwIO7O1VdfzYYNGxg/fnyZvYaIlF7r1qHqqbD16aCSRSSv/u+rr8B9R/1fOhqM\nFi9eTIcOHRg8eDAdO3Zk5cqVDB8+nOzsbDp27MiIESPy9z3iiCOYM2cOubm5NGnShGuvvZbOnTtz\n2GGHsXr1agD+9Kc/cdddd+Xvf+2119KjRw8OPPBA3nnnHQA2bdrEKaecQocOHRgwYADZ2dn5iSzP\nP/7xD5555hmuu+46zjzzTMyMPn360KBBYfPWi1Qd5dmQnKqRI6FevZ3X1asX1qeDkkWkvOv/Pvnk\nEy6//HIWLFhAq1atuPXWW5k5cyZz587ltddeY8GCBbsc8/3333PUUUcxd+5cDjvsMB5++OFCz+3u\nfPDBB9x+++35ieeee+6hRYsWLFiwgBtvvJHZs2fvctx5551Hv379uPPOO3n00Ud32S5SFZXnD8ni\nGDwYxo2DNm3ALPwdNy49jdugZJGvvOv/9ttvP7Kzs/OfT5o0iW7dutGtWzcWLlxYaLKoW7cuxx9/\nPADdu3dnyZIlhZ775JNP3mWf6dOnM3DgQAA6d+5Mx44dy/DdiFRe5f1DsjgGD4YlS2D79vA3XYkC\n1GaRr7zr/+rXr5+/vGjRIu6++24++OADmjRpwpAhQwq9J6FWrVr5y9WrVyc3N7fQc9euXTvpPiKS\nmvL+IZmpVLKIlHf9X6L169fTsGFDGjVqxMqVK3nllVfK/DUOP/xwpkyZAsBHH31UaMlFRHZV1A/G\ndP2QzFQqWUTyim9l2RsqVd26daNDhw4cdNBBtGnThsMPP7zMX+Piiy/mzDPPpEOHDvmPxo0bJz3u\nsMMOY/HixWzcuJGsrCwmTJhAnz59yjw+kUw1cuTON79B+f2QzCSVZg7u7OxsLzj50cKFC2nfvn1M\nEWWW3NxccnNzqVOnDosWLeK4445j0aJF1KhRfr8X9H1IRVXW3eoziZnNcvfsZPupZFFFbNy4kT59\n+pCbm4u7c//995drohBJRaZelAcPzow44qSrRRXRpEkTZs2aFXcYIkUq77GOpHjUwC0iGSGTu6iK\nkoWIZAh1Uc1sShYikhHURTWzKVmISEaI814nSU7JIo169+69yw12d911F+eff/5uj8sbuG/FihUM\nGDCg0H2OPvpoCnYVLuiuu+5ic0IlcL9+/fjuu+9SCX231qxZQ8+ePenatStvv/02N9xwA/vuu68G\nHJRSKe+xjqR4lCzSaNCgQUyePHmndZMnT2bQoEEpHb/PPvvw1FNPlfj1CyaLqVOn0qRJkxKfL8/r\nr7/OIYccwuzZs+nVqxcnnHACH3zwQanPK1KeYx1J8ShZpNGAAQP497//nT/R0ZIlS1ixYgW9evXK\nv++hW7duHHLIITz//PO7HL9kyRIOPvhgALZs2cLAgQNp3749/fv3Z8uWLfn7nX/++fnDm998880A\njBkzhhUrVtC7d2969+4NQNu2bVm7di0Ao0eP5uCDD+bggw/OH958yZIltG/fnnPPPZeOHTty3HHH\n7fQ6AHPmzOHqq6/m+eefp0uXLmzZsoVDDz2Uli1blvGnJyKZpMrcZ3HZZVBg+oZS69IFoutsofbc\nc0969OjBSy+9xEknncTkyZM59dRTMTPq1KnDs88+S6NGjVi7di2HHnooJ554YpFzVd93333Uq1eP\nhQsXMm/ePLp165a/beTIkey5555s27aNPn36MG/ePC655BJGjx7NtGnT2GuvvXY616xZs3jkkUd4\n//33cXd69uzJUUcdxR577MGiRYuYNGkSDzzwAKeeeipPP/00Q4YMSXjPXRgxYgQzZ87k3nvvLd0H\nKCIVRlpLFmbW18w+NbPFZnZtIdvbmNnrZjbPzN40s6wC2xuZWY6ZVdirUmJVVGIVlLtz/fXX06lT\nJ4499liWL1/OqlWrijzPW2+9lX/R7tSpE506dcrfNmXKFLp160bXrl2ZP39+0kECp0+fTv/+/alf\nvz4NGjTg5JNP5u233wagXbt2dOnSBdj9MOhSsWXiZD6S2dJWsjCz6sBY4FdADjDDzF5w98Qr2R3A\no+4+wcyOAUYBZyRs/3/AW2URz+5KAOl00kkncfnll/Phhx+yefNmunfvDsDEiRNZs2YNs2bNombN\nmrRt27bQYcmT+fLLL7njjjuYMWMGe+yxB0OHDi3RefLkDW8OYYjzgtVQUvHpTmkpiXSWLHoAi939\nC3f/CZgMnFRgnw7AG9HytMTtZtYdaA68msYY065Bgwb07t2bs88+e6eG7e+//569996bmjVrMm3a\nNL4qbDKNBEceeSRPPPEEAB9//DHz5s0DwvDm9evXp3HjxqxatYqXXnop/5iGDRuyYcOGXc7Vq1cv\nnnvuOTZv3symTZt49tln6dWrV1m8XakAdKe0lEQ6k0UrYFnC85xoXaK5wMnRcn+goZk1NbNqwN+B\nq9IYX7kZNGgQc+fO3SlZDB48mJkzZ3LIIYfw6KOPctBBB+32HOeffz4bN26kffv23HTTTfkllM6d\nO9O1a1cOOuggTj/99J2GNx8+fDh9+/bNb+DO061bN4YOHUqPHj3o2bMnw4YNo2vXriV+f1dffTVZ\nWVls3ryZrKwsbrnllhKfS9JPd0pLSaRtiHIzGwD0dfdh0fMzgJ7uflHCPvsA9wLtCNVNpwAHA0OA\neu5+m5kNBbITj0s4fjgwHKB169bdC/4615DYmUXfR2Zo27bwWSHbtAndVaVqSXWI8nSWLJYD+yY8\nz4rW5XP3Fe5+srt3BW6I1n0HHAZcZGZLCO0aZ5rZrQVfwN3HuXu2u2c3a9YsTW9DpHLRndJSEuns\nOjsDOMDM2hGSxEDg9MQdzGwv4Bt33w5cBzwM4O6DE/YZSihZ7NKbSkSKL85ZIaXiSluycPdcM7sI\neAWoDjzs7vPNbAQw091fAI4GRpmZE6qhLkxDHEXeuyDlp7LMyFhZaDIfKa5KPa3ql19+ScOGDWna\ntKkSRozcnXXr1rFhwwbatWsXdzgikkDTqgJZWVnk5OSwZs2auEOp8urUqUNWVlbyHUUkI1XqZFGz\nZk39khURKQMaSFBERJKq1CULEZHKYNs2WL0ali8v/NGmDTz4YHpjULIQSaOJE9VFVXZv8+aik0De\nY+VKyM3d+bjq1aFFC2jVCurXT3+cShYiaaIB+6q27dthzZrkiaCwySsbNgxJoFUr6N17x3Lio3nz\nkDDKS6XuOisSJw2rUXlt2ZJaaWDr1p2Pq1ZtR2lgd4+GDcvvvajrrEjMNGBfxbJtG6xbB6tWwddf\nh78Fl1esCIng2293Pb5Bgx0X+6OOKro0UKOCXnUraNgima9168JLFq1bl38sVdX27bsmgKISwerV\nYf+CatcOpYHmzWG//eDIIwtPBI0alf/7K09KFiJpMnLkzm0WoAH7ysL27fDNN0Vf9AsmgG3bdj1H\n7drh4t+8eUjev/hFWM5LConLjRqBBoBQshBJGw3YVzxbt0JOTiiNrVhRdCIoKgHUqrXjIp+VBd27\nF37xb94cGjdWAiguJQuRNNKAfTts2BASwVdfheRZcHnFCijY36ZmzR0X+n32ga5dd1z0CyYCJYD0\nUrIQkVLbvj384i+YABKTQsEuojVrwr77ht5hxx4b/rZpE0pgrVqFBNCkiRJAplCyEJGkfvxxRxVR\nYaWCZcvCPokaNdpx8T/88B3LeUmhRYvQlVQqBiULEeH773dfRfT117tWEbVsGS763bpB//47J4PW\nrUOpQCoPJQuRKmb7dnjzTZgwAWbPDslg/fqd96lVK1zwW7eGvn13LRVkZYUeRVJ1KFmIVBHLloUE\n8cgj8MUXoUH4yCPDDWSJiaB169BorCoiSaRkIVKJ/fQTvPACPPQQvPpqKFX07g0jRsDJJ0PdunFH\nKBWFkoVIJTR/fkgQjz0Ga9eGaqPrr4ezzoKf/Szu6KQiUrIQqSTWr4fJk0OS+OCD0DX1pJPg7LPh\nuOPKd4RSqXyULEQqMHeYPj0kiCefDEOLdOwIo0fDkCHQrFncEUploWQhUgGtXBkaqx9+GBYtCkNa\nDxkSShE9euhGNil7ShYiFcTWrTB1aihFTJ0axkfq1SuMPTVgQPnMliZVl5KFSIb79NOQIB59NAym\n16IF/PGPobH65z+POzqpKtSTWiqFiRPDzHTVqoW/EyfGHVHpbNwY7oc44gg46KDQBnHooaEb7LJl\nMGqUEoWUr7QmCzPra2afmtliM7u2kO1tzOx1M5tnZm+aWVa0vouZvWtm86Ntp6UzTqnY8ua6/uqr\n0OCbN9d1RUsY7vDuuzBsWBhK4+yzQ7fX224L4zI99xyccELFnWlNKra0zcFtZtWBz4BfATnADGCQ\nuy9I2OdJ4F/uPsHMjgHOcvczzOzngLv7IjPbB5gFtHf3QqY2DzQHd9VV0ee6Xr063A/x0EOwcGFo\nezj1VDjnHPjlL9VYLemVCXNw9wAWu/sXUUCTgZOABQn7dACuiJanAc8BuPtneTu4+wozWw00A4pM\nFlJ1VcS5rnNz4ZVXQoJ48cXw/LDD4MEHQ6Jo2DDuCEV2ls5k0QpYlvA8B+hZYJ+5wMnA3UB/oKGZ\nNXX3dXk7mFkPoBbwecEXMLPhwHCA1prYuMqqSHNdf/556O46fnyY7KdZM7j00lDl1KFD3NGJFC3u\nBu6rgKPMbDZwFLAcyJ8w0cxaAo8Rqqd2mUrd3ce5e7a7ZzfT3UdV1siRYW7rRJk01/XmzfD442FM\npv33h1tvDTO+PfNMaIu44w4lCsl86SxZLAf2TXieFa3L5+4rCCULzKwBcEpeu4SZNQL+Ddzg7u+l\nMU6p4DJpruv162HOnDD0d97fBQvCPRL77Rfi+v3vw0xwIhVJOpPFDOAAM2tHSBIDgdMTdzCzvYBv\nolLDdcDD0fpawLPAo+7+VBpjlEqivOe6dg93UeclhLzHF1/s2GfvvUMJ4vjjw5wQRx6pxmqpuNKW\nLNw918wuAl4BqgMPu/t8MxsBzHT3F4CjgVFm5sBbwIXR4acCRwJNzWxotG6ou89JV7wiRdm+HRYv\n3rm0MHt26MWUZ7/9woxx55wDXbqEJNGyZXwxi5S1tHWdLW/qOitl4ccfw/DeeQlhzhyYOzfcJAfh\nHoeOHUMyyHt06hQmEhKpiDKh66xIRvv++5AMEksLCxaEbqwADRqEUsJZZ+0oLXTooOlEpWpSspBK\nL699IbG0ULB9oXnzkAx+85vwt0uXULWkqUVFAiULqVQS2xcSk0Ni+8L+++9oX8irSmrRIr6YRSoC\nJQupFObODdOG/uc/sGlTWFezZmhfSCwtdO4MjRrFG6tIRaRkIRXaunVw441w//2wxx7hTui80kKH\nDlCrVtwRilQOShZSIeXmhgRx443hRriLLoJbbgkJQ0TKnpKFVDhvvgmXXAIffQR9+sBdd8HBB8cd\nlUjlpr4eUmF89RX8z/+EMZY2bICnn4bXXlOiECkPKllIxtu8OUwA9Le/heEyRoyAq66CunXjjkyk\n6lCykIzlHkoPV14ZBgg87bSQNDJx6HGRyk7VUJKRPvoIjjkmVDvtsUfoEjt5shKFSFyULCSjfPNN\n6NnUpQvMmwf33QezZoURW0UkPqqGkoywbRuMGwd/+hN89x1ccAH8+c+w555xRyYioGQhGeCtt0JX\n2LlzQ0+nu++GQw6JOyoRSaRqKInNsmUwcCAcdRR8+y08+SS8/roShUgmUslCyt2WLWHe6VGjQo+n\nW26BP/5x13m0RSRzKFlIuXGHZ58NXWGXLAk9nW6/Hdq0iTsyEUlG1VBSLj7+GI49Fk45BRo2hGnT\nYMoUJQqRiiLlZGFmzc3st9Fj73QGJZXHt9+GxusuXcLcEmPHwocfwtFHxx2ZiBRHSsnCzE4FPgD+\nBzgVeN/MBqQzMKnYtm0Lo8IecEBIEH/4AyxaFLrE1lDlp0iFk+p/2xuAX7j7agAzawb8H/BUugKT\nimv6dLj44jBD3VFHwZgx0KlT3FGJSGmkWg1VLS9RRNYV41ipInJy4PTToVevMCnRP/8Z2iaUKEQq\nvlRLFi+b2SvApOj5acDU9IQkFc0PP8Df/w5//WuYA/umm+Caa9QVVqQySSlZuPsfzexk4Iho1Th3\nfzZ9YUlF4A7PPw9XXAFffhl6Ot1xB7RtG3dkIlLWklYlmVl1M5vm7s+4+xXRI6VEYWZ9zexTM1ts\nZtcWsr2Nmb1uZvPM7E0zy0rY9nszWxQ9fl+8tyXpMnFiSAZmoeTQvz/Urx/uvH7qKSUKkcoqabJw\n923AdjNrXJwTm1l1YCxwPNABGGRmHQrsdgfwqLt3AkYAo6Jj9wRuBnoCPYCbzUyzK8ds4kQ499ww\nYx2E6qeaNcPd18ccE29sIpJeqTZSbwQ+MrOHzGxM3iPJMT2Axe7+hbv/BEwGTiqwTwfgjWh5WsL2\nXwOvufs37v4t8BrQN8VYJU2uvjoM1ZFo69bQRiEilVuqDdzPRI/iaAUsS3ieQygpJJoLnAzcDfQH\nGppZ0yKObVXwBcxsODAcoLVmxUmrF16AFSsK37Z0afnGIiLlL9Vk8RTwQ1QllVfFVLsMXv8q4F4z\nGwq8BSwHtqV6sLuPA8YBZGdnexnEIwXk5sINN4TpTGvVgp9+2nUf5WmRyi/VaqjXgboJz+sSbsrb\nneXAvgnPs6J1+dx9hbuf7O5dCTf+4e7fpXKspN/KldCnT0gU558P//jHrt1h69WDkSPjiU9Eyk+q\nJYs67r4x74m7bzSzZL3oZwAHmFk7woV+IHB64g5mthfwjbtvB64DHo42vQL8NaFR+7hou5STadNg\n0CDYsCE0bJ8efXO1aoWSxtKloUQxciQMHhxvrCKSfqmWLDaZWbe8J2bWHdiym/1x91zgIsKFfyEw\nxd3nm9kIMzsx2u1o4FMz+wxoDoyMjv0G+H+EhDMDGBGtkzTbvj3cXHfssWFK0xkzdiQKCIlhyZKw\n35IlShQiVYW5J6/qN7NfEHozrQAMaAGc5u6z0hte6rKzs33mzJlxh1GhrVsHZ54JU6eGBHH//dCg\nQdxRiUg6mdksd89Otl+qd3DPMLODgAOjVZ+6+9bSBCiZ5YMPwmREX38N990XRok1izsqEckUu00W\nZnaMu78RDfWR6OdmhrsXtzutZBj3MIT4FVfAPvvAf/8L2Ul/Y4hIVZOsZHEU4aa5EwrZ5hT/3gvJ\nIBs2hDuy//lP+O1vYcKE0E4hIlLQbpOFu98c/T2rfMKR8vLxxzBgQJiQaNSocHd2NQ06LyJFSKnN\nwsyaAGcCbROPcfdL0hOWpNNjj4U2iUaNwgCAmuJURJJJ9T6LqcB7wEfA9vSFI+n0ww9hPuwHHggz\n2E2aBC1bxh2ViFQExbkp74q0RiJp9fnnobfT7Nlw3XUwYoTmwhaR1KV6uXjMzM4F/gX8mLdSN8pV\nDM89B0OHhjaJF18MjdkiIsUDKw+lAAASfUlEQVSRapPmT8DtwLvArOihO+Ay3NatYa6J/v3hgAPg\nww+VKESkZFItWVwJ7O/ua9MZjJSd5cth4ECYPh0uuABGj4baZTFOsIhUSakmi8XA5nQGImXn9dfD\nIICbN8MTT4RlEZHSSDVZbALmmNk0dm6zUNfZDJI3COBNN0H79mFO7Pbt445KRCqDVJPFc9FDMtTa\ntXDGGfDyy2Ek2Pvvh/r1445KRCqLVAcSnJC3bGbd3P3D9IUkxfXee3DqqbBqVZigaPhwDQIoImWr\nJAM8PFjmUUiJuMOYMXDkkeGeiXfe0WixIpIeJUkWuhRlgPXr4bTT4NJL4fjjYdYs6N497qhEpLIq\nSbL4c5lHIcXy0UdhGPFnngnzYz/3HOyxR/LjRERKqtjJwt2fA4gmQ5JyNmEC9OwJGzfCG2+Em+5U\n7SQi6VaaQalfLbMoJKktW2DYsDBsx6GHhjGejjwy7qhEpKpINlPemKI2AU3KPhwpzOLFYe6JuXPh\nhhvgz3+G6tXjjkpEqpJkXWfPIgz18WMh23RfcDl45hk466zQ2+nf/4Z+/eKOSESqomTJYgbwsbu/\nU3CDmd2SlogECN1ir702NGD36AFTpkCbNnFHJSJVVbI2iwHAnMI2uHu7sg9H8rz1VkgU55wTlpUo\nRCROyZJFA3fXAIIxuPVW2HtvuOcejRYrIvFLlizyx4Mys6eLe3Iz62tmn5rZYjO7tpDtrc1smpnN\nNrN5ZtYvWl/TzCaY2UdmttDMrivua1dks2eHMZ4uuwzq1o07GhGR5MkisQf/z4pzYjOrDowFjgc6\nAIPMrEOB3f4ETHH3rsBA4H+j9f8D1Hb3Q4DuwB/MrG1xXr8iu/VWaNQozEMhIpIJkiULL2I5FT2A\nxe7+hbv/BEwGTirk/I2i5cbAioT19c2sBlCXMFPf+mK+foW0aFEYWvyCC6Bx47ijEREJkvWG6mxm\n6wkljLrRMtFzd/dGRR9KK2BZwvMcoGeBfW4BXjWzi4H6wLHR+qcIiWUlUA+4vLD5vs1sODAcoHXr\n1kneSsVw++1Qs2YY80lEJFPstmTh7tXdvZG7N3T3GtFy3vPdJYpUDQLGu3sW0A94zMyqEUol24B9\ngHbAlWa2SzWYu49z92x3z27WrFkZhBOvFSvCcB5nnw0tWsQdjYjIDqUZ7iOZ5cC+Cc+zonWJzgGm\nALj7u0AdYC/gdOBld9/q7quB/wLZaYw1I4weDdu2hfGeREQySTqTxQzgADNrZ2a1CA3YLxTYZynQ\nB8DM2hOSxZpo/THR+vrAocAnaYw1dt98E2a3O+00aKc7WEQkw6QtWbh7LnAR8AqwkNDrab6ZjTCz\nE6PdrgTONbO5wCRgqLs7oRdVAzObT0g6j7j7vHTFmgnGjg0jyV67SwdjEZH4Wbg2V3zZ2dk+c+bM\nuMMokU2bwh3ahx0GL74YdzQiUpWY2Sx3T1rNn85qKEnRQw/BunVwXZW69VBEKhIli5j99BPccQf0\n6gW//GXc0YiIFC7ZfRaSZk88AcuWhcZtEZFMpZJFjLZvh7/9DTp3hr59445GRKRoKlnE6Pnn4ZNP\nYNIkzaMtIplNJYuYuMOoUbDffmHKVBGRTKaSRUzeeANmzAhtFTX0LYhIhlPJIia33gotW8Lvfx93\nJCIiySlZxGDmTPi//4PLL9cseCJSMShZxGDUKGjSBM47L+5IRERSo2RRzj75BJ59Fi66CBo2jDsa\nEZHUKFmUs9tugzp14JJL4o5ERCR1ShblaNkyeOwxGDYMKsFcTSJShShZlKO//z38vfLKeOMQESku\nJYtysnYtPPAAnH56GI5cRKQiUbIoJ/fcA5s3wzXXxB2JiEjxKVmUgw0bQrL43e+gQ4e4oxERKT4l\ni3Iwbhx8+62mTBWRikvJIs1+/BFGj4bevaFnz7ijEREpGQ1hl2aPPQYrVsD48XFHIiJScipZpNG2\nbeEmvO7d4dhj445GRKTkVLJIo2eegUWL4MknNbmRiFRsKlmkSd7kRj//OfTvH3c0IiKlo5JFmrz6\nKsyeDQ89BNWrxx2NiEjppLVkYWZ9zexTM1tsZrt0HDWz1mY2zcxmm9k8M+uXsK2Tmb1rZvPN7CMz\nq5POWMvarbdCq1YwZEjckYiIlF7aShZmVh0YC/wKyAFmmNkL7r4gYbc/AVPc/T4z6wBMBdqaWQ3g\nceAMd59rZk2BremKtay99x68+WboMlurVtzRiIiUXjpLFj2Axe7+hbv/BEwGTiqwjwONouXGwIpo\n+ThgnrvPBXD3de6+LY2xlqlRo2DPPeHcc+OORESkbKQzWbQCliU8z4nWJboFGGJmOYRSxcXR+p8D\nbmavmNmHZnZ1YS9gZsPNbKaZzVyzZk3ZRl9CH38ML7wQ5qto0KDk55k4Edq2hWrVwt+JE8sqQhGR\n4ou7N9QgYLy7ZwH9gMfMrBqheuwIYHD0t7+Z9Sl4sLuPc/dsd89uliETRNx2G9SvH2bCK6mJE2H4\ncPjqq9Cr6quvwnMlDBGJSzqTxXJg34TnWdG6ROcAUwDc/V2gDrAXoRTylruvdffNhFJHtzTGWiaW\nLIEnnggX9qZNS36eG24II9Qm2rw5rBcRiUM6k8UM4AAza2dmtYCBwAsF9lkK9AEws/aEZLEGeAU4\nxMzqRY3dRwELyHB33BGqja64onTnWbq0eOtFRNItbcnC3XOBiwgX/oWEXk/zzWyEmZ0Y7XYlcK6Z\nzQUmAUM9+BYYTUg4c4AP3f3f6Yq1LKxeHe6pOPNMyMoq3blaty7eehGRdEvrTXnuPpVQhZS47qaE\n5QXA4UUc+zih+2yFcPfdYYTZP/6x9OcaOTJUZSVWRdWrF9aLiMQh7gbuSmH9ehg7Fk45BQ48sPTn\nGzw4zIHRpk0YU6pNm/B88ODSn1tEpCQ03EcZuO8++P77sp3caPBgJQcRyRwqWZTSDz/AnXfCr34V\nhiIXEamMlCxKafx4WLUKrrsu7khERNJHyaIUcnPDTXg9e8LRR8cdjYhI+qjNohSefBK+/DIMGKjJ\njUSkMlPJooTcwzDkHTrAiScm319EpCJTyaKEpk6FefNgwoRw17aISGWmy1wJjRoV7qgeNCjuSERE\n0k8lixKYPh3++18YMwZq1ow7GhGR9FPJogRGjYJmzeCcc+KORESkfChZFNPcuaG94tJLw3hNIiJV\ngZJFMf3tb2EGvAsuiDsSEZHyo2RRDJ9/Dv/8J5x/PuyxR9zRiIiUHyWLYrj99tCgffnlcUciIlK+\nlCxStHIlPPIIDB0KLVvGHY2ISPlSskjRXXeFsaDKYnIjEZGKRskiBd99F+asOPVU2G+/uKMRESl/\nShYpGDsWNmwo28mNREQqEiWLJDZvDvNrH388dO4cdzQiIvFQskji4YdhzRpNbiQiVZuSxW5s3Rq6\nyx5+OPTqFXc0IiLx0UCCuzFpEixdCv/7v3FHIiISL5UsirB9exja45BDoF+/uKMREYlXWpOFmfU1\ns0/NbLGZ7dKXyMxam9k0M5ttZvPMrF8h2zea2VXpjLMwL74ICxaEHlCaMlVEqrq0JQszqw6MBY4H\nOgCDzKxDgd3+BExx967AQKBghc9o4KV0xVgU9zAMebt24d4KEZGqLp1tFj2Axe7+BYCZTQZOAhYk\n7ONAo2i5MbAib4OZ/Q74EtiUxhgL9Z//wPvvh7aKGmrVERFJazVUK2BZwvOcaF2iW4AhZpYDTAUu\nBjCzBsA1wJ939wJmNtzMZprZzDVr1pRV3IwaBc2bw1lnldkpRUQqtLgbuAcB4909C+gHPGZm1QhJ\n5E5337i7g919nLtnu3t2s2bNyiSgWbPg1VfDyLJ16pTJKUVEKrx0VrIsB/ZNeJ4VrUt0DtAXwN3f\nNbM6wF5AT2CAmd0GNAG2m9kP7n5vGuMF4NZboVEjOO+8dL+SiEjFkc5kMQM4wMzaEZLEQOD0Avss\nBfoA482sPVAHWOPu+bfAmdktwMbySBSffQZPPx16QDVunO5XExGpONJWDeXuucBFwCvAQkKvp/lm\nNsLMTox2uxI418zmApOAoe7u6Yopmdtug9q14bLL4opARCQzWYzX5jKVnZ3tM2fOLPHxOTnws5/B\n8OFwb9rLMCIimcHMZrl7drL94m7gzhh33hnu2r6q3G//ExHJfEoWwLp1cP/9MGgQtG0bdzQiIplH\nyYJQ7bRpE1xzTdyRiIhkpiqfLDZtgjFj4IQT4OCD445GRCQzVfnBLNavhz59wk14IiJSuCqfLFq2\nhClT4o5CRCSzVflqKBERSU7JQkREklKyEBGRpJQsREQkKSULERFJSslCRESSUrIQEZGklCxERCSp\nSjNEuZmtAb4qxSn2AtaWUThlSXEVj+IqHsVVPJUxrjbunnRe6kqTLErLzGamMqZ7eVNcxaO4ikdx\nFU9VjkvVUCIikpSShYiIJKVkscO4uAMoguIqHsVVPIqreKpsXGqzEBGRpFSyEBGRpJQsREQkqSqf\nLMzsYTNbbWYfxx1LHjPb18ymmdkCM5tvZpfGHROAmdUxsw/MbG4U15/jjimRmVU3s9lm9q+4Y8lj\nZkvM7CMzm2NmM+OOJ4+ZNTGzp8zsEzNbaGaHxR0TgJkdGH1WeY/1ZnZZBsR1efRv/mMzm2RmdeKO\nCcDMLo1imp/uz6nKt1mY2ZHARuBRd8+IWbjNrCXQ0t0/NLOGwCzgd+6+IOa4DKjv7hvNrCYwHbjU\n3d+LM648ZnYFkA00cvffxh0PhGQBZLt7Rt3IZWYTgLfd/UEzqwXUc/fv4o4rkZlVB5YDPd29NDfc\nljaOVoR/6x3cfYuZTQGmuvv4uGKK4joYmAz0AH4CXgbOc/fF6Xi9Kl+ycPe3gG/ijiORu6909w+j\n5Q3AQqBVvFGBBxujpzWjR0b82jCzLOA3wINxx5LpzKwxcCTwEIC7/5RpiSLSB/g8zkSRoAZQ18xq\nAPWAFTHHA9AeeN/dN7t7LvAf4OR0vViVTxaZzszaAl2B9+ONJIiqeuYAq4HX3D0j4gLuAq4Gtscd\nSAEOvGpms8xseNzBRNoBa4BHomq7B82sftxBFWIgMCnuINx9OXAHsBRYCXzv7q/GGxUAHwO9zKyp\nmdUD+gH7puvFlCwymJk1AJ4GLnP39XHHA+Du29y9C5AF9IiKwrEys98Cq919VtyxFOIId+8GHA9c\nGFV7xq0G0A24z927ApuAa+MNaWdR1diJwJMZEMsewEmEJLsPUN/MhsQbFbj7QuBvwKuEKqg5wLZ0\nvZ6SRYaK2gSeBia6+zNxx1NQVG0xDegbdyzA4cCJUfvAZOAYM3s83pCC6Fcp7r4aeJZQvxy3HCAn\noVT4FCF5ZJLjgQ/dfVXcgQDHAl+6+xp33wo8A/wy5pgAcPeH3L27ux8JfAt8lq7XUrLIQFFD8kPA\nQncfHXc8ecysmZk1iZbrAr8CPok3KnD369w9y93bEqou3nD32H/5mVn9qIMCUTXPcYSqg1i5+9fA\nMjM7MFrVB4i180QhBpEBVVCRpcChZlYv+r/Zh9COGDsz2zv625rQXvFEul6rRrpOXFGY2STgaGAv\nM8sBbnb3h+KNisOBM4CPovYBgOvdfWqMMQG0BCZEvVSqAVPcPWO6qWag5sCz4fpCDeAJd3853pDy\nXQxMjKp7vgDOijmefFFi/RXwh7hjAXD3983sKeBDIBeYTeYM+/G0mTUFtgIXprOjQpXvOisiIsmp\nGkpERJJSshARkaSULEREJCklCxERSUrJQkREklKyEEnCzLYVGAm1zO52NrO2mTTisUhRqvx9FiIp\n2BINcSJSZalkIVJC0VwVt0XzVXxgZvtH69ua2RtmNs/MXo/ursXMmpvZs9F8IHPNLG/IiOpm9kA0\nJ8Gr0d3xmNkl0Zwm88xsckxvUwRQshBJRd0C1VCnJWz73t0PAe4ljHwLcA8wwd07AROBMdH6McB/\n3L0zYSym+dH6A4Cx7t4R+A44JVp/LdA1Os956XpzIqnQHdwiSZjZRndvUMj6JcAx7v5FNPDj1+7e\n1MzWEiav2hqtX+nue5nZGiDL3X9MOEdbwlDvB0TPrwFquvtfzOxlwsRczwHPJcwlIlLuVLIQKR0v\nYrk4fkxY3saOtsTfAGMJpZAZ0cQ7IrFQshApndMS/r4bLb9DGP0WYDDwdrT8OnA+5E8i1biok5pZ\nNWBfd58GXAM0BnYp3YiUF/1SEUmubsLovwAvu3te99k9zGweoXQwKFp3MWEWuj8SZqTLG9H1UmCc\nmZ1DKEGcT5h5rTDVgcejhGLAmAyd+lSqCLVZiJRQ1GaR7e5r445FJN1UDSUiIkmpZCEiIkmpZCEi\nIkkpWYiISFJKFiIikpSShYiIJKVkISIiSf1/OfCztpJei8IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b24531470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()    \n",
    "\n",
    "f1_values = history_dict['f1']\n",
    "val_f1_values = history_dict['val_f1']\n",
    "\n",
    "plt.plot(epochs, f1_values, 'bo', label='Training f1')\n",
    "plt.plot(epochs, val_f1_values, 'b', label='Validation f1')\n",
    "plt.title('Training and validation batch-level f1-micro')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1-micro')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_prob = parallel_model.predict([metax_train, titlex_train, descx_train, x_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157871, 210)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = y_prob.copy()\n",
    "y_pred[y_pred>=P_THRESHOLD] = 1\n",
    "y_pred[y_pred<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97647641734831159"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#average= None, the scores for each class are returned.\n",
    "#precision_recall_fscore_support(y_train, y_pred, average=None, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#a = precision_recall_fscore_support(y_train, y_pred, average=None, sample_weight=None)\n",
    "# pd.DataFrame(list(a))\n",
    "# f1_byclass = pd.DataFrame((a)[2], columns=['f1'])\n",
    "\n",
    "# support_byclass = pd.DataFrame((a)[3], columns=['support'])\n",
    "\n",
    "# f1_byclass = pd.merge(\n",
    "#     left=f1_byclass, \n",
    "#     right=support_byclass, \n",
    "#     left_index=True,\n",
    "#     right_index=True,\n",
    "#     how='outer', \n",
    "#     validate='one_to_one'\n",
    "# )\n",
    "\n",
    "# f1_byclass['index_col'] = f1_byclass.index\n",
    "\n",
    "# f1_byclass['level2taxon'] = f1_byclass['index_col'].map(labels_index).copy()\n",
    "\n",
    "# print(\"At p_threshold of {}, there were {} out of {} ({})% taxons with auto-tagged content in the training data\"\n",
    "#       .format(P_THRESHOLD, \n",
    "#               f1_byclass.loc[f1_byclass['f1'] > 0].shape[0], \n",
    "#               y_pred.shape[1], \n",
    "#               (f1_byclass.loc[f1_byclass['f1'] > 0].shape[0]/y_pred.shape[1])*100 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# no_auto_content = f1_byclass.loc[f1_byclass['f1'] == 0]\n",
    "# no_auto_content = no_auto_content.set_index('level2taxon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# no_auto_content['support'].sort_values().plot( kind = 'barh', figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classes_predictedto = f1_byclass.loc[f1_byclass['f1'] > 0]\n",
    "# classes_predictedto = classes_predictedto.set_index('level2taxon') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classes_predictedto.plot.scatter(x='support', y='f1', figsize=(20, 10), xticks=np.arange(0, 9700, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classes_predictedto['f1'].sort_values().plot( kind = 'barh', figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.97960107831968923, 0.9733716266332948, 0.97647641734831159, None)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate globally by counting the total true positives, false negatives and false positives.\n",
    "precision_recall_fscore_support(y_train, y_pred, average='micro', sample_weight=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.98888854357204048, 0.98843490957176949, 0.9885800447953631, None)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account\n",
    "precision_recall_fscore_support(y_train, y_pred, average='macro', sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.97958527782352156, 0.9733716266332948, 0.97634379113701197, None)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account\n",
    "precision_recall_fscore_support(y_train, y_pred, average='weighted', sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Development set metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_dev = parallel_model.predict([metax_dev, titlex_dev, descx_dev, x_dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_dev[y_pred_dev>=P_THRESHOLD] = 1\n",
    "y_pred_dev[y_pred_dev<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.        ,  0.98888889,  1.        ,  1.        ,  1.        ,\n",
       "         0.97590361,  1.        ,  0.95547945,  1.        ,  1.        ,\n",
       "         1.        ,  0.88235294,  1.        ,  1.        ,  0.93636364,\n",
       "         1.        ,  0.97115385,  1.        ,  1.        ,  0.91818182,\n",
       "         0.91814294,  0.87172012,  0.93863636,  1.        ,  1.        ,\n",
       "         0.98214286,  1.        ,  1.        ,  0.98484848,  1.        ,\n",
       "         0.95061728,  0.98780488,  1.        ,  0.90291262,  0.88839286,\n",
       "         0.95192308,  0.89780078,  1.        ,  0.94871795,  0.92753623,\n",
       "         1.        ,  0.94478528,  0.984375  ,  1.        ,  0.92134831,\n",
       "         1.        ,  1.        ,  0.97701149,  0.909699  ,  1.        ,\n",
       "         0.99137931,  0.91549296,  1.        ,  1.        ,  0.99462366,\n",
       "         1.        ,  1.        ,  0.96482412,  0.91304348,  0.91944444,\n",
       "         0.99033816,  1.        ,  0.97560976,  0.88235294,  1.        ,\n",
       "         0.91612903,  1.        ,  0.96296296,  0.96153846,  1.        ,\n",
       "         1.        ,  1.        ,  0.90909091,  0.97435897,  0.93048128,\n",
       "         0.89059081,  1.        ,  0.96024096,  0.93650794,  0.98717949,\n",
       "         0.95798319,  0.91720662,  1.        ,  0.87272727,  1.        ,\n",
       "         1.        ,  1.        ,  0.93617021,  1.        ,  0.94708029,\n",
       "         0.91011236,  0.92268041,  0.98275862,  0.94366197,  0.90751445,\n",
       "         0.92111369,  0.92857143,  0.98      ,  0.96470588,  1.        ,\n",
       "         0.9375    ,  1.        ,  0.95238095,  0.94680851,  1.        ,\n",
       "         0.93442623,  0.98734177,  1.        ,  1.        ,  0.99082569,\n",
       "         1.        ,  0.97142857,  0.94178082,  0.92241379,  0.88333333,\n",
       "         0.94736842,  0.93333333,  0.97159091,  0.97643098,  0.99173554,\n",
       "         0.90374332,  1.        ,  0.85294118,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.98148148,  0.89881735,  0.97802198,\n",
       "         0.94857143,  0.94767442,  1.        ,  0.98305085,  1.        ,\n",
       "         0.96341463,  0.98888889,  0.97790055,  0.93413174,  1.        ,\n",
       "         0.93059937,  0.92173913,  0.98305085,  1.        ,  1.        ,\n",
       "         1.        ,  0.94408602,  1.        ,  1.        ,  0.95505618,\n",
       "         0.936     ,  0.9281768 ,  0.98888889,  0.98666667,  0.90697674,\n",
       "         0.93969849,  0.878125  ,  0.95081967,  0.92753623,  0.91735537,\n",
       "         0.94323144,  0.93333333,  0.95705521,  0.97727273,  1.        ,\n",
       "         0.96666667,  1.        ,  0.92253521,  0.95505618,  0.86266094,\n",
       "         0.97142857,  1.        ,  1.        ,  1.        ,  0.95180723,\n",
       "         1.        ,  0.94520548,  0.97777778,  0.96875   ,  0.9       ,\n",
       "         0.94480519,  0.94871795,  0.8976378 ,  1.        ,  0.984375  ,\n",
       "         1.        ,  1.        ,  0.96685083,  0.99230769,  1.        ,\n",
       "         0.87923598,  1.        ,  0.87735849,  1.        ,  1.        ,\n",
       "         0.96078431,  1.        ,  1.        ,  0.95317726,  0.90153846,\n",
       "         0.976     ,  1.        ,  1.        ,  0.87150838,  1.        ,\n",
       "         1.        ,  0.96923077,  1.        ,  1.        ,  0.97641509]),\n",
       " array([ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.93      ,  1.        ,  1.        ,\n",
       "         1.        ,  0.97402597,  1.        ,  1.        ,  0.91964286,\n",
       "         1.        ,  0.96190476,  1.        ,  1.        ,  0.92944785,\n",
       "         0.89838613,  0.83988764,  0.95381062,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.9625    ,  1.        ,  1.        ,  0.92079208,  0.85775862,\n",
       "         0.94285714,  0.88182973,  0.94047619,  0.94871795,  0.84581498,\n",
       "         1.        ,  0.96855346,  1.        ,  1.        ,  0.84536082,\n",
       "         1.        ,  1.        ,  0.96590909,  0.92832765,  1.        ,\n",
       "         1.        ,  0.98484848,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.95049505,  0.984375  ,  0.84223919,\n",
       "         1.        ,  1.        ,  0.98765432,  0.88888889,  1.        ,\n",
       "         0.9044586 ,  1.        ,  1.        ,  0.97402597,  1.        ,\n",
       "         1.        ,  1.        ,  0.79646018,  0.98701299,  0.93048128,\n",
       "         0.88478261,  1.        ,  0.97313797,  0.96721311,  0.98717949,\n",
       "         0.87692308,  0.88780488,  1.        ,  0.64      ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  0.89175258,\n",
       "         0.89338235,  0.93717277,  1.        ,  0.81707317,  0.88202247,\n",
       "         0.94749403,  1.        ,  1.        ,  0.98795181,  1.        ,\n",
       "         0.94736842,  1.        ,  1.        ,  0.98888889,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.91210614,  0.93043478,  1.        ,\n",
       "         0.98630137,  0.93333333,  0.95      ,  0.99315068,  1.        ,\n",
       "         0.81642512,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.87244898,  1.        ,\n",
       "         0.93679458,  0.88108108,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.9516129 ,  0.89142857,  1.        ,\n",
       "         0.9335443 ,  0.92982456,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.93503727,  1.        ,  1.        ,  0.91397849,\n",
       "         0.95510204,  0.82758621,  1.        ,  1.        ,  0.94545455,\n",
       "         0.90338164,  0.85932722,  0.97206704,  1.        ,  0.85384615,\n",
       "         0.9       ,  0.84240688,  0.90697674,  1.        ,  1.        ,\n",
       "         0.98305085,  1.        ,  0.8343949 ,  0.98837209,  0.90950226,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  0.97530864,\n",
       "         1.        ,  0.97183099,  0.94623656,  1.        ,  1.        ,\n",
       "         0.88449848,  1.        ,  0.93442623,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.97765363,  1.        ,  1.        ,\n",
       "         0.85041716,  1.        ,  0.89423077,  1.        ,  1.        ,\n",
       "         0.98      ,  1.        ,  1.        ,  0.94684385,  0.93015873,\n",
       "         0.9037037 ,  1.        ,  1.        ,  0.89655172,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  0.9787234 ]),\n",
       " array([ 1.        ,  0.99441341,  1.        ,  1.        ,  1.        ,\n",
       "         0.98780488,  1.        ,  0.94256757,  1.        ,  1.        ,\n",
       "         1.        ,  0.92592593,  1.        ,  1.        ,  0.92792793,\n",
       "         1.        ,  0.96650718,  1.        ,  1.        ,  0.92378049,\n",
       "         0.9081571 ,  0.85550787,  0.94616266,  1.        ,  1.        ,\n",
       "         0.99099099,  1.        ,  1.        ,  0.99236641,  1.        ,\n",
       "         0.95652174,  0.99386503,  1.        ,  0.91176471,  0.87280702,\n",
       "         0.94736842,  0.88974359,  0.96932515,  0.94871795,  0.88479263,\n",
       "         1.        ,  0.95652174,  0.99212598,  1.        ,  0.88172043,\n",
       "         1.        ,  1.        ,  0.97142857,  0.91891892,  1.        ,\n",
       "         0.995671  ,  0.94890511,  1.        ,  1.        ,  0.99730458,\n",
       "         1.        ,  1.        ,  0.95760599,  0.94736842,  0.87915007,\n",
       "         0.99514563,  1.        ,  0.98159509,  0.88560886,  1.        ,\n",
       "         0.91025641,  1.        ,  0.98113208,  0.96774194,  1.        ,\n",
       "         1.        ,  1.        ,  0.8490566 ,  0.98064516,  0.93048128,\n",
       "         0.88767721,  1.        ,  0.96664645,  0.9516129 ,  0.98717949,\n",
       "         0.91566265,  0.90226629,  1.        ,  0.73846154,  1.        ,\n",
       "         1.        ,  1.        ,  0.96703297,  1.        ,  0.91858407,\n",
       "         0.90166976,  0.92987013,  0.99130435,  0.87581699,  0.89458689,\n",
       "         0.93411765,  0.96296296,  0.98989899,  0.97619048,  1.        ,\n",
       "         0.94240838,  1.        ,  0.97560976,  0.9673913 ,  1.        ,\n",
       "         0.96610169,  0.99363057,  1.        ,  1.        ,  0.99539171,\n",
       "         1.        ,  0.98550725,  0.92670598,  0.92640693,  0.9380531 ,\n",
       "         0.96644295,  0.93333333,  0.96067416,  0.98471986,  0.99585062,\n",
       "         0.85786802,  1.        ,  0.92063492,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.99065421,  0.88543689,  0.98888889,\n",
       "         0.94264622,  0.91316527,  1.        ,  0.99145299,  1.        ,\n",
       "         0.98136646,  0.99441341,  0.96457766,  0.9122807 ,  1.        ,\n",
       "         0.93206951,  0.92576419,  0.99145299,  1.        ,  1.        ,\n",
       "         1.        ,  0.93953986,  1.        ,  1.        ,  0.93406593,\n",
       "         0.94545455,  0.875     ,  0.99441341,  0.99328859,  0.92581602,\n",
       "         0.92118227,  0.86862442,  0.96132597,  0.96240602,  0.88446215,\n",
       "         0.92110874,  0.88554217,  0.93134328,  0.98850575,  1.        ,\n",
       "         0.97478992,  1.        ,  0.87625418,  0.97142857,  0.88546256,\n",
       "         0.98550725,  1.        ,  1.        ,  1.        ,  0.96341463,\n",
       "         1.        ,  0.95833333,  0.96174863,  0.98412698,  0.94736842,\n",
       "         0.91365777,  0.97368421,  0.91566265,  1.        ,  0.99212598,\n",
       "         1.        ,  1.        ,  0.97222222,  0.996139  ,  1.        ,\n",
       "         0.86458649,  1.        ,  0.88571429,  1.        ,  1.        ,\n",
       "         0.97029703,  1.        ,  1.        ,  0.95      ,  0.915625  ,\n",
       "         0.93846154,  1.        ,  1.        ,  0.88385269,  1.        ,\n",
       "         1.        ,  0.984375  ,  1.        ,  1.        ,  0.97756789]),\n",
       " array([  43,   89,   75,   76,  100,   81,   55,  300,   51,   51,   54,\n",
       "          77,  111,  111,  112,   51,  105,   59,   48,  326, 1673,  356,\n",
       "         433,   51,  172,   55,  101,   84,  130,   59,   80,   81,   50,\n",
       "         101,  696,  105,  787,   84,   78,  227,   46,  159,   63,   93,\n",
       "          97,   91,   53,   88,  293,   83,  115,   66,   55,   47,  185,\n",
       "         103,   52,  202,   64,  393,  205,   51,   81,  135,   67,  471,\n",
       "          47,   52,   77,   61,   44,  187,  113,   77,  187,  460,   39,\n",
       "         819,   61,   78,  260, 1435,   51,  300,   48,  174,   58,   88,\n",
       "          71,  582,  544,  191,   57,   82,  178,  419,  104,   98,   83,\n",
       "          69,   95,   47,   80,   90,   68,   57,   78,   53,   46,  108,\n",
       "          65,   68,  603,  115,  106,   73,   60,  180,  292,  120,  207,\n",
       "          50,   58,   72,   58,   49,   55,   53,  784,   89,  886,  185,\n",
       "          58,   58,   70,   79,   89,  186,  175,   77,  316,  114,   58,\n",
       "          59,   95,   61,  939,   53,   41,   93,  245,  203,   89,   74,\n",
       "         165,  207,  327,  179,   64,  130,  240,  349,  172,   43,   48,\n",
       "          59,   54,  314,   86,  221,   68,   60,   85,   94,   81,   89,\n",
       "          71,  186,   62,   81,  987,   74,  122,   67,   63,   66,   58,\n",
       "         179,  129,   57, 1678,   57,  104,   50,   67,  100,  106,   56,\n",
       "         301,  315,  135,   76,   79,  348,   64,  246,   63,   68,   69,\n",
       "         423]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average= None, the scores for each class are returned.\n",
    "precision_recall_fscore_support(y_dev, y_pred_dev, average=None, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.94139453279755503, 0.92784626540971715, 0.93457130014608381, None)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate globally by counting the total true positives, false negatives and false positives.\n",
    "precision_recall_fscore_support(y_dev, y_pred_dev, average='micro', sample_weight=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.96504786585498414, 0.96512688462959417, 0.96467775967131664, None)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account\n",
    "precision_recall_fscore_support(y_dev, y_pred_dev, average='macro', sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.94103147684194877, 0.92784626540971715, 0.93394404096026984, None)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account\n",
    "precision_recall_fscore_support(y_dev, y_pred_dev, average='weighted', sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag unlabelled content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_predictions(new_texts, df, level1taxon=False):\n",
    "    #process data for model input\n",
    "    \n",
    "    new_sequences = tokenizer.texts_to_sequences(new_texts) #yield one sequence per input text\n",
    "\n",
    "    new_word_index = tokenizer.word_index\n",
    "    print('Found %s unique tokens.' % len(new_word_index))\n",
    "\n",
    "    x_new = pad_sequences(new_sequences, maxlen= MAX_SEQUENCE_LENGTH) #MAX_SEQUENCE_LENGTH\n",
    "    \n",
    "    print('Shape of untagged tensor:', x_new.shape)\n",
    "    \n",
    "    #predict tag for untagged data\n",
    "    y_pred_new = parallel_model.predict(x_new)\n",
    "    \n",
    "    #get model output into pandas & get a column to track index for later merge\n",
    "    y_pred_new = pd.DataFrame(y_pred_new)\n",
    "    y_pred_new['index_col'] = y_pred_new.index\n",
    "    \n",
    "    #Make long by taxon so easier to filter rows and examine effect of p_threshold\n",
    "    y_pred_new = pd.melt(y_pred_new, id_vars=['index_col'],\n",
    "                             var_name='level2taxon_code', value_name='probability')\n",
    "    \n",
    "    #get taxon names\n",
    "    y_pred_new['level2taxon'] = y_pred_new['level2taxon_code'].map(labels_index)\n",
    "    \n",
    "    if level1taxon==False:\n",
    "        #get the info about the content\n",
    "        new_info = df[[ 'base_path', 'content_id', 'title', 'description', \n",
    "                   'document_type', 'publishing_app', 'locale']]\n",
    "    else:\n",
    "        new_info = df[[ 'base_path', 'content_id', 'title', 'description', \n",
    "                   'document_type', 'publishing_app', 'locale', 'level1taxon']]\n",
    "    \n",
    "    \n",
    "    #merge content info with taxon prediction\n",
    "    pred_new = pd.merge(\n",
    "    left=new_info, \n",
    "    right=y_pred_new, \n",
    "    left_index=True,\n",
    "    right_on='index_col',\n",
    "    how='outer'\n",
    "    )\n",
    "    \n",
    "    #drop the cols needed for mergingin and naming\n",
    "    pred_new.drop(['index_col'], axis=1, inplace = True)\n",
    "    \n",
    "    #keep only rows where prob of taxon > 0.5\n",
    "    \n",
    "    \n",
    "    return pred_new #.loc[pred_new['probability'] > P_THRESHOLD] #only return rows/samples where probability is hihger than threshold\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Untagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read in untagged content\n",
    "untagged_raw = pd.read_csv(os.path.join(DATADIR, 'untagged_content.csv.gz'), dtype=object, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_published_at</th>\n",
       "      <th>base_path</th>\n",
       "      <th>content_id</th>\n",
       "      <th>description</th>\n",
       "      <th>details</th>\n",
       "      <th>document_type</th>\n",
       "      <th>first_published_at.1</th>\n",
       "      <th>locale</th>\n",
       "      <th>primary_publishing_organisation</th>\n",
       "      <th>publishing_app</th>\n",
       "      <th>taxons</th>\n",
       "      <th>title</th>\n",
       "      <th>document_type_gp</th>\n",
       "      <th>body</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-08-02 14:48:42</td>\n",
       "      <td>/recruit-apprentice</td>\n",
       "      <td>61ad70a2-3210-4dbc-a103-4332b0e7b733</td>\n",
       "      <td>advertise apprenticeship vacancies and manage ...</td>\n",
       "      <td>{'transaction_start_link': 'https://www.recrui...</td>\n",
       "      <td>transaction</td>\n",
       "      <td>2016-08-02 14:48:42</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>publisher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>recruit an apprentice</td>\n",
       "      <td>service</td>\n",
       "      <td></td>\n",
       "      <td>recruit an apprentice advertise apprenticeship...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-02-29 09:24:10</td>\n",
       "      <td>/simplified-expenses-checker</td>\n",
       "      <td>8ad76560-8a27-42ee-9a99-8aaa8f0109a5</td>\n",
       "      <td>find out if simplified expenses suits your bus...</td>\n",
       "      <td>{'transaction_start_link': '/simplified-expens...</td>\n",
       "      <td>transaction</td>\n",
       "      <td>2016-02-29 09:24:10</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>smartanswers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>check if simplified expenses could save your b...</td>\n",
       "      <td>service</td>\n",
       "      <td></td>\n",
       "      <td>check if simplified expenses could save your b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-04 09:45:48</td>\n",
       "      <td>/apply-for-bankruptcy</td>\n",
       "      <td>92ac7166-6cb3-426e-b72a-c8d12236abdf</td>\n",
       "      <td>how to apply for bankruptcy online: how much i...</td>\n",
       "      <td>{'transaction_start_link': 'https://apply-for-...</td>\n",
       "      <td>transaction</td>\n",
       "      <td>2016-04-04 09:45:48</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>publisher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apply for bankruptcy</td>\n",
       "      <td>service</td>\n",
       "      <td></td>\n",
       "      <td>apply for bankruptcy how to apply for bankrupt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-05-08 08:00:00</td>\n",
       "      <td>/apply-funding-innovation</td>\n",
       "      <td>e750146a-77f2-421f-bae7-599c19f9b139</td>\n",
       "      <td>use this service to apply for government-backe...</td>\n",
       "      <td>{'transaction_start_link': 'https://apply-for-...</td>\n",
       "      <td>transaction</td>\n",
       "      <td>2017-05-08 08:00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>publisher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apply for innovation funding</td>\n",
       "      <td>service</td>\n",
       "      <td></td>\n",
       "      <td>apply for innovation funding use this service ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-06-14 09:00:01</td>\n",
       "      <td>/check-house-price-trends</td>\n",
       "      <td>76e82c22-cfff-4875-9e27-e8c6d70f8928</td>\n",
       "      <td>find out property price trends in the uk from ...</td>\n",
       "      <td>{'transaction_start_link': 'http://landregistr...</td>\n",
       "      <td>transaction</td>\n",
       "      <td>2016-06-14 09:00:01</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>publisher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>check uk property price trends</td>\n",
       "      <td>service</td>\n",
       "      <td></td>\n",
       "      <td>check uk property price trends find out proper...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    first_published_at                     base_path  \\\n",
       "0  2016-08-02 14:48:42           /recruit-apprentice   \n",
       "1  2016-02-29 09:24:10  /simplified-expenses-checker   \n",
       "2  2016-04-04 09:45:48         /apply-for-bankruptcy   \n",
       "3  2017-05-08 08:00:00     /apply-funding-innovation   \n",
       "4  2016-06-14 09:00:01     /check-house-price-trends   \n",
       "\n",
       "                             content_id  \\\n",
       "0  61ad70a2-3210-4dbc-a103-4332b0e7b733   \n",
       "1  8ad76560-8a27-42ee-9a99-8aaa8f0109a5   \n",
       "2  92ac7166-6cb3-426e-b72a-c8d12236abdf   \n",
       "3  e750146a-77f2-421f-bae7-599c19f9b139   \n",
       "4  76e82c22-cfff-4875-9e27-e8c6d70f8928   \n",
       "\n",
       "                                         description  \\\n",
       "0  advertise apprenticeship vacancies and manage ...   \n",
       "1  find out if simplified expenses suits your bus...   \n",
       "2  how to apply for bankruptcy online: how much i...   \n",
       "3  use this service to apply for government-backe...   \n",
       "4  find out property price trends in the uk from ...   \n",
       "\n",
       "                                             details document_type  \\\n",
       "0  {'transaction_start_link': 'https://www.recrui...   transaction   \n",
       "1  {'transaction_start_link': '/simplified-expens...   transaction   \n",
       "2  {'transaction_start_link': 'https://apply-for-...   transaction   \n",
       "3  {'transaction_start_link': 'https://apply-for-...   transaction   \n",
       "4  {'transaction_start_link': 'http://landregistr...   transaction   \n",
       "\n",
       "  first_published_at.1 locale primary_publishing_organisation publishing_app  \\\n",
       "0  2016-08-02 14:48:42     en                             NaN      publisher   \n",
       "1  2016-02-29 09:24:10     en                             NaN   smartanswers   \n",
       "2  2016-04-04 09:45:48     en                             NaN      publisher   \n",
       "3  2017-05-08 08:00:00     en                             NaN      publisher   \n",
       "4  2016-06-14 09:00:01     en                             NaN      publisher   \n",
       "\n",
       "  taxons                                              title document_type_gp  \\\n",
       "0    NaN                              recruit an apprentice          service   \n",
       "1    NaN  check if simplified expenses could save your b...          service   \n",
       "2    NaN                               apply for bankruptcy          service   \n",
       "3    NaN                       apply for innovation funding          service   \n",
       "4    NaN                     check uk property price trends          service   \n",
       "\n",
       "  body                                      combined_text  \n",
       "0       recruit an apprentice advertise apprenticeship...  \n",
       "1       check if simplified expenses could save your b...  \n",
       "2       apply for bankruptcy how to apply for bankrupt...  \n",
       "3       apply for innovation funding use this service ...  \n",
       "4       check uk property price trends find out proper...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untagged_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_texts = untagged_raw['combined_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_untagged = get_predictions(new_texts, untagged_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data is long by taxon\n",
    "print('Number of unique content items: {}'.format(pred_untagged.content_id.nunique()))\n",
    "print('Number of content items tagged to taxons with more than p_threshold: {}'.format(pred_untagged.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_untagged.loc[(pred_untagged['probability'] > 0.65) & (pred_untagged['probability'] < 0.85)].sort_values(by='probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#write to csv\n",
    "pred_untagged.to_csv(os.path.join(DATADIR, 'predictions_for_untagged_data_trainingdatatok.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply tokenizer to our text data\n",
    "tokenizer.fit_on_texts(new_texts)\n",
    "\n",
    "pred_untagged_refit_tok = get_predictions(new_texts, untagged_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#write to csv\n",
    "pred_untagged_refit_tok.to_csv(os.path.join(DATADIR, 'predictions_for_untagged_data_refittok.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New data (untagged + old taxons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old_taxons data has no combined text. This needs fixing in the data pipeline before being able to use these data for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read in untagged content\n",
    "new_raw = pd.read_csv(os.path.join(DATADIR, 'new_content.csv'), dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(new_raw['combined_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_raw['combined_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(new_raw[new_raw['combined_text'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(new_raw.loc[(new_raw['combined_text'].isna()) & (new_raw['untagged_type'] == 'old_taxons')]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_raw[new_raw.untagged_type == 'old_taxons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make a copy so you can edit data without needed to read in each time\n",
    "new_df = new_raw.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_new = get_predictions(new_df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#keep only rows where prob of taxon > 0.5\n",
    "pred_new = pred_new.loc[pred_new['probability'] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#write to csv\n",
    "pred_new.to_csv(os.path.join(DATADIR, 'predictions_for_new_data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelled at level1only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labelled_level1 = pd.read_csv(os.path.join(DATADIR, 'labelled_level1.csv'), dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "level1_texts = labelled_level1['combined_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reset tokenizer to training data texts\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_labelled_level1 = get_predictions(level1_texts, labelled_level1, level1taxon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_labelled_level1.sort_values(by='probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#write to csv\n",
    "pred_labelled_level1.to_csv(os.path.join(DATADIR, 'predictions_for_level1only.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='cnn.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "keep_output": true,
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
