{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional NN to classify govuk content to level2 taxons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on:\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load requirements and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.utils import to_categorical, layer_utils, plot_model\n",
    "\n",
    "from keras.layers import (Embedding, Input, Dense, Dropout, \n",
    "                          Activation, Conv1D, MaxPooling1D, Flatten, concatenate, Reshape)\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.callbacks import TensorBoard, Callback, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score \n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import functools\n",
    "\n",
    "import h5py\n",
    "\n",
    "from scipy import sparse\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environmental vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATADIR = os.getenv('DATADIR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print data version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm running on data extracted from content store on /data/2018-03-27\n"
     ]
    }
   ],
   "source": [
    "print('algorithm running on data extracted from content store on {}'.format(DATADIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuition for POS_RATIO is that it penalises the prediction of zero for everything, which is attractive to the model because the multilabel y matrix is super sparse. \n",
    "\n",
    "Increasing POS_RATIO should penalise predicting zeros more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MAX_NB_WORDS\n",
    "MAX_SEQUENCE_LENGTH =1000\n",
    "EMBEDDING_DIM = 100 # keras embedding layer output_dim = Dimension of the dense embedding\n",
    "P_THRESHOLD = 0.5 #Threshold for probability of being assigned to class\n",
    "POS_RATIO = 0.5 #ratio of positive to negative for each class in weighted binary cross entropy loss function\n",
    "NUM_WORDS=20000 #keras tokenizer num_words: None or int. Maximum number of words to work with \n",
    "#(if set, tokenization will be restricted to the top num_words most common words in the dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = np.load(os.path.join(DATADIR, 'train_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'meta', 'title', 'desc', 'y', 'content_id']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (176708, 1000)\n",
      "meta_train.shape = (176708, 521)\n",
      "title_train.shape = (176708, 10000)\n",
      "desc_train.shape = (176708, 10000)\n",
      "y_train.shape = (176708, 216)\n"
     ]
    }
   ],
   "source": [
    "x_train = train['x']\n",
    "meta_train = train['meta'].all().todense()\n",
    "title_train = train['title'].all().todense()\n",
    "desc_train = train['desc'].all().todense()\n",
    "y_train = train['y'].all().todense()\n",
    "\n",
    "print('x_train.shape = {}'.format(x_train.shape))\n",
    "print('meta_train.shape = {}'.format(meta_train.shape))\n",
    "print('title_train.shape = {}'.format(title_train.shape))\n",
    "print('desc_train.shape = {}'.format(desc_train.shape))\n",
    "print('y_train.shape = {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dev = np.load(os.path.join(DATADIR, 'dev_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_dev.shape = (12776, 1000)\n",
      "meta_dev.shape = (12776, 521)\n",
      "title_dev.shape = (12776, 10000)\n",
      "desc_dev.shape = (12776, 10000)\n",
      "y_dev.shape = (12776, 216)\n"
     ]
    }
   ],
   "source": [
    "x_dev = dev['x']\n",
    "meta_dev = dev['meta'].all().todense()\n",
    "title_dev = dev['title'].all().todense()\n",
    "desc_dev = dev['desc'].all().todense()\n",
    "y_dev = dev['y'].all().todense()\n",
    "\n",
    "print('x_dev.shape = {}'.format(x_dev.shape))\n",
    "print('meta_dev.shape = {}'.format(meta_dev.shape))\n",
    "print('title_dev.shape = {}'.format(title_dev.shape))\n",
    "print('desc_dev.shape = {}'.format(desc_dev.shape))\n",
    "print('y_dev.shape = {}'.format(y_dev.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = np.load(os.path.join(DATADIR, 'test_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test.shape = (12777, 1000)\n",
      "meta_test.shape = (12777, 521)\n",
      "title_test.shape = (12777, 10000)\n",
      "desc_test.shape = (12777, 10000)\n",
      "y_test.shape = (12777, 216)\n"
     ]
    }
   ],
   "source": [
    "x_test = test['x']\n",
    "meta_test = test['meta'].all().todense()\n",
    "title_test = test['title'].all().todense()\n",
    "desc_test = test['desc'].all().todense()\n",
    "y_test = test['y'].all().todense()\n",
    "\n",
    "print('x_test.shape = {}'.format(x_test.shape))\n",
    "print('meta_test.shape = {}'.format(meta_test.shape))\n",
    "print('title_test.shape = {}'.format(title_test.shape))\n",
    "print('desc_test.shape = {}'.format(desc_test.shape))\n",
    "print('y_test.shape = {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### previous shapes in old data \n",
    "Shape of x_train: (150870, 1000)\n",
    "Shape of metax_train: (150870, 436)\n",
    "Shape of titlex_train: (150870, 10000)\n",
    "Shape of descx_train: (150870, 10000)\n",
    "Shape of y_train: (150870, 210)\n",
    "\n",
    "Shape of x_dev: (9234, 1000)\n",
    "Shape of meta_dev: (9234, 436)\n",
    "Shape of titlex_dev: (9234, 10000)\n",
    "Shape of descx_dev: (9234, 10000)\n",
    "Shape of y_dev: (9234, 210)\n",
    "\n",
    "Shape of x_test: (9234, 1000)\n",
    "Shape of metax_test: (9234, 436)\n",
    "Shape of titlex_test: (9234, 10000)\n",
    "Shape of descx_test: (9234, 10000)\n",
    "Shape of y_test: (9234, 210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing the Embedding layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "def load_tokenizer_from_file(filename):\n",
    "    \n",
    "    tokenizer = Tokenizer()\n",
    "\n",
    "    with open(filename, 'r') as infile:\n",
    "        tokenizer_data = json.load(infile)\n",
    "\n",
    "    tokenizer.word_counts = OrderedDict(tokenizer_data['word_counts'])\n",
    "    tokenizer.word_docs = tokenizer_data['word_docs']\n",
    "    tokenizer.word_index = tokenizer_data['word_index']\n",
    "    tokenizer.document_count = tokenizer_data['document_count']\n",
    "    tokenizer.index_docs = tokenizer_data['index_docs']\n",
    "\n",
    "    return tokenizer\n",
    "\n",
    "tokenizer_combined_text = load_tokenizer_from_file(os.path.join(DATADIR, \"combined_text_tokenizer.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(tokenizer_combined_text.word_index) + 1, \n",
    "                            EMBEDDING_DIM, \n",
    "                            input_length=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Embedding layer should be fed sequences of integers, i.e. a 2D input of shape (samples, indices). These input sequences should be padded so that they all have the same length in a batch of input data (although an Embedding layer is capable of processing sequence of heterogenous length, if you don't pass an explicit input_length argument to the layer).\n",
    "\n",
    "All that the Embedding layer does is to map the integer inputs to the vectors found at the corresponding index in the embedding matrix, i.e. the sequence [1, 2] would be converted to [embeddings[1], embeddings[2]]. This means that the output of the Embedding layer will be a 3D tensor of shape (samples, sequence_length, embedding_dim)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate class weights for unbalanced datasets.\n",
    "paramter to model.fit = __class_weight__: Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
    "\n",
    "Implement class_weight from sklearn:\n",
    "\n",
    "- Import the module \n",
    "\n",
    "`from sklearn.utils import class_weight`\n",
    "- calculate the class weight, If ‘balanced’, class weights will be given by n_samples / (n_classes * np.bincount(y)):\n",
    "\n",
    "`class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)`\n",
    "\n",
    "- change it to a dict in order to work with Keras.\n",
    "\n",
    "`class_weight_dict = dict(enumerate(class_weight))`\n",
    "\n",
    "- Add to model fitting\n",
    "\n",
    "`model.fit(X_train, y_train, class_weight=class_weight)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "# class_weight_dict = dict(enumerate(class_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.00756\n",
      "8.01512\n"
     ]
    }
   ],
   "source": [
    "class WeightedBinaryCrossEntropy(object):\n",
    "\n",
    "    def __init__(self, pos_ratio):\n",
    "        neg_ratio = 1. - pos_ratio\n",
    "        #self.pos_ratio = tf.constant(pos_ratio, tf.float32)\n",
    "        self.pos_ratio = pos_ratio\n",
    "        #self.weights = tf.constant(neg_ratio / pos_ratio, tf.float32)\n",
    "        self.weights = neg_ratio / pos_ratio\n",
    "        self.__name__ = \"weighted_binary_crossentropy({0})\".format(pos_ratio)\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        return self.weighted_binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "    def weighted_binary_crossentropy(self, y_true, y_pred):\n",
    "            # Transform to logits\n",
    "            epsilon = tf.convert_to_tensor(K.common._EPSILON, y_pred.dtype.base_dtype)\n",
    "            y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
    "            y_pred = tf.log(y_pred / (1 - y_pred))\n",
    "\n",
    "            cost = tf.nn.weighted_cross_entropy_with_logits(y_true, y_pred, self.weights)\n",
    "            return K.mean(cost * self.pos_ratio, axis=-1)\n",
    "    \n",
    "y_true_arr = np.array([0,1,0,1], dtype=\"float32\")\n",
    "y_pred_arr = np.array([0,0,1,1], dtype=\"float32\")\n",
    "y_true = tf.constant(y_true_arr)\n",
    "y_pred = tf.constant(y_pred_arr)\n",
    "\n",
    "with tf.Session().as_default(): \n",
    "    print(WeightedBinaryCrossEntropy(0.5)(y_true, y_pred).eval())\n",
    "    print(binary_crossentropy(y_true, y_pred).eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### difficulty getting global precision/recall metrics . CAUTION interpreting monitoring metrics\n",
    "fcholltet: \"Basically these are all global metrics that were approximated\n",
    "batch-wise, which is more misleading than helpful. This was mentioned in\n",
    "the docs but it's much cleaner to remove them altogether. It was a mistake\n",
    "to merge them in the first place.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    \"\"\"Use Recall  and precision metrics to calculate harmonic mean (F1 score).\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1 = 2*((precision*recall)/(precision+recall))\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a 1D convnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NB_CLASSES = y_train.shape[1]\n",
    "NB_METAVARS = meta_train.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='wordindex') #MAX_SEQUENCE_LENGTH\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Dropout(0.2, name = 'dropout_embedded')(embedded_sequences)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv0')(x)\n",
    "\n",
    "x = MaxPooling1D(5, name = 'max_pool0')(x)\n",
    "\n",
    "x = Dropout(0.5, name = 'dropout0')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv1')(x)\n",
    "\n",
    "x = MaxPooling1D(5 , name = 'max_pool1')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv2')(x)\n",
    "\n",
    "x = MaxPooling1D(35, name = 'global_max_pool')(x)  # global max pooling\n",
    "\n",
    "x = Flatten()(x) #reduce dimensions from 3 to 2; convert to vector + FULLYCONNECTED\n",
    "\n",
    "meta_input = Input(shape=(NB_METAVARS,), name='meta')\n",
    "meta_hidden = Dense(128, activation='relu', name = 'hidden_meta')(meta_input)\n",
    "meta_hidden = Dropout(0.2, name = 'dropout_meta')(meta_hidden)\n",
    "\n",
    "\n",
    "title_input = Input(shape=(title_train.shape[1],), name='titles')\n",
    "title_hidden = Dense(128, activation='relu', name = 'hidden_title')(title_input)\n",
    "title_hidden = Dropout(0.2, name = 'dropout_title')(title_hidden)\n",
    "\n",
    "desc_input = Input(shape=(desc_train.shape[1],), name='descs')\n",
    "desc_hidden = Dense(128, activation='relu', name = 'hidden_desc')(desc_input)\n",
    "desc_hidden = Dropout(0.2, name = 'dropout_desc')(desc_hidden)\n",
    "\n",
    "concatenated = concatenate([meta_hidden, title_hidden, desc_hidden, x])\n",
    "\n",
    "x = Dense(400, activation='relu', name = 'fully_connected0')(concatenated)\n",
    "\n",
    "x = Dropout(0.2, name = 'dropout1')(x)\n",
    "\n",
    "x = Dense(NB_CLASSES, activation='sigmoid', name = 'fully_connected1')(x)\n",
    "\n",
    "# # The Model class turns an input tensor and output tensor into a model\n",
    "# This creates Keras model instance, will use this instance to train/test the model.\n",
    "model = Model(inputs=[meta_input, title_input, desc_input, sequence_input], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "wordindex (InputLayer)          (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 100)    34647400    wordindex[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_embedded (Dropout)      (None, 1000, 100)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv1D)                  (None, 996, 128)     64128       dropout_embedded[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pool0 (MaxPooling1D)        (None, 199, 128)     0           conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout0 (Dropout)              (None, 199, 128)     0           max_pool0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv1D)                  (None, 195, 128)     82048       dropout0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pool1 (MaxPooling1D)        (None, 39, 128)      0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "meta (InputLayer)               (None, 521)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "titles (InputLayer)             (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "descs (InputLayer)              (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv1D)                  (None, 35, 128)      82048       max_pool1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hidden_meta (Dense)             (None, 128)          66816       meta[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "hidden_title (Dense)            (None, 128)          1280128     titles[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "hidden_desc (Dense)             (None, 128)          1280128     descs[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pool (MaxPooling1D)  (None, 1, 128)       0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_meta (Dropout)          (None, 128)          0           hidden_meta[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_title (Dropout)         (None, 128)          0           hidden_title[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_desc (Dropout)          (None, 128)          0           hidden_desc[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           global_max_pool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           dropout_meta[0][0]               \n",
      "                                                                 dropout_title[0][0]              \n",
      "                                                                 dropout_desc[0][0]               \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fully_connected0 (Dense)        (None, 400)          205200      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 400)          0           fully_connected0[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fully_connected1 (Dense)        (None, 216)          86616       dropout1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 37,794,512\n",
      "Trainable params: 37,794,512\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard callbacks /metrics /monitor training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **Size of these files is killing storage during training. Is it histograms?**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tb = TensorBoard(log_dir='./learn_embedding_logs', histogram_freq=1, write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = os.path.join(DATADIR, 'model_checkpoint.hdf5')\n",
    "\n",
    "cp = ModelCheckpoint(\n",
    "                     filepath = CHECKPOINT_PATH, \n",
    "                     monitor='val_loss', \n",
    "                     verbose=0, \n",
    "                     save_best_only=False, \n",
    "                     save_weights_only=False, \n",
    "                     mode='auto', \n",
    "                     period=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "#model.fit(x, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 & 3. Train & compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 176708 samples, validate on 12776 samples\n",
      "Epoch 1/10\n",
      "176708/176708 [==============================] - 182s 1ms/step - loss: 0.0087 - binary_accuracy: 0.9951 - f1: nan - val_loss: 0.0040 - val_binary_accuracy: 0.9973 - val_f1: 0.7732\n",
      "Epoch 2/10\n",
      "176708/176708 [==============================] - 179s 1ms/step - loss: 0.0030 - binary_accuracy: 0.9980 - f1: 0.8663 - val_loss: 0.0035 - val_binary_accuracy: 0.9976 - val_f1: 0.8048\n",
      "Epoch 3/10\n",
      "176708/176708 [==============================] - 179s 1ms/step - loss: 0.0023 - binary_accuracy: 0.9985 - f1: 0.9014 - val_loss: 0.0034 - val_binary_accuracy: 0.9977 - val_f1: 0.8216\n",
      "Epoch 4/10\n",
      "176708/176708 [==============================] - 179s 1ms/step - loss: 0.0019 - binary_accuracy: 0.9987 - f1: 0.9183 - val_loss: 0.0034 - val_binary_accuracy: 0.9978 - val_f1: 0.8270\n",
      "Epoch 5/10\n",
      "176708/176708 [==============================] - 179s 1ms/step - loss: 0.0017 - binary_accuracy: 0.9989 - f1: 0.9282 - val_loss: 0.0034 - val_binary_accuracy: 0.9978 - val_f1: 0.8287\n",
      "Epoch 6/10\n",
      "176708/176708 [==============================] - 179s 1ms/step - loss: 0.0016 - binary_accuracy: 0.9990 - f1: 0.9345 - val_loss: 0.0036 - val_binary_accuracy: 0.9979 - val_f1: 0.8320\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=WeightedBinaryCrossEntropy(POS_RATIO),\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['binary_accuracy', f1])\n",
    "\n",
    "# This `fit` call will be distributed on 8 GPUs.\n",
    "# Since the batch size is 256, each GPU will process 32 samples.\n",
    "history = model.fit(\n",
    "    {'meta': meta_train, 'titles': title_train, 'descs': desc_train, 'wordindex': x_train},\n",
    "    y_train, \n",
    "    validation_data=([meta_dev, title_dev, desc_dev, x_dev], y_dev), \n",
    "    epochs=10, batch_size=128, callbacks=[early_stopping]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_binary_accuracy', 'val_f1', 'loss', 'binary_accuracy', 'f1'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrCAOJGZmVhAHEjMzK4gDiZmZFeT/A6YXxaDuzgj3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efe439931d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(range(len(loss_values)), loss_values, 'bo', label='Training loss')           \n",
    "plt.plot(range(len(val_loss_values)), val_loss_values, 'b', label='Validation loss')      \n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMDOzvP4/AeYzj5MvaKsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efe434d1dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()    \n",
    "\n",
    "f1_values = history_dict['f1']\n",
    "val_f1_values = history_dict['val_f1']\n",
    "\n",
    "plt.plot(range(len(f1_values)), f1_values, 'bo', label='Training f1')\n",
    "plt.plot(range(len(val_f1_values)), val_f1_values, 'b', label='Validation f1')\n",
    "plt.title('Training and validation batch-level f1-micro')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1-micro')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_file(array,name):\n",
    "    df = pd.DataFrame(data = array.tolist(),columns=[i for i in range(1,y_train.shape[1]+1)])\n",
    "    df.to_csv(os.path.join(DATADIR, name+'.csv.gz'),compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_1123_2703_'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_run = time.strftime(\"_%H%M_%d%m_\")\n",
    "date_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict([meta_train, title_train, desc_train, x_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_prob,\"train_results\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_prob.copy()\n",
    "y_pred[y_pred>=P_THRESHOLD] = 1\n",
    "y_pred[y_pred<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro: (0.97059848964380369, 0.94727783283779321, 0.95879637602047729, None)\n",
      "macro: (0.97998888111518812, 0.96946676095233908, 0.97430481203925567, None)\n",
      "weightedmacro: (0.97032221613472014, 0.94727783283779321, 0.9581386729187622, None)\n"
     ]
    }
   ],
   "source": [
    "print('micro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='micro', sample_weight=None)))\n",
    "print('macro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='macro', sample_weight=None)))\n",
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='weighted', sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_dev = model.predict([meta_dev, title_dev, desc_dev, x_dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_prob_dev,\"dev_results\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dev = y_prob_dev.copy()\n",
    "y_pred_dev[y_pred_dev>=P_THRESHOLD] = 1\n",
    "y_pred_dev[y_pred_dev<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro: (0.86086904261073383, 0.80485475080069679, 0.83192008363340697, None)\n",
      "macro: (0.76155486712440679, 0.79048635688826763, 0.76875357340137096, None)\n",
      "weightedmacro: (0.8613058273851496, 0.80485475080069679, 0.82872027510771362, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('micro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='micro', sample_weight=None)))\n",
    "print('macro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='macro', sample_weight=None)))\n",
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='weighted', sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weightedmacro: (array([ 1.        ,  0.875     ,  0.92857143,  0.71428571,  1.        ,\n",
      "        0.75609756,  0.71428571,  0.76237624,  0.        ,  0.        ,\n",
      "        0.99415205,  0.66666667,  1.        ,  0.66666667,  1.        ,\n",
      "        0.9       ,  1.        ,  0.79136691,  0.8938992 ,  0.62037037,\n",
      "        0.88292683,  0.        ,  0.71428571,  1.        ,  1.        ,\n",
      "        1.        ,  0.71428571,  1.        ,  0.8125    ,  0.85      ,\n",
      "        0.66666667,  0.        ,  0.58974359,  0.85077951,  0.        ,\n",
      "        0.875     ,  0.79216867,  0.77777778,  0.65079365,  0.        ,\n",
      "        0.80434783,  0.83529412,  1.        ,  1.        ,  0.63636364,\n",
      "        1.        ,  0.        ,  1.        ,  0.75438596,  1.        ,\n",
      "        1.        ,  1.        ,  0.        ,  0.83333333,  0.        ,\n",
      "        0.        ,  0.87542088,  0.76923077,  0.72857143,  0.71428571,\n",
      "        0.71428571,  0.75      ,  0.68518519,  1.        ,  0.83108108,\n",
      "        0.7979798 ,  0.        ,  1.        ,  0.5       ,  1.        ,\n",
      "        1.        ,  1.        ,  0.82222222,  0.78378378,  0.94252874,\n",
      "        0.84790875,  0.        ,  0.8       ,  0.        ,  0.83333333,\n",
      "        0.78571429,  0.92086331,  0.87837838,  1.        ,  0.        ,\n",
      "        0.78688525,  1.        ,  1.        ,  1.        ,  0.95833333,\n",
      "        0.        ,  0.91021672,  0.75757576,  0.86153846,  1.        ,\n",
      "        0.90909091,  0.93333333,  0.64705882,  0.76623377,  0.92394366,\n",
      "        0.875     ,  1.        ,  1.        ,  0.9       ,  0.77358491,\n",
      "        0.5       ,  0.8       ,  0.8       ,  1.        ,  0.44444444,\n",
      "        1.        ,  0.85714286,  1.        ,  1.        ,  1.        ,\n",
      "        0.8       ,  0.81      ,  0.83870968,  0.75      ,  0.76666667,\n",
      "        0.84      ,  0.92753623,  0.9612069 ,  1.        ,  0.76851852,\n",
      "        0.        ,  0.92307692,  1.        ,  0.66666667,  1.        ,\n",
      "        1.        ,  1.        ,  0.80751174,  0.86956522,  0.84875847,\n",
      "        0.87962963,  0.        ,  0.75      ,  1.        ,  0.66666667,\n",
      "        1.        ,  0.81538462,  0.88888889,  0.88888889,  0.95918367,\n",
      "        0.875     ,  1.        ,  0.        ,  0.        ,  0.91949911,\n",
      "        0.        ,  1.        ,  0.        ,  0.87096774,  0.94716981,\n",
      "        0.96666667,  0.76      ,  1.        ,  1.        ,  0.91666667,\n",
      "        0.90134529,  0.88505747,  0.87837838,  0.8125    ,  0.9375    ,\n",
      "        0.74193548,  0.9205298 ,  0.88721805,  0.80519481,  0.        ,\n",
      "        1.        ,  0.58333333,  0.        ,  0.77777778,  0.85185185,\n",
      "        0.7761194 ,  1.        ,  0.83333333,  0.        ,  0.75      ,\n",
      "        1.        ,  0.7826087 ,  1.        ,  0.7       ,  0.97619048,\n",
      "        0.77777778,  0.5       ,  0.80617496,  0.84615385,  0.85858586,\n",
      "        1.        ,  0.82352941,  1.        ,  1.        ,  0.72727273,\n",
      "        0.72521246,  0.83333333,  0.77966102,  0.5       ,  1.        ,\n",
      "        0.72      ,  1.        ,  1.        ,  0.        ,  0.9378882 ,\n",
      "        0.87692308,  0.82857143,  0.66666667,  0.88      ,  0.88741722,\n",
      "        1.        ,  0.75      ,  0.83333333,  1.        ,  0.8       ,\n",
      "        0.94409938]), array([ 1.        ,  1.        ,  0.875     ,  0.90909091,  1.        ,\n",
      "        0.53448276,  1.        ,  0.78974359,  0.        ,  0.        ,\n",
      "        0.98722416,  1.        ,  1.        ,  0.74285714,  1.        ,\n",
      "        0.96428571,  1.        ,  0.81481481,  0.80238095,  0.71276596,\n",
      "        0.86602871,  0.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.91666667,  1.        ,  1.        ,\n",
      "        1.        ,  0.        ,  0.92      ,  0.78762887,  0.        ,\n",
      "        0.84848485,  0.65914787,  0.93333333,  0.43617021,  0.        ,\n",
      "        0.56060606,  0.88198758,  1.        ,  0.99277606,  0.56      ,\n",
      "        1.        ,  0.        ,  0.8       ,  0.83225806,  1.        ,\n",
      "        1.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.89965398,  1.        ,  0.66233766,  1.        ,\n",
      "        1.        ,  1.        ,  0.82222222,  1.        ,  0.55656109,\n",
      "        0.70535714,  0.        ,  0.94230769,  0.78571429,  1.        ,\n",
      "        1.        ,  1.        ,  0.47435897,  0.96666667,  0.78846154,\n",
      "        0.78245614,  0.        ,  0.85596708,  0.        ,  0.90909091,\n",
      "        1.        ,  0.74853801,  0.8265896 ,  1.        ,  0.        ,\n",
      "        0.56470588,  1.        ,  1.        ,  1.        ,  0.88461538,\n",
      "        0.        ,  0.8121547 ,  0.78347578,  0.62921348,  1.        ,\n",
      "        0.90909091,  0.93333333,  0.6875    ,  0.83098592,  0.87234043,\n",
      "        0.82352941,  1.        ,  1.        ,  1.        ,  0.85416667,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  0.68067227,  0.8125    ,  0.52631579,  0.79310345,\n",
      "        1.        ,  0.86486486,  0.9612069 ,  1.        ,  0.68595041,\n",
      "        0.        ,  0.95454545,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.7962963 ,  1.        ,  0.78333333,\n",
      "        0.87155963,  0.        ,  0.85714286,  1.        ,  1.        ,\n",
      "        1.        ,  0.79104478,  0.94117647,  0.71428571,  0.71212121,\n",
      "        1.        ,  1.        ,  0.        ,  0.        ,  0.85809683,\n",
      "        0.        ,  1.        ,  0.        ,  0.84375   ,  0.94007491,\n",
      "        0.93548387,  0.4691358 ,  1.        ,  1.        ,  1.        ,\n",
      "        0.90540541,  0.73333333,  0.68062827,  0.95121951,  1.        ,\n",
      "        0.54761905,  0.86335404,  0.77124183,  0.81578947,  0.        ,\n",
      "        1.        ,  1.        ,  0.        ,  0.54609929,  0.92      ,\n",
      "        0.8125    ,  1.        ,  1.        ,  0.        ,  1.        ,\n",
      "        1.        ,  0.81818182,  1.        ,  1.        ,  0.84536082,\n",
      "        1.        ,  0.94444444,  0.79661017,  1.        ,  0.67460317,\n",
      "        1.        ,  0.93333333,  1.        ,  1.        ,  1.        ,\n",
      "        0.54237288,  1.        ,  0.86792453,  1.        ,  1.        ,\n",
      "        1.        ,  0.72222222,  1.        ,  0.        ,  0.93209877,\n",
      "        0.78082192,  0.76315789,  1.        ,  0.66666667,  0.75706215,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.92121212]), array([ 1.        ,  0.93333333,  0.9009901 ,  0.8       ,  1.        ,\n",
      "        0.62626263,  0.83333333,  0.77581864,  0.        ,  0.        ,\n",
      "        0.99067599,  0.8       ,  1.        ,  0.7027027 ,  1.        ,\n",
      "        0.93103448,  1.        ,  0.80291971,  0.84567127,  0.66336634,\n",
      "        0.87439614,  0.        ,  0.83333333,  1.        ,  1.        ,\n",
      "        1.        ,  0.83333333,  0.95652174,  0.89655172,  0.91891892,\n",
      "        0.8       ,  0.        ,  0.71875   ,  0.81798715,  0.        ,\n",
      "        0.86153846,  0.71956224,  0.84848485,  0.52229299,  0.        ,\n",
      "        0.66071429,  0.85800604,  1.        ,  0.99637494,  0.59574468,\n",
      "        1.        ,  0.        ,  0.88888889,  0.79141104,  1.        ,\n",
      "        1.        ,  1.        ,  0.        ,  0.90909091,  0.        ,\n",
      "        0.        ,  0.88737201,  0.86956522,  0.69387755,  0.83333333,\n",
      "        0.83333333,  0.85714286,  0.74747475,  1.        ,  0.66666667,\n",
      "        0.74881517,  0.        ,  0.97029703,  0.61111111,  1.        ,\n",
      "        1.        ,  1.        ,  0.60162602,  0.86567164,  0.85863874,\n",
      "        0.81386861,  0.        ,  0.82703777,  0.        ,  0.86956522,\n",
      "        0.88      ,  0.82580645,  0.85169744,  1.        ,  0.        ,\n",
      "        0.65753425,  1.        ,  1.        ,  1.        ,  0.92      ,\n",
      "        0.        ,  0.85839416,  0.77030812,  0.72727273,  1.        ,\n",
      "        0.90909091,  0.93333333,  0.66666667,  0.7972973 ,  0.89740082,\n",
      "        0.84848485,  1.        ,  1.        ,  0.94736842,  0.81188119,\n",
      "        0.66666667,  0.88888889,  0.88888889,  1.        ,  0.61538462,\n",
      "        1.        ,  0.92307692,  1.        ,  1.        ,  1.        ,\n",
      "        0.88888889,  0.73972603,  0.82539683,  0.6185567 ,  0.77966102,\n",
      "        0.91304348,  0.8951049 ,  0.9612069 ,  1.        ,  0.72489083,\n",
      "        0.        ,  0.93854749,  1.        ,  0.8       ,  1.        ,\n",
      "        1.        ,  1.        ,  0.8018648 ,  0.93023256,  0.81473456,\n",
      "        0.87557604,  0.        ,  0.8       ,  1.        ,  0.8       ,\n",
      "        1.        ,  0.8030303 ,  0.91428571,  0.79207921,  0.8173913 ,\n",
      "        0.93333333,  1.        ,  0.        ,  0.        ,  0.88773748,\n",
      "        0.        ,  1.        ,  0.        ,  0.85714286,  0.94360902,\n",
      "        0.95081967,  0.58015267,  1.        ,  1.        ,  0.95652174,\n",
      "        0.90337079,  0.80208333,  0.76696165,  0.87640449,  0.96774194,\n",
      "        0.63013699,  0.89102564,  0.82517483,  0.81045752,  0.        ,\n",
      "        1.        ,  0.73684211,  0.        ,  0.64166667,  0.88461538,\n",
      "        0.79389313,  1.        ,  0.90909091,  0.        ,  0.85714286,\n",
      "        1.        ,  0.8       ,  1.        ,  0.82352941,  0.90607735,\n",
      "        0.875     ,  0.65384615,  0.80136402,  0.91666667,  0.75555556,\n",
      "        1.        ,  0.875     ,  1.        ,  1.        ,  0.84210526,\n",
      "        0.62060606,  0.90909091,  0.82142857,  0.66666667,  1.        ,\n",
      "        0.8372093 ,  0.83870968,  1.        ,  0.        ,  0.93498452,\n",
      "        0.82608696,  0.79452055,  0.8       ,  0.75862069,  0.81707317,\n",
      "        1.        ,  0.85714286,  0.90909091,  1.        ,  0.88888889,\n",
      "        0.93251534]), array([   1,    7,  104,   22,   56,   58,   10,  195,    0,    0,  861,\n",
      "          2,    2,   35,    1,   28,    1,  135, 1260,  188,  209,    0,\n",
      "          5,    4,    1,    1,    5,   12,   13,   17,    8,    0,   25,\n",
      "        485,    0,   33,  399,   15,   94,    0,   66,  161,    6,  969,\n",
      "         25,    6,    0,   15,  155,    3,    7,    8,    0,    5,    0,\n",
      "          0,  289,   10,  154,   10,    5,    6,   45,    1,  221,  112,\n",
      "          0,  104,   14,    1,    6,    3,   78,   30,  104,  285,    0,\n",
      "        243,    0,   22,   11,  171,  865,    2,    0,  170,    1,    3,\n",
      "          4,   26,    0,  362,  351,   89,   12,   33,   30,   32,   71,\n",
      "        376,   17,    2,   11,    9,   48,    1,    8,   12,    1,    4,\n",
      "         13,    6,    1,    4,    2,    8,  238,   32,   57,   29,   21,\n",
      "         74,  232,    2,  121,    0,   88,    1,    4,    3,    1,    4,\n",
      "        432,   20,  480,  109,    0,    7,    1,    2,    5,   67,   17,\n",
      "        112,   66,   14,    2,    0,    0,  599,    0,    1,    0,   32,\n",
      "        267,   31,   81,   14,    2,   11,  222,  105,  191,   41,   15,\n",
      "         42,  161,  306,   76,    0,    1,    7,    0,  141,   25,  128,\n",
      "          2,    5,    0,    6,   10,   22,    7,   21,   97,    7,   18,\n",
      "        590,   11,  126,   11,   15,    4,    1,    8,  944,    5,   53,\n",
      "          1,    8,   18,   54,    2,    0,  162,  146,   38,   12,   66,\n",
      "        177,    1,   15,    5,    3,    4,  165]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average=None, sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_train,\"true_train\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_dev,\"true_dev\"+date_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(data_to_tag): \n",
    "    filename = data_to_tag+\"_arrays.npz\"\n",
    "    arrays = np.load(os.path.join(DATADIR,filename))\n",
    "    \n",
    "    print('Set up arrays for new_content: {}'.format(arrays.files))\n",
    "    x_predict = arrays['x']\n",
    "    meta_predict = arrays['meta'].all().todense()\n",
    "    title_predict = arrays['title'].all().todense()\n",
    "    desc_predict = arrays['desc'].all().todense()\n",
    "    \n",
    "    print('x_arrays.shape = {}'.format(x_predict.shape))\n",
    "    print('meta_arrays.shape = {}'.format(meta_predict.shape))\n",
    "    print('title_arrays.shape = {}'.format(title_predict.shape))\n",
    "    print('desc_arrays.shape = {}'.format(desc_predict.shape))\n",
    "    \n",
    "    print('Predict on untagged content')\n",
    "    y_pred_new = model.predict([meta_predict, title_predict, desc_predict, x_predict])\n",
    "    \n",
    "    to_file(y_pred_new, data_to_tag+\"_predictions\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up arrays for new_content: ['x', 'meta', 'title', 'desc', 'content_id']\n",
      "x_arrays.shape = (56737, 1000)\n",
      "meta_arrays.shape = (56737, 521)\n",
      "title_arrays.shape = (56737, 10000)\n",
      "desc_arrays.shape = (56737, 10000)\n",
      "Predict on untagged content\n"
     ]
    }
   ],
   "source": [
    "get_predictions(\"new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_predictions_1123_2703_\n"
     ]
    }
   ],
   "source": [
    "print(\"new_predictions\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up arrays for new_content: ['x', 'meta', 'title', 'desc', 'content_id']\n",
      "x_arrays.shape = (18015, 1000)\n",
      "meta_arrays.shape = (18015, 521)\n",
      "title_arrays.shape = (18015, 10000)\n",
      "desc_arrays.shape = (18015, 10000)\n",
      "Predict on untagged content\n"
     ]
    }
   ],
   "source": [
    "get_predictions(\"level1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level1_predictions_1123_2703_\n"
     ]
    }
   ],
   "source": [
    "print(\"level1_predictions\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "keep_output": true,
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
