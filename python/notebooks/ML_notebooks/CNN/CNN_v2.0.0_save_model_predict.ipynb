{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional NN to classify govuk content to level2 taxons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on:\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load requirements and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.utils import to_categorical, layer_utils, plot_model\n",
    "\n",
    "from keras.layers import (Embedding, Input, Dense, Dropout, \n",
    "                          Activation, Conv1D, MaxPooling1D, Flatten, concatenate, Reshape)\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.callbacks import TensorBoard, Callback, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score \n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import functools\n",
    "\n",
    "import h5py\n",
    "\n",
    "from scipy import sparse\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environmental vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATADIR = os.getenv('DATADIR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print data version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm running on data extracted from content store on /data/2018-03-05\n"
     ]
    }
   ],
   "source": [
    "print('algorithm running on data extracted from content store on {}'.format(DATADIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuition for POS_RATIO is that it penalises the prediction of zero for everything, which is attractive to the model because the multilabel y matrix is super sparse. \n",
    "\n",
    "Increasing POS_RATIO should penalise predicting zeros more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MAX_NB_WORDS\n",
    "MAX_SEQUENCE_LENGTH =1000\n",
    "EMBEDDING_DIM = 100 # keras embedding layer output_dim = Dimension of the dense embedding\n",
    "P_THRESHOLD = 0.5 #Threshold for probability of being assigned to class\n",
    "POS_RATIO = 0.5 #ratio of positive to negative for each class in weighted binary cross entropy loss function\n",
    "NUM_WORDS=20000 #keras tokenizer num_words: None or int. Maximum number of words to work with \n",
    "#(if set, tokenization will be restricted to the top num_words most common words in the dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = np.load(os.path.join(DATADIR, 'train_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'meta', 'title', 'desc', 'y', 'content_id']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (175767, 1000)\n",
      "meta_train.shape = (175767, 535)\n",
      "title_train.shape = (175767, 10000)\n",
      "desc_train.shape = (175767, 10000)\n",
      "y_train.shape = (175767, 218)\n"
     ]
    }
   ],
   "source": [
    "x_train = train['x']\n",
    "meta_train = train['meta'].all().todense()\n",
    "title_train = train['title'].all().todense()\n",
    "desc_train = train['desc'].all().todense()\n",
    "y_train = train['y'].all().todense()\n",
    "\n",
    "print('x_train.shape = {}'.format(x_train.shape))\n",
    "print('meta_train.shape = {}'.format(meta_train.shape))\n",
    "print('title_train.shape = {}'.format(title_train.shape))\n",
    "print('desc_train.shape = {}'.format(desc_train.shape))\n",
    "print('y_train.shape = {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dev = np.load(os.path.join(DATADIR, 'dev_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_dev.shape = (12408, 1000)\n",
      "meta_dev.shape = (12408, 535)\n",
      "title_dev.shape = (12408, 10000)\n",
      "desc_dev.shape = (12408, 10000)\n",
      "y_dev.shape = (12408, 218)\n"
     ]
    }
   ],
   "source": [
    "x_dev = dev['x']\n",
    "meta_dev = dev['meta'].all().todense()\n",
    "title_dev = dev['title'].all().todense()\n",
    "desc_dev = dev['desc'].all().todense()\n",
    "y_dev = dev['y'].all().todense()\n",
    "\n",
    "print('x_dev.shape = {}'.format(x_dev.shape))\n",
    "print('meta_dev.shape = {}'.format(meta_dev.shape))\n",
    "print('title_dev.shape = {}'.format(title_dev.shape))\n",
    "print('desc_dev.shape = {}'.format(desc_dev.shape))\n",
    "print('y_dev.shape = {}'.format(y_dev.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = np.load(os.path.join(DATADIR, 'test_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test.shape = (12409, 1000)\n",
      "meta_test.shape = (12409, 535)\n",
      "title_test.shape = (12409, 10000)\n",
      "desc_test.shape = (12409, 10000)\n",
      "y_test.shape = (12409, 218)\n"
     ]
    }
   ],
   "source": [
    "x_test = test['x']\n",
    "meta_test = test['meta'].all().todense()\n",
    "title_test = test['title'].all().todense()\n",
    "desc_test = test['desc'].all().todense()\n",
    "y_test = test['y'].all().todense()\n",
    "\n",
    "print('x_test.shape = {}'.format(x_test.shape))\n",
    "print('meta_test.shape = {}'.format(meta_test.shape))\n",
    "print('title_test.shape = {}'.format(title_test.shape))\n",
    "print('desc_test.shape = {}'.format(desc_test.shape))\n",
    "print('y_test.shape = {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### previous shapes in old data \n",
    "Shape of x_train: (150870, 1000)\n",
    "Shape of metax_train: (150870, 436)\n",
    "Shape of titlex_train: (150870, 10000)\n",
    "Shape of descx_train: (150870, 10000)\n",
    "Shape of y_train: (150870, 210)\n",
    "\n",
    "Shape of x_dev: (9234, 1000)\n",
    "Shape of meta_dev: (9234, 436)\n",
    "Shape of titlex_dev: (9234, 10000)\n",
    "Shape of descx_dev: (9234, 10000)\n",
    "Shape of y_dev: (9234, 210)\n",
    "\n",
    "Shape of x_test: (9234, 1000)\n",
    "Shape of metax_test: (9234, 436)\n",
    "Shape of titlex_test: (9234, 10000)\n",
    "Shape of descx_test: (9234, 10000)\n",
    "Shape of y_test: (9234, 210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing the Embedding layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "def load_tokenizer_from_file(filename):\n",
    "    \n",
    "    tokenizer = Tokenizer()\n",
    "\n",
    "    with open(filename, 'r') as infile:\n",
    "        tokenizer_data = json.load(infile)\n",
    "\n",
    "    tokenizer.word_counts = OrderedDict(tokenizer_data['word_counts'])\n",
    "    tokenizer.word_docs = tokenizer_data['word_docs']\n",
    "    tokenizer.word_index = tokenizer_data['word_index']\n",
    "    tokenizer.document_count = tokenizer_data['document_count']\n",
    "    tokenizer.index_docs = tokenizer_data['index_docs']\n",
    "\n",
    "    return tokenizer\n",
    "\n",
    "tokenizer_combined_text = load_tokenizer_from_file(os.path.join(DATADIR, \"combined_text_tokenizer.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(tokenizer_combined_text.word_index) + 1, \n",
    "                            EMBEDDING_DIM, \n",
    "                            input_length=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Embedding layer should be fed sequences of integers, i.e. a 2D input of shape (samples, indices). These input sequences should be padded so that they all have the same length in a batch of input data (although an Embedding layer is capable of processing sequence of heterogenous length, if you don't pass an explicit input_length argument to the layer).\n",
    "\n",
    "All that the Embedding layer does is to map the integer inputs to the vectors found at the corresponding index in the embedding matrix, i.e. the sequence [1, 2] would be converted to [embeddings[1], embeddings[2]]. This means that the output of the Embedding layer will be a 3D tensor of shape (samples, sequence_length, embedding_dim)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate class weights for unbalanced datasets.\n",
    "paramter to model.fit = __class_weight__: Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
    "\n",
    "Implement class_weight from sklearn:\n",
    "\n",
    "- Import the module \n",
    "\n",
    "`from sklearn.utils import class_weight`\n",
    "- calculate the class weight, If ‘balanced’, class weights will be given by n_samples / (n_classes * np.bincount(y)):\n",
    "\n",
    "`class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)`\n",
    "\n",
    "- change it to a dict in order to work with Keras.\n",
    "\n",
    "`class_weight_dict = dict(enumerate(class_weight))`\n",
    "\n",
    "- Add to model fitting\n",
    "\n",
    "`model.fit(X_train, y_train, class_weight=class_weight)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "# class_weight_dict = dict(enumerate(class_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.00756\n",
      "8.01512\n"
     ]
    }
   ],
   "source": [
    "class WeightedBinaryCrossEntropy(object):\n",
    "\n",
    "    def __init__(self, pos_ratio):\n",
    "        neg_ratio = 1. - pos_ratio\n",
    "        #self.pos_ratio = tf.constant(pos_ratio, tf.float32)\n",
    "        self.pos_ratio = pos_ratio\n",
    "        #self.weights = tf.constant(neg_ratio / pos_ratio, tf.float32)\n",
    "        self.weights = neg_ratio / pos_ratio\n",
    "        self.__name__ = \"weighted_binary_crossentropy({0})\".format(pos_ratio)\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        return self.weighted_binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "    def weighted_binary_crossentropy(self, y_true, y_pred):\n",
    "            # Transform to logits\n",
    "            epsilon = tf.convert_to_tensor(K.common._EPSILON, y_pred.dtype.base_dtype)\n",
    "            y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
    "            y_pred = tf.log(y_pred / (1 - y_pred))\n",
    "\n",
    "            cost = tf.nn.weighted_cross_entropy_with_logits(y_true, y_pred, self.weights)\n",
    "            return K.mean(cost * self.pos_ratio, axis=-1)\n",
    "    \n",
    "y_true_arr = np.array([0,1,0,1], dtype=\"float32\")\n",
    "y_pred_arr = np.array([0,0,1,1], dtype=\"float32\")\n",
    "y_true = tf.constant(y_true_arr)\n",
    "y_pred = tf.constant(y_pred_arr)\n",
    "\n",
    "with tf.Session().as_default(): \n",
    "    print(WeightedBinaryCrossEntropy(0.5)(y_true, y_pred).eval())\n",
    "    print(binary_crossentropy(y_true, y_pred).eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### difficulty getting global precision/recall metrics . CAUTION interpreting monitoring metrics\n",
    "fcholltet: \"Basically these are all global metrics that were approximated\n",
    "batch-wise, which is more misleading than helpful. This was mentioned in\n",
    "the docs but it's much cleaner to remove them altogether. It was a mistake\n",
    "to merge them in the first place.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    \"\"\"Use Recall  and precision metrics to calculate harmonic mean (F1 score).\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1 = 2*((precision*recall)/(precision+recall))\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a 1D convnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NB_CLASSES = y_train.shape[1]\n",
    "NB_METAVARS = meta_train.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='wordindex') #MAX_SEQUENCE_LENGTH\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Dropout(0.2, name = 'dropout_embedded')(embedded_sequences)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv0')(x)\n",
    "\n",
    "x = MaxPooling1D(5, name = 'max_pool0')(x)\n",
    "\n",
    "x = Dropout(0.5, name = 'dropout0')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv1')(x)\n",
    "\n",
    "x = MaxPooling1D(5 , name = 'max_pool1')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv2')(x)\n",
    "\n",
    "x = MaxPooling1D(35, name = 'global_max_pool')(x)  # global max pooling\n",
    "\n",
    "x = Flatten()(x) #reduce dimensions from 3 to 2; convert to vector + FULLYCONNECTED\n",
    "\n",
    "meta_input = Input(shape=(NB_METAVARS,), name='meta')\n",
    "meta_hidden = Dense(128, activation='relu', name = 'hidden_meta')(meta_input)\n",
    "meta_hidden = Dropout(0.2, name = 'dropout_meta')(meta_hidden)\n",
    "\n",
    "\n",
    "title_input = Input(shape=(title_train.shape[1],), name='titles')\n",
    "title_hidden = Dense(128, activation='relu', name = 'hidden_title')(title_input)\n",
    "title_hidden = Dropout(0.2, name = 'dropout_title')(title_hidden)\n",
    "\n",
    "desc_input = Input(shape=(desc_train.shape[1],), name='descs')\n",
    "desc_hidden = Dense(128, activation='relu', name = 'hidden_desc')(desc_input)\n",
    "desc_hidden = Dropout(0.2, name = 'dropout_desc')(desc_hidden)\n",
    "\n",
    "concatenated = concatenate([meta_hidden, title_hidden, desc_hidden, x])\n",
    "\n",
    "x = Dense(400, activation='relu', name = 'fully_connected0')(concatenated)\n",
    "\n",
    "x = Dropout(0.2, name = 'dropout1')(x)\n",
    "\n",
    "x = Dense(NB_CLASSES, activation='sigmoid', name = 'fully_connected1')(x)\n",
    "\n",
    "# # The Model class turns an input tensor and output tensor into a model\n",
    "# This creates Keras model instance, will use this instance to train/test the model.\n",
    "model = Model(inputs=[meta_input, title_input, desc_input, sequence_input], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "wordindex (InputLayer)          (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 100)    34338600    wordindex[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_embedded (Dropout)      (None, 1000, 100)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv1D)                  (None, 996, 128)     64128       dropout_embedded[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pool0 (MaxPooling1D)        (None, 199, 128)     0           conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout0 (Dropout)              (None, 199, 128)     0           max_pool0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv1D)                  (None, 195, 128)     82048       dropout0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pool1 (MaxPooling1D)        (None, 39, 128)      0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "meta (InputLayer)               (None, 535)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "titles (InputLayer)             (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "descs (InputLayer)              (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv1D)                  (None, 35, 128)      82048       max_pool1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hidden_meta (Dense)             (None, 128)          68608       meta[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "hidden_title (Dense)            (None, 128)          1280128     titles[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "hidden_desc (Dense)             (None, 128)          1280128     descs[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pool (MaxPooling1D)  (None, 1, 128)       0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_meta (Dropout)          (None, 128)          0           hidden_meta[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_title (Dropout)         (None, 128)          0           hidden_title[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_desc (Dropout)          (None, 128)          0           hidden_desc[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           global_max_pool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           dropout_meta[0][0]               \n",
      "                                                                 dropout_title[0][0]              \n",
      "                                                                 dropout_desc[0][0]               \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fully_connected0 (Dense)        (None, 400)          205200      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 400)          0           fully_connected0[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fully_connected1 (Dense)        (None, 218)          87418       dropout1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 37,488,306\n",
      "Trainable params: 37,488,306\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard callbacks /metrics /monitor training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **Size of these files is killing storage during training. Is it histograms?**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tb = TensorBoard(log_dir='./learn_embedding_logs', histogram_freq=1, write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = os.path.join(DATADIR, 'model_checkpoint.hdf5')\n",
    "\n",
    "cp = ModelCheckpoint(\n",
    "                     filepath = CHECKPOINT_PATH, \n",
    "                     monitor='val_loss', \n",
    "                     verbose=0, \n",
    "                     save_best_only=False, \n",
    "                     save_weights_only=False, \n",
    "                     mode='auto', \n",
    "                     period=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "#model.fit(x, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 & 3. Train & compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 175767 samples, validate on 12408 samples\n",
      "Epoch 1/10\n",
      "175767/175767 [==============================] - 136s 776us/step - loss: 0.0087 - binary_accuracy: 0.9951 - f1: nan - val_loss: 0.0041 - val_binary_accuracy: 0.9973 - val_f1: 0.7759\n",
      "Epoch 2/10\n",
      "175767/175767 [==============================] - 128s 728us/step - loss: 0.0029 - binary_accuracy: 0.9980 - f1: 0.8715 - val_loss: 0.0036 - val_binary_accuracy: 0.9977 - val_f1: 0.8063\n",
      "Epoch 3/10\n",
      "175767/175767 [==============================] - 128s 728us/step - loss: 0.0022 - binary_accuracy: 0.9985 - f1: 0.9057 - val_loss: 0.0034 - val_binary_accuracy: 0.9978 - val_f1: 0.8211\n",
      "Epoch 4/10\n",
      "175767/175767 [==============================] - 128s 726us/step - loss: 0.0019 - binary_accuracy: 0.9988 - f1: 0.9217 - val_loss: 0.0033 - val_binary_accuracy: 0.9979 - val_f1: 0.8307\n",
      "Epoch 5/10\n",
      "175767/175767 [==============================] - 128s 726us/step - loss: 0.0016 - binary_accuracy: 0.9989 - f1: 0.9312 - val_loss: 0.0035 - val_binary_accuracy: 0.9979 - val_f1: 0.8336\n",
      "Epoch 6/10\n",
      "175767/175767 [==============================] - 128s 725us/step - loss: 0.0015 - binary_accuracy: 0.9990 - f1: 0.9367 - val_loss: 0.0041 - val_binary_accuracy: 0.9979 - val_f1: 0.8280\n"
     ]
    }
   ],
   "source": [
    "# metrics callback causes: CCCCCCR55555555511155\n",
    "# So disable for now\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "# Replicates `model` on 8 GPUs.\n",
    "# This assumes that your machine has 8 available GPUs.\n",
    "parallel_model = multi_gpu_model(model, gpus=8)\n",
    "parallel_model.compile(loss=WeightedBinaryCrossEntropy(POS_RATIO),\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['binary_accuracy', f1])\n",
    "\n",
    "# This `fit` call will be distributed on 8 GPUs.\n",
    "# Since the batch size is 256, each GPU will process 32 samples.\n",
    "history = parallel_model.fit(\n",
    "    {'meta': meta_train, 'titles': title_train, 'descs': desc_train, 'wordindex': x_train},\n",
    "    y_train, \n",
    "    validation_data=([meta_dev, title_dev, desc_dev, x_dev], y_dev), \n",
    "    epochs=10, batch_size=128, callbacks=[early_stopping]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_binary_accuracy', 'val_f1', 'loss', 'binary_accuracy', 'f1'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f319d9bc978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, 7)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')           \n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')      \n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f319d9bc5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()    \n",
    "\n",
    "f1_values = history_dict['f1']\n",
    "val_f1_values = history_dict['val_f1']\n",
    "\n",
    "plt.plot(epochs, f1_values, 'bo', label='Training f1')\n",
    "plt.plot(epochs, val_f1_values, 'b', label='Validation f1')\n",
    "plt.title('Training and validation batch-level f1-micro')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1-micro')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_file(array,name):\n",
    "    df = pd.DataFrame(data = array.tolist(),columns=[i for i in range(1,y_train.shape[1]+1)])\n",
    "    df.to_csv(os.path.join(DATADIR, name+'.csv.gz'),compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_1010_0803_'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_run = time.strftime(\"_%H%M_%d%m_\")\n",
    "date_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = parallel_model.predict([meta_train, title_train, desc_train, x_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_prob,\"train_results\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_prob.copy()\n",
    "y_pred[y_pred>=P_THRESHOLD] = 1\n",
    "y_pred[y_pred<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro: (0.97271783537606327, 0.94284313916424844, 0.95754752745169791, None)\n",
      "macro: (0.98237437525002991, 0.96390205334084123, 0.97244877974912269, None)\n",
      "weightedmacro: (0.97270364294834932, 0.94284313916424844, 0.95686852456865601, None)\n"
     ]
    }
   ],
   "source": [
    "print('micro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='micro', sample_weight=None)))\n",
    "print('macro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='macro', sample_weight=None)))\n",
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='weighted', sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_dev = parallel_model.predict([meta_dev, title_dev, desc_dev, x_dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_prob_dev,\"dev_results\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dev = y_prob_dev.copy()\n",
    "y_pred_dev[y_pred_dev>=P_THRESHOLD] = 1\n",
    "y_pred_dev[y_pred_dev<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro: (0.86504714919128212, 0.79417497993349384, 0.82809744432820209, None)\n",
      "macro: (0.77235558148910566, 0.80151588193994372, 0.77747634676442445, None)\n",
      "weightedmacro: (0.86897450390606434, 0.79417497993349384, 0.82547398235036362, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('micro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='micro', sample_weight=None)))\n",
    "print('macro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='macro', sample_weight=None)))\n",
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='weighted', sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weightedmacro: (array([ 0.        ,  0.66666667,  0.96428571,  0.54545455,  1.        ,\n",
      "        0.625     ,  0.77777778,  0.87857143,  1.        ,  1.        ,\n",
      "        0.        ,  1.        ,  1.        ,  1.        ,  0.70833333,\n",
      "        0.        ,  0.69230769,  1.        ,  0.        ,  0.85714286,\n",
      "        0.85477941,  0.75949367,  0.81102362,  1.        ,  1.        ,\n",
      "        1.        ,  0.5       ,  1.        ,  1.        ,  1.        ,\n",
      "        0.7       ,  0.93333333,  0.9       ,  0.        ,  0.6097561 ,\n",
      "        0.8560794 ,  0.5       ,  0.65517241,  0.81625442,  0.83333333,\n",
      "        0.75609756,  1.        ,  0.71428571,  0.86666667,  1.        ,\n",
      "        1.        ,  0.68292683,  0.75      ,  0.        ,  0.75      ,\n",
      "        0.7540107 ,  1.        ,  1.        ,  0.76470588,  1.        ,\n",
      "        1.        ,  1.        ,  0.        ,  0.97265625,  0.78571429,\n",
      "        0.82727273,  0.83333333,  0.71428571,  0.84615385,  0.89655172,\n",
      "        1.        ,  0.78881988,  0.75675676,  1.        ,  0.98507463,\n",
      "        0.60714286,  1.        ,  1.        ,  0.9       ,  0.8       ,\n",
      "        0.75      ,  0.95      ,  0.86635945,  0.        ,  0.91666667,\n",
      "        1.        ,  0.84615385,  0.7       ,  0.87301587,  0.91823899,\n",
      "        1.        ,  1.        ,  0.79754601,  1.        ,  1.        ,\n",
      "        0.83333333,  0.92857143,  1.        ,  0.88686131,  0.90134529,\n",
      "        0.75308642,  1.        ,  0.85714286,  1.        ,  0.88888889,\n",
      "        0.65625   ,  0.84337349,  0.97297297,  0.84848485,  0.        ,\n",
      "        0.89473684,  0.875     ,  0.82608696,  0.        ,  0.71428571,\n",
      "        0.76923077,  0.        ,  0.57142857,  1.        ,  1.        ,\n",
      "        0.        ,  0.5       ,  1.        ,  0.71428571,  0.87431694,\n",
      "        0.65      ,  0.77192982,  0.70833333,  0.92307692,  0.95522388,\n",
      "        0.99425287,  0.8       ,  0.78481013,  0.        ,  0.97142857,\n",
      "        1.        ,  0.66666667,  1.        ,  1.        ,  0.        ,\n",
      "        0.82366589,  0.6875    ,  0.8217636 ,  0.89583333,  0.        ,\n",
      "        0.66666667,  1.        ,  1.        ,  1.        ,  0.91071429,\n",
      "        0.92857143,  0.79824561,  0.92156863,  0.66666667,  0.66666667,\n",
      "        1.        ,  0.83333333,  0.95190381,  1.        ,  0.        ,\n",
      "        1.        ,  0.875     ,  0.96566524,  0.640625  ,  0.93333333,\n",
      "        1.        ,  0.85714286,  0.90425532,  0.87012987,  0.90990991,\n",
      "        0.82608696,  0.84615385,  0.88888889,  0.96323529,  0.89156627,\n",
      "        0.88311688,  0.75      ,  0.        ,  0.57142857,  0.        ,\n",
      "        0.7983871 ,  0.85      ,  0.90425532,  0.6       ,  1.        ,\n",
      "        0.        ,  0.76923077,  1.        ,  0.94444444,  1.        ,\n",
      "        0.70588235,  0.95061728,  0.8       ,  0.81481481,  0.83677298,\n",
      "        0.93333333,  1.        ,  0.73873874,  0.8       ,  0.60869565,\n",
      "        0.8       ,  0.        ,  0.65585774,  0.33333333,  0.625     ,\n",
      "        0.        ,  1.        ,  0.91176471,  0.90697674,  0.        ,\n",
      "        1.        ,  0.89333333,  0.87288136,  0.73170732,  0.8125    ,\n",
      "        0.88709677,  0.8       ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  0.83333333,  0.95431472]), array([ 0.        ,  1.        ,  0.87804878,  1.        ,  1.        ,\n",
      "        0.37735849,  0.875     ,  0.65425532,  1.        ,  0.95833333,\n",
      "        0.        ,  0.98481308,  1.        ,  1.        ,  0.69387755,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.72483221,\n",
      "        0.79351536,  0.63829787,  0.91150442,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  0.93333333,  1.        ,  0.        ,  0.75757576,\n",
      "        0.7735426 ,  1.        ,  0.76      ,  0.62432432,  1.        ,\n",
      "        0.35227273,  1.        ,  0.54545455,  0.78571429,  1.        ,\n",
      "        0.99781897,  0.875     ,  1.        ,  0.        ,  0.94736842,\n",
      "        0.8245614 ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.        ,  0.80322581,  1.        ,\n",
      "        0.53846154,  1.        ,  1.        ,  1.        ,  0.60465116,\n",
      "        1.        ,  0.56696429,  0.69421488,  1.        ,  0.92957746,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  0.54794521,\n",
      "        0.91304348,  0.81896552,  0.69372694,  0.        ,  0.82206406,\n",
      "        1.        ,  0.84615385,  1.        ,  0.76923077,  0.77742279,\n",
      "        1.        ,  1.        ,  0.65326633,  1.        ,  1.        ,\n",
      "        1.        ,  0.96296296,  1.        ,  0.75465839,  0.66118421,\n",
      "        0.7721519 ,  1.        ,  1.        ,  1.        ,  0.96      ,\n",
      "        0.7       ,  0.77777778,  0.8       ,  0.75675676,  0.        ,\n",
      "        1.        ,  1.        ,  0.95      ,  0.        ,  1.        ,\n",
      "        1.        ,  0.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.        ,  1.        ,  1.        ,  1.        ,  0.73732719,\n",
      "        0.83870968,  0.84615385,  0.89473684,  0.92307692,  0.8       ,\n",
      "        0.93010753,  1.        ,  0.52991453,  0.        ,  0.94444444,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  0.        ,\n",
      "        0.78021978,  1.        ,  0.86220472,  0.81904762,  0.        ,\n",
      "        0.8       ,  1.        ,  1.        ,  1.        ,  0.69863014,\n",
      "        1.        ,  0.71653543,  0.68115942,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.85740072,  1.        ,  0.        ,\n",
      "        1.        ,  0.95454545,  0.94142259,  0.46067416,  1.        ,\n",
      "        1.        ,  1.        ,  0.88082902,  0.68367347,  0.60479042,\n",
      "        0.92682927,  1.        ,  0.4137931 ,  0.82911392,  0.75254237,\n",
      "        0.79069767,  1.        ,  0.        ,  1.        ,  0.        ,\n",
      "        0.64705882,  1.        ,  0.63432836,  1.        ,  1.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.80952381,  1.        ,\n",
      "        0.88888889,  0.78571429,  1.        ,  0.91666667,  0.7729636 ,\n",
      "        1.        ,  1.        ,  0.70689655,  0.8       ,  1.        ,\n",
      "        1.        ,  0.        ,  0.7125    ,  1.        ,  0.78125   ,\n",
      "        0.        ,  1.        ,  0.93939394,  0.69642857,  0.        ,\n",
      "        1.        ,  0.96402878,  0.63580247,  0.81081081,  1.        ,\n",
      "        0.94827586,  0.78106509,  1.        ,  0.9047619 ,  1.        ,\n",
      "        1.        ,  1.        ,  0.95431472]), array([ 0.        ,  0.8       ,  0.91914894,  0.70588235,  1.        ,\n",
      "        0.47058824,  0.82352941,  0.75      ,  1.        ,  0.9787234 ,\n",
      "        0.        ,  0.99234844,  1.        ,  1.        ,  0.70103093,\n",
      "        0.        ,  0.81818182,  1.        ,  0.        ,  0.78545455,\n",
      "        0.82300885,  0.69364162,  0.85833333,  1.        ,  1.        ,\n",
      "        1.        ,  0.66666667,  1.        ,  1.        ,  1.        ,\n",
      "        0.82352941,  0.93333333,  0.94736842,  0.        ,  0.67567568,\n",
      "        0.81272085,  0.66666667,  0.7037037 ,  0.70750383,  0.90909091,\n",
      "        0.48062016,  1.        ,  0.6185567 ,  0.82420749,  1.        ,\n",
      "        0.9989083 ,  0.76712329,  0.85714286,  0.        ,  0.8372093 ,\n",
      "        0.7877095 ,  1.        ,  1.        ,  0.86666667,  1.        ,\n",
      "        1.        ,  1.        ,  0.        ,  0.87985866,  0.88      ,\n",
      "        0.65232975,  0.90909091,  0.83333333,  0.91666667,  0.72222222,\n",
      "        1.        ,  0.65974026,  0.72413793,  1.        ,  0.95652174,\n",
      "        0.75555556,  1.        ,  1.        ,  0.94736842,  0.6504065 ,\n",
      "        0.82352941,  0.87962963,  0.7704918 ,  0.        ,  0.86679174,\n",
      "        1.        ,  0.84615385,  0.82352941,  0.81784387,  0.84198385,\n",
      "        1.        ,  1.        ,  0.71823204,  1.        ,  1.        ,\n",
      "        0.90909091,  0.94545455,  1.        ,  0.81543624,  0.76280835,\n",
      "        0.7625    ,  1.        ,  0.92307692,  1.        ,  0.92307692,\n",
      "        0.67741935,  0.80924855,  0.87804878,  0.8       ,  0.        ,\n",
      "        0.94444444,  0.93333333,  0.88372093,  0.        ,  0.83333333,\n",
      "        0.86956522,  0.        ,  0.72727273,  1.        ,  1.        ,\n",
      "        0.        ,  0.66666667,  1.        ,  0.83333333,  0.8       ,\n",
      "        0.73239437,  0.80733945,  0.79069767,  0.92307692,  0.8707483 ,\n",
      "        0.96111111,  0.88888889,  0.63265306,  0.        ,  0.95774648,\n",
      "        1.        ,  0.8       ,  1.        ,  1.        ,  0.        ,\n",
      "        0.8013544 ,  0.81481481,  0.84149856,  0.85572139,  0.        ,\n",
      "        0.72727273,  1.        ,  1.        ,  1.        ,  0.79069767,\n",
      "        0.96296296,  0.75518672,  0.78333333,  0.8       ,  0.8       ,\n",
      "        1.        ,  0.90909091,  0.90218424,  1.        ,  0.        ,\n",
      "        1.        ,  0.91304348,  0.95338983,  0.53594771,  0.96551724,\n",
      "        1.        ,  0.92307692,  0.89238845,  0.76571429,  0.72661871,\n",
      "        0.87356322,  0.91666667,  0.56470588,  0.89115646,  0.81617647,\n",
      "        0.83435583,  0.85714286,  0.        ,  0.72727273,  0.        ,\n",
      "        0.71480144,  0.91891892,  0.74561404,  0.75      ,  1.        ,\n",
      "        0.        ,  0.86956522,  1.        ,  0.87179487,  1.        ,\n",
      "        0.78688525,  0.8603352 ,  0.88888889,  0.8627451 ,  0.8036036 ,\n",
      "        0.96551724,  1.        ,  0.72246696,  0.8       ,  0.75675676,\n",
      "        0.88888889,  0.        ,  0.68300654,  0.5       ,  0.69444444,\n",
      "        0.        ,  1.        ,  0.92537313,  0.78787879,  0.        ,\n",
      "        1.        ,  0.92733564,  0.73571429,  0.76923077,  0.89655172,\n",
      "        0.91666667,  0.79041916,  1.        ,  0.95      ,  1.        ,\n",
      "        1.        ,  0.90909091,  0.95431472]), array([   0,    8,  123,   12,   59,   53,    8,  188,    1,   24,    0,\n",
      "        856,    4,    3,   49,    0,   27,    1,    0,  149, 1172,  188,\n",
      "        226,    1,    4,    2,    3,    1,    5,   16,    7,   15,    9,\n",
      "          0,   33,  446,    3,   25,  370,   10,   88,    1,   55,  182,\n",
      "          2,  917,   32,    6,    0,   19,  171,    2,    3,   13,    1,\n",
      "          2,    1,    0,  310,   11,  169,   10,    5,   11,   43,    2,\n",
      "        224,  121,    2,   71,   17,    1,    4,    9,   73,   23,  116,\n",
      "        271,    0,  281,    1,   26,    7,  143,  939,    3,    1,  199,\n",
      "          1,    4,    5,   27,    2,  322,  304,   79,    3,    6,    4,\n",
      "         25,   30,   90,  360,   37,    0,   17,    7,   40,    0,    5,\n",
      "         10,    0,    8,   17,    5,    0,    1,    1,    5,  217,   31,\n",
      "         52,   19,   13,   80,  186,    4,  117,    0,  108,    1,    2,\n",
      "          2,    2,    0,  455,   11,  508,  105,    0,    5,    1,    1,\n",
      "          4,   73,   13,  127,   69,    8,    2,    2,    5,  554,    1,\n",
      "          0,    1,   22,  239,   89,   14,    2,    6,  193,   98,  167,\n",
      "         41,   11,   58,  158,  295,   86,    3,    0,    8,    0,  153,\n",
      "         17,  134,    3,    3,    0,   10,   10,   21,    9,   27,   98,\n",
      "          4,   24,  577,   14,    2,  116,    5,   14,    4,    0,  880,\n",
      "          1,   32,    0,    6,   33,   56,    0,    3,  139,  162,   37,\n",
      "         13,   58,  169,    2,   21,    7,    3,    5,  197]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average=None, sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_train,\"true_train\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_dev,\"true_dev\"+date_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_filename = \"predict_arrays.npz\"\n",
    "predict = np.load(os.path.join(DATADIR, predict_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(arrays):  \n",
    "    \n",
    "    print('Set up arrays for new_content: {}'.format(arrays.files))\n",
    "    x_predict = arrays['x']\n",
    "    meta_predict = arrays['meta'].all().todense()\n",
    "    title_predict = arrays['title'].all().todense()\n",
    "    desc_predict = arrays['desc'].all().todense()\n",
    "    \n",
    "    print('x_arrays.shape = {}'.format(x_predict.shape))\n",
    "    print('meta_arrays.shape = {}'.format(meta_predict.shape))\n",
    "    print('title_arrays.shape = {}'.format(title_predict.shape))\n",
    "    print('desc_arrays.shape = {}'.format(desc_predict.shape))\n",
    "    \n",
    "    print('Predict on untagged content')\n",
    "    y_pred_new = model.predict([meta_predict, title_predict, desc_predict, x_predict])\n",
    "    \n",
    "    to_file(y_pred_new, \"new_predictions\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1f8ce635-2103-4e70-9535-c0726db5d599',\n",
       "       'a40ea7e6-2540-4724-b637-f14e09debf79',\n",
       "       '81b22f15-8f7e-4aa1-8d61-aa66f5e82021',\n",
       "       '5d6687e7-7631-11e4-a3cb-005056011aef',\n",
       "       '5dc49794-7631-11e4-a3cb-005056011aef',\n",
       "       '78b3e7d9-1835-4606-8a82-ede4c2578aa9',\n",
       "       '5d8140f1-7631-11e4-a3cb-005056011aef',\n",
       "       '5ef93da2-7631-11e4-a3cb-005056011aef',\n",
       "       '5dc2e94e-7631-11e4-a3cb-005056011aef',\n",
       "       '5c8fadc6-7631-11e4-a3cb-005056011aef'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_predict = predict['content_id']\n",
    "id_predict[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up arrays for new_content: ['x', 'meta', 'title', 'desc', 'content_id']\n",
      "x_arrays.shape = (87726, 1000)\n",
      "meta_arrays.shape = (87726, 535)\n",
      "title_arrays.shape = (87726, 10000)\n",
      "desc_arrays.shape = (87726, 10000)\n",
      "Predict on untagged content\n"
     ]
    }
   ],
   "source": [
    "get_predictions(predict)"
   ]
  }
 ],
 "metadata": {
  "keep_output": true,
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
