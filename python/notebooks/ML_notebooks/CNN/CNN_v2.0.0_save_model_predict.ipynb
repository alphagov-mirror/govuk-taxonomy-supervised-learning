{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional NN to classify govuk content to level2 taxons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on:\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load requirements and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.utils import to_categorical, layer_utils, plot_model\n",
    "\n",
    "from keras.layers import (Embedding, Input, Dense, Dropout, \n",
    "                          Activation, Conv1D, MaxPooling1D, Flatten, concatenate, Reshape)\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.callbacks import TensorBoard, Callback, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score \n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import functools\n",
    "\n",
    "import h5py\n",
    "\n",
    "from scipy import sparse\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environmental vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATADIR = os.getenv('DATADIR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print data version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm running on data extracted from content store on /data/2018-03-21\n"
     ]
    }
   ],
   "source": [
    "print('algorithm running on data extracted from content store on {}'.format(DATADIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuition for POS_RATIO is that it penalises the prediction of zero for everything, which is attractive to the model because the multilabel y matrix is super sparse. \n",
    "\n",
    "Increasing POS_RATIO should penalise predicting zeros more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MAX_NB_WORDS\n",
    "MAX_SEQUENCE_LENGTH =1000\n",
    "EMBEDDING_DIM = 100 # keras embedding layer output_dim = Dimension of the dense embedding\n",
    "P_THRESHOLD = 0.5 #Threshold for probability of being assigned to class\n",
    "POS_RATIO = 0.5 #ratio of positive to negative for each class in weighted binary cross entropy loss function\n",
    "NUM_WORDS=20000 #keras tokenizer num_words: None or int. Maximum number of words to work with \n",
    "#(if set, tokenization will be restricted to the top num_words most common words in the dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = np.load(os.path.join(DATADIR, 'train_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'meta', 'title', 'desc', 'y', 'content_id']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (178809, 1000)\n",
      "meta_train.shape = (178809, 540)\n",
      "title_train.shape = (178809, 10000)\n",
      "desc_train.shape = (178809, 10000)\n",
      "y_train.shape = (178809, 217)\n"
     ]
    }
   ],
   "source": [
    "x_train = train['x']\n",
    "meta_train = train['meta'].all().todense()\n",
    "title_train = train['title'].all().todense()\n",
    "desc_train = train['desc'].all().todense()\n",
    "y_train = train['y'].all().todense()\n",
    "\n",
    "print('x_train.shape = {}'.format(x_train.shape))\n",
    "print('meta_train.shape = {}'.format(meta_train.shape))\n",
    "print('title_train.shape = {}'.format(title_train.shape))\n",
    "print('desc_train.shape = {}'.format(desc_train.shape))\n",
    "print('y_train.shape = {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dev = np.load(os.path.join(DATADIR, 'dev_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_dev.shape = (12913, 1000)\n",
      "meta_dev.shape = (12913, 540)\n",
      "title_dev.shape = (12913, 10000)\n",
      "desc_dev.shape = (12913, 10000)\n",
      "y_dev.shape = (12913, 217)\n"
     ]
    }
   ],
   "source": [
    "x_dev = dev['x']\n",
    "meta_dev = dev['meta'].all().todense()\n",
    "title_dev = dev['title'].all().todense()\n",
    "desc_dev = dev['desc'].all().todense()\n",
    "y_dev = dev['y'].all().todense()\n",
    "\n",
    "print('x_dev.shape = {}'.format(x_dev.shape))\n",
    "print('meta_dev.shape = {}'.format(meta_dev.shape))\n",
    "print('title_dev.shape = {}'.format(title_dev.shape))\n",
    "print('desc_dev.shape = {}'.format(desc_dev.shape))\n",
    "print('y_dev.shape = {}'.format(y_dev.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = np.load(os.path.join(DATADIR, 'test_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test.shape = (12915, 1000)\n",
      "meta_test.shape = (12915, 540)\n",
      "title_test.shape = (12915, 10000)\n",
      "desc_test.shape = (12915, 10000)\n",
      "y_test.shape = (12915, 217)\n"
     ]
    }
   ],
   "source": [
    "x_test = test['x']\n",
    "meta_test = test['meta'].all().todense()\n",
    "title_test = test['title'].all().todense()\n",
    "desc_test = test['desc'].all().todense()\n",
    "y_test = test['y'].all().todense()\n",
    "\n",
    "print('x_test.shape = {}'.format(x_test.shape))\n",
    "print('meta_test.shape = {}'.format(meta_test.shape))\n",
    "print('title_test.shape = {}'.format(title_test.shape))\n",
    "print('desc_test.shape = {}'.format(desc_test.shape))\n",
    "print('y_test.shape = {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### previous shapes in old data \n",
    "Shape of x_train: (150870, 1000)\n",
    "Shape of metax_train: (150870, 436)\n",
    "Shape of titlex_train: (150870, 10000)\n",
    "Shape of descx_train: (150870, 10000)\n",
    "Shape of y_train: (150870, 210)\n",
    "\n",
    "Shape of x_dev: (9234, 1000)\n",
    "Shape of meta_dev: (9234, 436)\n",
    "Shape of titlex_dev: (9234, 10000)\n",
    "Shape of descx_dev: (9234, 10000)\n",
    "Shape of y_dev: (9234, 210)\n",
    "\n",
    "Shape of x_test: (9234, 1000)\n",
    "Shape of metax_test: (9234, 436)\n",
    "Shape of titlex_test: (9234, 10000)\n",
    "Shape of descx_test: (9234, 10000)\n",
    "Shape of y_test: (9234, 210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing the Embedding layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "def load_tokenizer_from_file(filename):\n",
    "    \n",
    "    tokenizer = Tokenizer()\n",
    "\n",
    "    with open(filename, 'r') as infile:\n",
    "        tokenizer_data = json.load(infile)\n",
    "\n",
    "    tokenizer.word_counts = OrderedDict(tokenizer_data['word_counts'])\n",
    "    tokenizer.word_docs = tokenizer_data['word_docs']\n",
    "    tokenizer.word_index = tokenizer_data['word_index']\n",
    "    tokenizer.document_count = tokenizer_data['document_count']\n",
    "    tokenizer.index_docs = tokenizer_data['index_docs']\n",
    "\n",
    "    return tokenizer\n",
    "\n",
    "tokenizer_combined_text = load_tokenizer_from_file(os.path.join(DATADIR, \"combined_text_tokenizer.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(tokenizer_combined_text.word_index) + 1, \n",
    "                            EMBEDDING_DIM, \n",
    "                            input_length=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Embedding layer should be fed sequences of integers, i.e. a 2D input of shape (samples, indices). These input sequences should be padded so that they all have the same length in a batch of input data (although an Embedding layer is capable of processing sequence of heterogenous length, if you don't pass an explicit input_length argument to the layer).\n",
    "\n",
    "All that the Embedding layer does is to map the integer inputs to the vectors found at the corresponding index in the embedding matrix, i.e. the sequence [1, 2] would be converted to [embeddings[1], embeddings[2]]. This means that the output of the Embedding layer will be a 3D tensor of shape (samples, sequence_length, embedding_dim)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate class weights for unbalanced datasets.\n",
    "paramter to model.fit = __class_weight__: Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
    "\n",
    "Implement class_weight from sklearn:\n",
    "\n",
    "- Import the module \n",
    "\n",
    "`from sklearn.utils import class_weight`\n",
    "- calculate the class weight, If ‘balanced’, class weights will be given by n_samples / (n_classes * np.bincount(y)):\n",
    "\n",
    "`class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)`\n",
    "\n",
    "- change it to a dict in order to work with Keras.\n",
    "\n",
    "`class_weight_dict = dict(enumerate(class_weight))`\n",
    "\n",
    "- Add to model fitting\n",
    "\n",
    "`model.fit(X_train, y_train, class_weight=class_weight)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "# class_weight_dict = dict(enumerate(class_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.00756\n",
      "8.01512\n"
     ]
    }
   ],
   "source": [
    "class WeightedBinaryCrossEntropy(object):\n",
    "\n",
    "    def __init__(self, pos_ratio):\n",
    "        neg_ratio = 1. - pos_ratio\n",
    "        #self.pos_ratio = tf.constant(pos_ratio, tf.float32)\n",
    "        self.pos_ratio = pos_ratio\n",
    "        #self.weights = tf.constant(neg_ratio / pos_ratio, tf.float32)\n",
    "        self.weights = neg_ratio / pos_ratio\n",
    "        self.__name__ = \"weighted_binary_crossentropy({0})\".format(pos_ratio)\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        return self.weighted_binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "    def weighted_binary_crossentropy(self, y_true, y_pred):\n",
    "            # Transform to logits\n",
    "            epsilon = tf.convert_to_tensor(K.common._EPSILON, y_pred.dtype.base_dtype)\n",
    "            y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
    "            y_pred = tf.log(y_pred / (1 - y_pred))\n",
    "\n",
    "            cost = tf.nn.weighted_cross_entropy_with_logits(y_true, y_pred, self.weights)\n",
    "            return K.mean(cost * self.pos_ratio, axis=-1)\n",
    "    \n",
    "y_true_arr = np.array([0,1,0,1], dtype=\"float32\")\n",
    "y_pred_arr = np.array([0,0,1,1], dtype=\"float32\")\n",
    "y_true = tf.constant(y_true_arr)\n",
    "y_pred = tf.constant(y_pred_arr)\n",
    "\n",
    "with tf.Session().as_default(): \n",
    "    print(WeightedBinaryCrossEntropy(0.5)(y_true, y_pred).eval())\n",
    "    print(binary_crossentropy(y_true, y_pred).eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### difficulty getting global precision/recall metrics . CAUTION interpreting monitoring metrics\n",
    "fcholltet: \"Basically these are all global metrics that were approximated\n",
    "batch-wise, which is more misleading than helpful. This was mentioned in\n",
    "the docs but it's much cleaner to remove them altogether. It was a mistake\n",
    "to merge them in the first place.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    \"\"\"Use Recall  and precision metrics to calculate harmonic mean (F1 score).\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1 = 2*((precision*recall)/(precision+recall))\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a 1D convnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NB_CLASSES = y_train.shape[1]\n",
    "NB_METAVARS = meta_train.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='wordindex') #MAX_SEQUENCE_LENGTH\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Dropout(0.2, name = 'dropout_embedded')(embedded_sequences)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv0')(x)\n",
    "\n",
    "x = MaxPooling1D(5, name = 'max_pool0')(x)\n",
    "\n",
    "x = Dropout(0.5, name = 'dropout0')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv1')(x)\n",
    "\n",
    "x = MaxPooling1D(5 , name = 'max_pool1')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv2')(x)\n",
    "\n",
    "x = MaxPooling1D(35, name = 'global_max_pool')(x)  # global max pooling\n",
    "\n",
    "x = Flatten()(x) #reduce dimensions from 3 to 2; convert to vector + FULLYCONNECTED\n",
    "\n",
    "meta_input = Input(shape=(NB_METAVARS,), name='meta')\n",
    "meta_hidden = Dense(128, activation='relu', name = 'hidden_meta')(meta_input)\n",
    "meta_hidden = Dropout(0.2, name = 'dropout_meta')(meta_hidden)\n",
    "\n",
    "\n",
    "title_input = Input(shape=(title_train.shape[1],), name='titles')\n",
    "title_hidden = Dense(128, activation='relu', name = 'hidden_title')(title_input)\n",
    "title_hidden = Dropout(0.2, name = 'dropout_title')(title_hidden)\n",
    "\n",
    "desc_input = Input(shape=(desc_train.shape[1],), name='descs')\n",
    "desc_hidden = Dense(128, activation='relu', name = 'hidden_desc')(desc_input)\n",
    "desc_hidden = Dropout(0.2, name = 'dropout_desc')(desc_hidden)\n",
    "\n",
    "concatenated = concatenate([meta_hidden, title_hidden, desc_hidden, x])\n",
    "\n",
    "x = Dense(400, activation='relu', name = 'fully_connected0')(concatenated)\n",
    "\n",
    "x = Dropout(0.2, name = 'dropout1')(x)\n",
    "\n",
    "x = Dense(NB_CLASSES, activation='sigmoid', name = 'fully_connected1')(x)\n",
    "\n",
    "# # The Model class turns an input tensor and output tensor into a model\n",
    "# This creates Keras model instance, will use this instance to train/test the model.\n",
    "model = Model(inputs=[meta_input, title_input, desc_input, sequence_input], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "wordindex (InputLayer)          (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 100)    34758000    wordindex[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_embedded (Dropout)      (None, 1000, 100)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv1D)                  (None, 996, 128)     64128       dropout_embedded[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pool0 (MaxPooling1D)        (None, 199, 128)     0           conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout0 (Dropout)              (None, 199, 128)     0           max_pool0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv1D)                  (None, 195, 128)     82048       dropout0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pool1 (MaxPooling1D)        (None, 39, 128)      0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "meta (InputLayer)               (None, 540)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "titles (InputLayer)             (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "descs (InputLayer)              (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv1D)                  (None, 35, 128)      82048       max_pool1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hidden_meta (Dense)             (None, 128)          69248       meta[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "hidden_title (Dense)            (None, 128)          1280128     titles[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "hidden_desc (Dense)             (None, 128)          1280128     descs[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pool (MaxPooling1D)  (None, 1, 128)       0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_meta (Dropout)          (None, 128)          0           hidden_meta[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_title (Dropout)         (None, 128)          0           hidden_title[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_desc (Dropout)          (None, 128)          0           hidden_desc[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           global_max_pool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           dropout_meta[0][0]               \n",
      "                                                                 dropout_title[0][0]              \n",
      "                                                                 dropout_desc[0][0]               \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fully_connected0 (Dense)        (None, 400)          205200      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 400)          0           fully_connected0[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fully_connected1 (Dense)        (None, 217)          87017       dropout1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 37,907,945\n",
      "Trainable params: 37,907,945\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard callbacks /metrics /monitor training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **Size of these files is killing storage during training. Is it histograms?**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tb = TensorBoard(log_dir='./learn_embedding_logs', histogram_freq=1, write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = os.path.join(DATADIR, 'model_checkpoint.hdf5')\n",
    "\n",
    "cp = ModelCheckpoint(\n",
    "                     filepath = CHECKPOINT_PATH, \n",
    "                     monitor='val_loss', \n",
    "                     verbose=0, \n",
    "                     save_best_only=False, \n",
    "                     save_weights_only=False, \n",
    "                     mode='auto', \n",
    "                     period=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "#model.fit(x, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 & 3. Train & compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 178809 samples, validate on 12913 samples\n",
      "Epoch 1/10\n",
      "178809/178809 [==============================] - 188s 1ms/step - loss: 0.0086 - binary_accuracy: 0.9951 - f1: nan - val_loss: 0.0040 - val_binary_accuracy: 0.9973 - val_f1: 0.7775\n",
      "Epoch 2/10\n",
      "178809/178809 [==============================] - 182s 1ms/step - loss: 0.0030 - binary_accuracy: 0.9980 - f1: 0.8649 - val_loss: 0.0035 - val_binary_accuracy: 0.9976 - val_f1: 0.8074\n",
      "Epoch 3/10\n",
      "178809/178809 [==============================] - 182s 1ms/step - loss: 0.0023 - binary_accuracy: 0.9985 - f1: 0.8995 - val_loss: 0.0035 - val_binary_accuracy: 0.9976 - val_f1: 0.8149\n",
      "Epoch 4/10\n",
      "178809/178809 [==============================] - 182s 1ms/step - loss: 0.0019 - binary_accuracy: 0.9987 - f1: 0.9165 - val_loss: 0.0034 - val_binary_accuracy: 0.9978 - val_f1: 0.8231\n",
      "Epoch 5/10\n",
      "178809/178809 [==============================] - 182s 1ms/step - loss: 0.0017 - binary_accuracy: 0.9989 - f1: 0.9260 - val_loss: 0.0034 - val_binary_accuracy: 0.9978 - val_f1: 0.8276\n",
      "Epoch 6/10\n",
      "178809/178809 [==============================] - 182s 1ms/step - loss: 0.0016 - binary_accuracy: 0.9989 - f1: 0.9321 - val_loss: 0.0037 - val_binary_accuracy: 0.9978 - val_f1: 0.8270\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=WeightedBinaryCrossEntropy(POS_RATIO),\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['binary_accuracy', f1])\n",
    "\n",
    "# This `fit` call will be distributed on 8 GPUs.\n",
    "# Since the batch size is 256, each GPU will process 32 samples.\n",
    "history = model.fit(\n",
    "    {'meta': meta_train, 'titles': title_train, 'descs': desc_train, 'wordindex': x_train},\n",
    "    y_train, \n",
    "    validation_data=([meta_dev, title_dev, desc_dev, x_dev], y_dev), \n",
    "    epochs=10, batch_size=128, callbacks=[early_stopping]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_binary_accuracy', 'val_f1', 'loss', 'binary_accuracy', 'f1'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmRXEQWJmZgVxkJiZWUH+P1iEGCxZY+RVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8c4fe75278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(range(len(loss_values)), loss_values, 'bo', label='Training loss')           \n",
    "plt.plot(range(len(val_loss_values)), val_loss_values, 'b', label='Validation loss')      \n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzMysKCcLMzMr6v8D0uI0jFWDjOgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8c4fa1e278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()    \n",
    "\n",
    "f1_values = history_dict['f1']\n",
    "val_f1_values = history_dict['val_f1']\n",
    "\n",
    "plt.plot(range(len(f1_values)), f1_values, 'bo', label='Training f1')\n",
    "plt.plot(range(len(val_f1_values)), val_f1_values, 'b', label='Validation f1')\n",
    "plt.title('Training and validation batch-level f1-micro')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1-micro')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_file(array,name):\n",
    "    df = pd.DataFrame(data = array.tolist(),columns=[i for i in range(1,y_train.shape[1]+1)])\n",
    "    df.to_csv(os.path.join(DATADIR, name+'.csv.gz'),compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_1255_2103_'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_run = time.strftime(\"_%H%M_%d%m_\")\n",
    "date_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict([meta_train, title_train, desc_train, x_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_prob,\"train_results\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_prob.copy()\n",
    "y_pred[y_pred>=P_THRESHOLD] = 1\n",
    "y_pred[y_pred<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro: (0.96552665598694754, 0.95143676763747753, 0.95842993071110905, None)\n",
      "macro: (0.97705776181177462, 0.97049648772145003, 0.97340537192087695, None)\n",
      "weightedmacro: (0.96559402583071252, 0.95143676763747753, 0.95805487855414162, None)\n"
     ]
    }
   ],
   "source": [
    "print('micro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='micro', sample_weight=None)))\n",
    "print('macro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='macro', sample_weight=None)))\n",
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='weighted', sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_dev = model.predict([meta_dev, title_dev, desc_dev, x_dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_prob_dev,\"dev_results\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dev = y_prob_dev.copy()\n",
    "y_pred_dev[y_pred_dev>=P_THRESHOLD] = 1\n",
    "y_pred_dev[y_pred_dev<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro: (0.84620297259637711, 0.80895820613864688, 0.827161544791578, None)\n",
      "macro: (0.76523856545784863, 0.81719615325911166, 0.78168519384474788, None)\n",
      "weightedmacro: (0.85004933739745747, 0.80895820613864688, 0.82596224389495732, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('micro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='micro', sample_weight=None)))\n",
    "print('macro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='macro', sample_weight=None)))\n",
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='weighted', sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weightedmacro: (array([ 1.        ,  1.        ,  0.93913043,  0.63333333,  1.        ,\n",
      "        0.73809524,  0.8125    ,  0.80555556,  0.        ,  0.90625   ,\n",
      "        1.        ,  0.99770379,  0.        ,  1.        ,  0.52631579,\n",
      "        0.        ,  0.72      ,  1.        ,  1.        ,  0.85211268,\n",
      "        0.86550778,  0.71563981,  0.77826087,  0.        ,  1.        ,\n",
      "        1.        ,  0.5       ,  1.        ,  1.        ,  0.85      ,\n",
      "        0.77777778,  0.8       ,  0.6       ,  1.        ,  0.55555556,\n",
      "        0.85150376,  0.75      ,  0.55      ,  0.80918728,  0.92857143,\n",
      "        0.78723404,  0.        ,  0.5625    ,  0.85964912,  1.        ,\n",
      "        1.        ,  0.73333333,  0.81818182,  0.        ,  0.90909091,\n",
      "        0.82269504,  1.        ,  1.        ,  0.35714286,  0.        ,\n",
      "        0.83333333,  1.        ,  0.        ,  0.92569659,  0.78571429,\n",
      "        0.76388889,  0.8125    ,  0.66666667,  0.88888889,  0.64516129,\n",
      "        1.        ,  0.78443114,  0.7755102 ,  1.        ,  1.        ,\n",
      "        0.56      ,  1.        ,  0.8       ,  1.        ,  0.75471698,\n",
      "        0.85714286,  0.93877551,  0.81314879,  0.        ,  0.87084871,\n",
      "        0.        ,  0.71794872,  0.86666667,  0.90510949,  0.88141391,\n",
      "        1.        ,  0.        ,  0.79699248,  0.        ,  1.        ,\n",
      "        1.        ,  0.53571429,  0.        ,  0.89489489,  0.83333333,\n",
      "        0.80208333,  1.        ,  1.        ,  1.        ,  0.875     ,\n",
      "        0.71428571,  0.84615385,  0.92307692,  0.64285714,  1.        ,\n",
      "        0.86363636,  0.85714286,  0.75      ,  1.        ,  0.71428571,\n",
      "        0.94444444,  0.75      ,  0.42857143,  1.        ,  1.        ,\n",
      "        1.        ,  0.66666667,  1.        ,  0.6       ,  0.76036866,\n",
      "        0.79545455,  0.86666667,  0.68181818,  0.6875    ,  0.89230769,\n",
      "        0.98039216,  1.        ,  0.76923077,  0.5       ,  0.93939394,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  0.83333333,\n",
      "        0.80313199,  0.73076923,  0.83953033,  0.84      ,  1.        ,\n",
      "        0.88888889,  0.        ,  1.        ,  0.8       ,  0.81927711,\n",
      "        0.94117647,  0.79807692,  0.9245283 ,  0.66666667,  0.5       ,\n",
      "        1.        ,  0.66666667,  0.93914807,  0.        ,  1.        ,\n",
      "        0.        ,  0.875     ,  0.9330855 ,  0.49152542,  1.        ,\n",
      "        1.        ,  1.        ,  0.88114754,  0.86075949,  0.83615819,\n",
      "        0.84444444,  0.76      ,  0.85      ,  0.96638655,  0.88235294,\n",
      "        0.87234043,  0.75      ,  0.        ,  0.22222222,  0.66666667,\n",
      "        0.81578947,  0.83333333,  0.85576923,  0.85714286,  1.        ,\n",
      "        0.        ,  0.92857143,  1.        ,  0.72222222,  0.88888889,\n",
      "        0.84      ,  0.87878788,  0.71428571,  0.7       ,  0.79763912,\n",
      "        0.84615385,  0.81395349,  1.        ,  0.81818182,  1.        ,\n",
      "        1.        ,  0.62159329,  1.        ,  0.54901961,  0.        ,\n",
      "        0.8       ,  0.88235294,  0.87012987,  1.        ,  0.        ,\n",
      "        0.92361111,  0.8       ,  0.65957447,  0.9047619 ,  0.78333333,\n",
      "        0.80346821,  1.        ,  0.80952381,  1.        ,  0.875     ,\n",
      "        0.57142857,  0.93630573]), array([ 1.        ,  1.        ,  0.9       ,  1.        ,  1.        ,\n",
      "        0.5       ,  1.        ,  0.77540107,  0.        ,  0.90625   ,\n",
      "        1.        ,  0.9786036 ,  0.        ,  1.        ,  0.85714286,\n",
      "        0.        ,  0.9       ,  1.        ,  1.        ,  0.85815603,\n",
      "        0.78246485,  0.69266055,  0.90862944,  0.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  0.75      ,\n",
      "        0.80319149,  1.        ,  0.84615385,  0.58567775,  1.        ,\n",
      "        0.40659341,  0.        ,  0.44262295,  0.86982249,  1.        ,\n",
      "        0.99692308,  0.81481481,  1.        ,  0.        ,  0.86956522,\n",
      "        0.76315789,  1.        ,  1.        ,  1.        ,  0.        ,\n",
      "        1.        ,  1.        ,  0.        ,  0.86167147,  1.        ,\n",
      "        0.64327485,  1.        ,  1.        ,  1.        ,  0.60606061,\n",
      "        1.        ,  0.54356846,  0.68468468,  1.        ,  0.95945946,\n",
      "        0.875     ,  1.        ,  1.        ,  1.        ,  0.52631579,\n",
      "        0.96774194,  0.82142857,  0.83629893,  0.        ,  0.85818182,\n",
      "        0.        ,  0.96551724,  1.        ,  0.84353741,  0.82059448,\n",
      "        1.        ,  0.        ,  0.56084656,  0.        ,  1.        ,\n",
      "        1.        ,  0.88235294,  0.        ,  0.83943662,  0.80882353,\n",
      "        0.73333333,  1.        ,  1.        ,  1.        ,  0.92105263,\n",
      "        0.73529412,  0.63768116,  0.83965015,  0.9       ,  1.        ,\n",
      "        1.        ,  1.        ,  0.92307692,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  0.73333333,\n",
      "        0.875     ,  0.70909091,  0.88235294,  0.91666667,  0.84057971,\n",
      "        0.95238095,  1.        ,  0.63380282,  1.        ,  0.94897959,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.81405896,  0.95      ,  0.825     ,  0.85714286,  1.        ,\n",
      "        1.        ,  0.        ,  1.        ,  1.        ,  0.7816092 ,\n",
      "        0.88888889,  0.73451327,  0.765625  ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.82092199,  0.        ,  1.        ,\n",
      "        0.        ,  0.77777778,  0.94360902,  0.46774194,  0.93333333,\n",
      "        1.        ,  1.        ,  0.907173  ,  0.72340426,  0.75126904,\n",
      "        0.92682927,  1.        ,  0.61818182,  0.79310345,  0.78703704,\n",
      "        0.7961165 ,  1.        ,  0.        ,  1.        ,  1.        ,\n",
      "        0.62837838,  0.90909091,  0.64492754,  1.        ,  1.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.76470588,  1.        ,\n",
      "        0.91304348,  0.83653846,  1.        ,  0.84      ,  0.80033841,\n",
      "        1.        ,  0.74468085,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  0.64526659,  1.        ,  0.71794872,  0.        ,\n",
      "        1.        ,  1.        ,  0.84810127,  1.        ,  0.        ,\n",
      "        0.88666667,  0.704     ,  0.83783784,  0.95      ,  0.8245614 ,\n",
      "        0.78089888,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  0.89634146]), array([ 1.        ,  1.        ,  0.91914894,  0.7755102 ,  1.        ,\n",
      "        0.59615385,  0.89655172,  0.79019074,  0.        ,  0.90625   ,\n",
      "        1.        ,  0.9880614 ,  0.        ,  1.        ,  0.65217391,\n",
      "        0.        ,  0.8       ,  1.        ,  1.        ,  0.85512367,\n",
      "        0.82189401,  0.7039627 ,  0.83840749,  0.        ,  1.        ,\n",
      "        1.        ,  0.66666667,  1.        ,  1.        ,  0.91891892,\n",
      "        0.875     ,  0.88888889,  0.75      ,  1.        ,  0.63829787,\n",
      "        0.82664234,  0.85714286,  0.66666667,  0.67952522,  0.96296296,\n",
      "        0.53623188,  0.        ,  0.49541284,  0.86470588,  1.        ,\n",
      "        0.99845917,  0.77192982,  0.9       ,  0.        ,  0.88888889,\n",
      "        0.79180887,  1.        ,  1.        ,  0.52631579,  0.        ,\n",
      "        0.90909091,  1.        ,  0.        ,  0.89253731,  0.88      ,\n",
      "        0.6984127 ,  0.89655172,  0.8       ,  0.94117647,  0.625     ,\n",
      "        1.        ,  0.64215686,  0.72727273,  1.        ,  0.97931034,\n",
      "        0.68292683,  1.        ,  0.88888889,  1.        ,  0.62015504,\n",
      "        0.90909091,  0.87619048,  0.8245614 ,  0.        ,  0.86446886,\n",
      "        0.        ,  0.82352941,  0.92857143,  0.87323944,  0.84991754,\n",
      "        1.        ,  0.        ,  0.65838509,  0.        ,  1.        ,\n",
      "        1.        ,  0.66666667,  0.        ,  0.86627907,  0.82089552,\n",
      "        0.76616915,  1.        ,  1.        ,  1.        ,  0.8974359 ,\n",
      "        0.72463768,  0.72727273,  0.87938931,  0.75      ,  1.        ,\n",
      "        0.92682927,  0.92307692,  0.82758621,  1.        ,  0.83333333,\n",
      "        0.97142857,  0.85714286,  0.6       ,  1.        ,  1.        ,\n",
      "        1.        ,  0.8       ,  1.        ,  0.75      ,  0.74660633,\n",
      "        0.83333333,  0.78      ,  0.76923077,  0.78571429,  0.86567164,\n",
      "        0.96618357,  1.        ,  0.69498069,  0.66666667,  0.94416244,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  0.90909091,\n",
      "        0.80855856,  0.82608696,  0.83220175,  0.84848485,  1.        ,\n",
      "        0.94117647,  0.        ,  1.        ,  0.88888889,  0.8       ,\n",
      "        0.91428571,  0.76497696,  0.83760684,  0.8       ,  0.66666667,\n",
      "        1.        ,  0.8       ,  0.87606433,  0.        ,  1.        ,\n",
      "        0.        ,  0.82352941,  0.93831776,  0.47933884,  0.96551724,\n",
      "        1.        ,  1.        ,  0.89397089,  0.78612717,  0.79144385,\n",
      "        0.88372093,  0.86363636,  0.71578947,  0.87121212,  0.8319739 ,\n",
      "        0.83248731,  0.85714286,  0.        ,  0.36363636,  0.8       ,\n",
      "        0.70992366,  0.86956522,  0.73553719,  0.92307692,  1.        ,\n",
      "        0.        ,  0.96296296,  1.        ,  0.74285714,  0.94117647,\n",
      "        0.875     ,  0.85714286,  0.83333333,  0.76363636,  0.79898649,\n",
      "        0.91666667,  0.77777778,  1.        ,  0.9       ,  1.        ,\n",
      "        1.        ,  0.63320876,  1.        ,  0.62222222,  0.        ,\n",
      "        0.88888889,  0.9375    ,  0.85897436,  1.        ,  0.        ,\n",
      "        0.9047619 ,  0.74893617,  0.73809524,  0.92682927,  0.8034188 ,\n",
      "        0.79202279,  1.        ,  0.89473684,  1.        ,  0.93333333,\n",
      "        0.72727273,  0.91588785]), array([   1,    5,  120,   19,   41,   62,   13,  187,    0,   32,    2,\n",
      "        888,    0,    2,   35,    0,   20,    1,    1,  141, 1209,  218,\n",
      "        197,    0,    4,    3,    3,    1,    4,   17,   14,    8,    6,\n",
      "          1,   40,  564,    6,   26,  391,   13,   91,    0,   61,  169,\n",
      "          5,  975,   27,    9,    0,   23,  152,    3,    6,    5,    0,\n",
      "          5,    2,    0,  347,   11,  171,   13,    4,    8,   33,    1,\n",
      "        241,  111,    2,   74,   16,    2,    4,    6,   76,   31,  112,\n",
      "        281,    0,  275,    0,   29,   13,  147,  942,    1,    0,  189,\n",
      "          0,    5,    4,   17,    0,  355,  340,  105,    4,    6,   24,\n",
      "         38,   34,   69,  343,   30,    2,   19,    6,   39,    2,    5,\n",
      "         17,    3,    3,   19,    3,    1,    2,    2,    3,  225,   40,\n",
      "         55,   17,   12,   69,  210,    2,  142,    1,   98,    3,    3,\n",
      "          2,    1,    5,  441,   20,  520,   98,    1,    8,    0,    3,\n",
      "          4,   87,   18,  113,   64,    4,    1,    2,    2,  564,    0,\n",
      "          3,    0,   27,  266,   62,   15,    4,    4,  237,   94,  197,\n",
      "         41,   19,   55,  145,  324,  103,    3,    0,    4,    2,  148,\n",
      "         22,  138,    6,    3,    0,   13,    4,   17,    8,   23,  104,\n",
      "          5,   25,  591,   11,  141,    8,    9,    3,    1,  919,    2,\n",
      "         39,    0,    8,   15,   79,    2,    0,  150,  125,   37,   20,\n",
      "         57,  178,    1,   17,    5,    7,    4,  164]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average=None, sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_train,\"true_train\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_dev,\"true_dev\"+date_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(data_to_tag): \n",
    "    filename = data_to_tag+\"_arrays.npz\"\n",
    "    arrays = np.load(os.path.join(DATADIR,filename))\n",
    "    \n",
    "    print('Set up arrays for new_content: {}'.format(arrays.files))\n",
    "    x_predict = arrays['x']\n",
    "    meta_predict = arrays['meta'].all().todense()\n",
    "    title_predict = arrays['title'].all().todense()\n",
    "    desc_predict = arrays['desc'].all().todense()\n",
    "    \n",
    "    print('x_arrays.shape = {}'.format(x_predict.shape))\n",
    "    print('meta_arrays.shape = {}'.format(meta_predict.shape))\n",
    "    print('title_arrays.shape = {}'.format(title_predict.shape))\n",
    "    print('desc_arrays.shape = {}'.format(desc_predict.shape))\n",
    "    \n",
    "    print('Predict on untagged content')\n",
    "    y_pred_new = model.predict([meta_predict, title_predict, desc_predict, x_predict])\n",
    "    \n",
    "    to_file(y_pred_new, data_to_tag+\"_predictions\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up arrays for new_content: ['x', 'meta', 'title', 'desc', 'content_id']\n",
      "x_arrays.shape = (58609, 1000)\n",
      "meta_arrays.shape = (58609, 540)\n",
      "title_arrays.shape = (58609, 10000)\n",
      "desc_arrays.shape = (58609, 10000)\n",
      "Predict on untagged content\n"
     ]
    }
   ],
   "source": [
    "get_predictions(\"new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_predictions_1255_2103_\n"
     ]
    }
   ],
   "source": [
    "print(\"new_predictions\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up arrays for new_content: ['x', 'meta', 'title', 'desc', 'content_id']\n",
      "x_arrays.shape = (18273, 1000)\n",
      "meta_arrays.shape = (18273, 540)\n",
      "title_arrays.shape = (18273, 10000)\n",
      "desc_arrays.shape = (18273, 10000)\n",
      "Predict on untagged content\n"
     ]
    }
   ],
   "source": [
    "get_predictions(\"level1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level1_predictions_1255_2103_\n"
     ]
    }
   ],
   "source": [
    "print(\"level1_predictions\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "keep_output": true,
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
