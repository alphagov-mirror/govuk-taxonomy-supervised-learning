{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost to classify govuk content to level2 taxons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load requirements and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-abbe28b50a6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# If you want to avoid the OneVsRestClassifier magic switch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score \n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "# If you want to avoid the OneVsRestClassifier magic switch\n",
    "# from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import functools\n",
    "\n",
    "import h5py\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environmental vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATADIR=os.getenv('DATADIR')\n",
    "#DATADIR='/data' #this was put in for AWS run but doesn't work locally..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuition for POS_RATIO is that it penalises the prediction of zero for everything, which is attractive to the model because the multilabel y matrix is super sparse. \n",
    "\n",
    "Increasing POS_RATIO should penalise predicting zeros more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MAX_NB_WORDS\n",
    "MAX_SEQUENCE_LENGTH =1000\n",
    "EMBEDDING_DIM = 100 # keras embedding layer output_dim = Dimension of the dense embedding\n",
    "P_THRESHOLD = 0.5 #Threshold for probability of being assigned to class\n",
    "POS_RATIO = 0.5 #ratio of positive to negative for each class in weighted binary cross entropy loss function\n",
    "NUM_WORDS=20000 #keras tokenizer num_words: None or int. Maximum number of words to work with \n",
    "#(if set, tokenization will be restricted to the top num_words most common words in the dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data\n",
    "Content items tagged to level 2 taxons or lower in the topic taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labelled_level2 = pd.read_csv(os.path.join(DATADIR, 'labelled_level2_enriched_world_filtered.csv.gz'), dtype=object, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173560, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_level2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114048"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_level2['content_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean up any World taxons leftover despite dropping relevant doctypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#COLLAPSE World level2taxons\n",
    "labelled_level2.loc[labelled_level2['level1taxon'] == 'World', 'level2taxon'] = 'world_level1'\n",
    "\n",
    "#creating categorical variable for level2taxons from values\n",
    "labelled_level2['level2taxon'] = labelled_level2['level2taxon'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#count the number of content items per taxon into new column\n",
    "labelled_level2['num_content_per_taxon'] = labelled_level2.groupby([\"level2taxon\"])['level2taxon'].transform(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    173560.000000\n",
       "mean       4574.207145\n",
       "std        3682.635048\n",
       "min           1.000000\n",
       "25%        1500.000000\n",
       "50%        3780.000000\n",
       "75%        6156.000000\n",
       "max       11717.000000\n",
       "Name: num_content_per_taxon, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_level2['num_content_per_taxon'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11717"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of rows in biggest level2 taxon -this is the target size for all other level2 taxons in resampling\n",
    "max_content_freq = max(labelled_level2['num_content_per_taxon'])\n",
    "max_content_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173560, 23)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_level2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3927, 23)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_level2[(labelled_level2['document_type'] == 'world_news_story')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33214, 23)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_level2[(labelled_level2['document_type'] == 'news_story')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nonews = labelled_level2[(labelled_level2['document_type'] != 'news_story') &\n",
    "                         (labelled_level2['document_type'] != 'world_news_story')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136419, 23)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary mapping taxon codes to string labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the category numeric values (codes) and avoid zero-indexing\n",
    "labels = nonews['level2taxon'].cat.codes + 1\n",
    "\n",
    "#create dictionary of taxon category code to string label for use in model evaluation\n",
    "labels_index = dict(zip((labels), nonews['level2taxon']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#labels_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210\n"
     ]
    }
   ],
   "source": [
    "print(len(labels_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create target/Y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: when using the categorical_crossentropy loss, your targets should be in categorical format (e.g. if you have 10 classes, the target for each sample should be a 10-dimensional vector that is all-zeros expect for a 1 at the index corresponding to the class of the sample)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In multilabel learning, the joint set of binary classification tasks is expressed with label binary indicator array: each sample is one row of a 2d array of shape (n_samples, n_classes) with binary values:  \n",
    "the one, i.e. the non zero elements, corresponds to the subset of labels.  \n",
    "An array such as np.array([[1, 0, 0], [0, 1, 1], [0, 0, 0]]) represents label 0 in the first sample, labels 1 and 2 in the second sample, and no labels in the third sample.  \n",
    "Producing multilabel data as a list of sets of labels may be more intuitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  First reshape wide to get columns for each level2taxon and row number = number unique urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique level2taxons: 210\n"
     ]
    }
   ],
   "source": [
    "#get a smaller copy of data for pivoting ease (think you can work from full data actually and other cols get droopedauto)\n",
    "\n",
    "level2_reduced = nonews[['content_id', \n",
    "                         'level2taxon', \n",
    "                         'combined_text', \n",
    "                         'title', \n",
    "                         'description',\n",
    "                         'document_type', \n",
    "                            'first_published_at', \n",
    "                            'publishing_app', \n",
    "                            'primary_publishing_organisation']].copy()\n",
    "\n",
    "#how many level2taxons are there?\n",
    "print('Number of unique level2taxons: {}'.format(level2_reduced.level2taxon.nunique()))\n",
    "\n",
    "#count the number of taxons per content item into new column\n",
    "level2_reduced['num_taxon_per_content'] = level2_reduced.groupby([\"content_id\"])['content_id'].transform(\"count\")\n",
    "\n",
    "#Add 1 because of zero-indexing to get 1-number of level2taxons as numerical targets\n",
    "level2_reduced['level2taxon_code'] = level2_reduced.level2taxon.astype('category').cat.codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique level2taxons: 210\n"
     ]
    }
   ],
   "source": [
    "#how many level2taxons are there?\n",
    "print('Number of unique level2taxons: {}'.format(labelled_level2.level2taxon.nunique()))\n",
    "\n",
    "#count the number of taxons per content item into new column\n",
    "labelled_level2['num_taxon_per_content'] = labelled_level2.groupby([\"content_id\"])['content_id'].transform(\"count\")\n",
    "\n",
    "#Add 1 because of zero-indexing to get 1-number of level2taxons as numerical targets\n",
    "labelled_level2['level2taxon_code'] = labelled_level2.level2taxon.astype('category').cat.codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level2reduced shape: (136419, 11)\n",
      "pivot table shape (no duplicates): (92338, 210) \n"
     ]
    }
   ],
   "source": [
    "#reshape to wide per taxon and keep the combined text so indexing is consistent when splitting X from Y\n",
    "\n",
    "multilabel = (level2_reduced.pivot_table(index=['content_id', \n",
    "                                                'combined_text', \n",
    "                                                'title', \n",
    "                                                'description' \n",
    "                                                ] , columns='level2taxon_code', values='num_taxon_per_content'))\n",
    "print('level2reduced shape: {}'.format(level2_reduced.shape))\n",
    "print('pivot table shape (no duplicates): {} '.format(multilabel.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
       "            ...\n",
       "            201, 202, 203, 204, 205, 206, 207, 208, 209, 210],\n",
       "           dtype='int64', name='level2taxon_code', length=210)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>level2taxon_code</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_id</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00029fa4-9b60-4285-898c-85ae8a6367f5</th>\n",
       "      <th>emma jones - small business crown representative as small business crown representative emma is keen to help uk smes win government business. emma was appointed as small business crown representative in july 2016. she was selected for the role because of her wealth of experience in working with smes. she is the founder of small business support group enterprise nation and the co-founder of startup britain. emma’s work in her role as small business crown representative includes: working with government and the small business panel to identify the remaining barriers to smes doing business with the public sector supporting the launch and delivery of the campaign to help show that government is “open for business” for smes and helping them bid for and win more contracts increasing awareness among smaller businesses of opportunities to deliver on behalf of larger private sector firms who have secured government contracts working with government to identify new opportunities to get best value from smes getting support emma is keen to hear what small business have to say and wants to engage with as many smes as possible. so if you’re thinking about becoming a government supplier take a look at the events and opportunities below for how to get involved and gain support. events the leeds cross government sme roadshow - 24 november 2017 - is a great opportunity for smes to hear directly about the opportunities to sell to the public sector. more information about the event and how to register can be found here. webinars register for free for emma’s half-hour webinars offering advice on how to become a government supplier. a list of webinars coming up is featured below. blogs read emma’s blogs to gain useful insight updates and tips for smes and government buyers. these smes did it and so can you! prompt payment makes for good business 2017 a big year for small businesses calling central government buyers: emma can help you meet your target small business saturday dec 2016: top tips for selling to government selling to the public sector guide in partner with the crown commercial service emma has developed a guide for small businesses with tips on selling to government. read here . government is open for business ‘open for business’ is the government’s campaign to reach more smes as potential suppliers: to help and support them to become suppliers and to listen to how government can improve the process. for more information visit www.gov.uk/openforbusiness register with contracts finder to keep updated on new and upcoming contracts worth over £10 000. for inspiration on how other small business have grown and benefitted from being a supplier government read our case studies . if you would like to help in getting the message out that government is open for business then visit the resources page for ways in which you can support.</th>\n",
       "      <th>emma jones - small business crown representative</th>\n",
       "      <th>as small business crown representative emma is keen to help uk smes win government business.</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00037b70-5b08-44c2-bf0a-fa8eb636a60b</th>\n",
       "      <th>land remediation: bringing brownfield sites back to use brochure showing uk expertise in land remediation outlining technologies systems and ideas used in the regeneration of industrial land. the uk was the first industrialised country in the world. the legacy of the industrial revolution is over 400 000 hectares of contaminated land. uk expertise in land remediation has been borne out of necessity. the department for international trade’s ( dit ) brochure provides an overview of the expertise gained from over 5 decades of experience in land remediation. the brochure includes information on: sector specialists urban regeneration spill response monitoring and validation corporate liability management innovation industry bodies how dit can help this was published originally by uk trade and investment which has since moved to the department for international trade ( dit ).</th>\n",
       "      <th>land remediation: bringing brownfield sites back to use</th>\n",
       "      <th>brochure showing uk expertise in land remediation outlining technologies systems and ideas used in the regeneration of industrial land.</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00037ee5-7b5e-452d-a233-af2c134f5bce</th>\n",
       "      <th>steps 2 success:ni statistics from october 2014 to september 2016 details on the number of referrals and starts on the steps 2 success programme and the number of moves into employment up to 30 sept 2016 statistics presented include details on the number of referrals and starts to the steps 2 success programme up to 30 september 2016.</th>\n",
       "      <th>steps 2 success:ni statistics from october 2014 to september 2016</th>\n",
       "      <th>details on the number of referrals and starts on the steps 2 success programme and the number of moves into employment up to 30 sept 2016</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004c63d-ae16-432a-bb35-c0f949b1e27c</th>\n",
       "      <th>student support applications for higher education: september 2016 data includes the number of applications received and grants awarded. these monthly statistics present information on applications for student support and tuition fee loans and tuition fee grants which include data for welsh domiciled students (wherever they study) and eu domiciled students studying in wales.</th>\n",
       "      <th>student support applications for higher education: september 2016</th>\n",
       "      <th>data includes the number of applications received and grants awarded.</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0005ac76-50fe-42f1-8168-8b6fc046e40f</th>\n",
       "      <th>advice for building owners: large-scale wall system test 2 advice for building owners on the large-scale wall system test with acm with a polyethylene filler cladding with stone wool insulation. the government is undertaking large scale testing of cladding systems to understand better how 3 different types of aluminium composite material ( acm ) panels behave in combination with 2 different types of insulation in a fire. this note sets out advice to building owners following the results of the large scale test for a wall system including: acm with unmodified polyethylene filler (category 3 in screening tests) stone wool insulation. this should be read alongside the government’s explanatory note on the large scale wall systems testing .</th>\n",
       "      <th>advice for building owners: large-scale wall system test 2</th>\n",
       "      <th>advice for building owners on the large-scale wall system test with acm with a polyethylene filler cladding with stone wool insulation.</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "level2taxon_code                                                                                                                                                                               1    \\\n",
       "content_id                           combined_text                                      title                                              description                                               \n",
       "00029fa4-9b60-4285-898c-85ae8a6367f5 emma jones - small business crown representativ... emma jones - small business crown representative   as small business crown representative emma is ...  NaN   \n",
       "00037b70-5b08-44c2-bf0a-fa8eb636a60b land remediation: bringing brownfield sites bac... land remediation: bringing brownfield sites bac... brochure showing uk expertise in land remediati...  NaN   \n",
       "00037ee5-7b5e-452d-a233-af2c134f5bce steps 2 success:ni statistics from october 2014... steps 2 success:ni statistics from october 2014... details on the number of referrals and starts o...  NaN   \n",
       "0004c63d-ae16-432a-bb35-c0f949b1e27c student support applications for higher educati... student support applications for higher educati... data includes the number of applications receiv...  NaN   \n",
       "0005ac76-50fe-42f1-8168-8b6fc046e40f advice for building owners: large-scale wall sy... advice for building owners: large-scale wall sy... advice for building owners on the large-scale w...  NaN   \n",
       "\n",
       "level2taxon_code                                                                                                                                                                               2    \\\n",
       "content_id                           combined_text                                      title                                              description                                               \n",
       "00029fa4-9b60-4285-898c-85ae8a6367f5 emma jones - small business crown representativ... emma jones - small business crown representative   as small business crown representative emma is ...  NaN   \n",
       "00037b70-5b08-44c2-bf0a-fa8eb636a60b land remediation: bringing brownfield sites bac... land remediation: bringing brownfield sites bac... brochure showing uk expertise in land remediati...  NaN   \n",
       "00037ee5-7b5e-452d-a233-af2c134f5bce steps 2 success:ni statistics from october 2014... steps 2 success:ni statistics from october 2014... details on the number of referrals and starts o...  NaN   \n",
       "0004c63d-ae16-432a-bb35-c0f949b1e27c student support applications for higher educati... student support applications for higher educati... data includes the number of applications receiv...  NaN   \n",
       "0005ac76-50fe-42f1-8168-8b6fc046e40f advice for building owners: large-scale wall sy... advice for building owners: large-scale wall sy... advice for building owners on the large-scale w...  NaN   \n",
       "\n",
       "level2taxon_code                                                                                                                                                                               3    \\\n",
       "content_id                           combined_text                                      title                                              description                                               \n",
       "00029fa4-9b60-4285-898c-85ae8a6367f5 emma jones - small business crown representativ... emma jones - small business crown representative   as small business crown representative emma is ...  NaN   \n",
       "00037b70-5b08-44c2-bf0a-fa8eb636a60b land remediation: bringing brownfield sites bac... land remediation: bringing brownfield sites bac... brochure showing uk expertise in land remediati...  NaN   \n",
       "00037ee5-7b5e-452d-a233-af2c134f5bce steps 2 success:ni statistics from october 2014... steps 2 success:ni statistics from october 2014... details on the number of referrals and starts o...  NaN   \n",
       "0004c63d-ae16-432a-bb35-c0f949b1e27c student support applications for higher educati... student support applications for higher educati... data includes the number of applications receiv...  NaN   \n",
       "0005ac76-50fe-42f1-8168-8b6fc046e40f advice for building owners: large-scale wall sy... advice for building owners: large-scale wall sy... advice for building owners on the large-scale w...  NaN   \n",
       "\n",
       "level2taxon_code                                                                                                                                                                               4    \\\n",
       "content_id                           combined_text                                      title                                              description                                               \n",
       "00029fa4-9b60-4285-898c-85ae8a6367f5 emma jones - small business crown representativ... emma jones - small business crown representative   as small business crown representative emma is ...  NaN   \n",
       "00037b70-5b08-44c2-bf0a-fa8eb636a60b land remediation: bringing brownfield sites bac... land remediation: bringing brownfield sites bac... brochure showing uk expertise in land remediati...  NaN   \n",
       "00037ee5-7b5e-452d-a233-af2c134f5bce steps 2 success:ni statistics from october 2014... steps 2 success:ni statistics from october 2014... details on the number of referrals and starts o...  NaN   \n",
       "0004c63d-ae16-432a-bb35-c0f949b1e27c student support applications for higher educati... student support applications for higher educati... data includes the number of applications receiv...  NaN   \n",
       "0005ac76-50fe-42f1-8168-8b6fc046e40f advice for building owners: large-scale wall sy... advice for building owners: large-scale wall sy... advice for building owners on the large-scale w...  NaN   \n",
       "\n",
       "level2taxon_code                                                                                                                                                                               5    \\\n",
       "content_id                           combined_text                                      title                                              description                                               \n",
       "00029fa4-9b60-4285-898c-85ae8a6367f5 emma jones - small business crown representativ... emma jones - small business crown representative   as small business crown representative emma is ...  NaN   \n",
       "00037b70-5b08-44c2-bf0a-fa8eb636a60b land remediation: bringing brownfield sites bac... land remediation: bringing brownfield sites bac... brochure showing uk expertise in land remediati...  NaN   \n",
       "00037ee5-7b5e-452d-a233-af2c134f5bce steps 2 success:ni statistics from october 2014... steps 2 success:ni statistics from october 2014... details on the number of referrals and starts o...  NaN   \n",
       "0004c63d-ae16-432a-bb35-c0f949b1e27c student support applications for higher educati... student support applications for higher educati... data includes the number of applications receiv...  NaN   \n",
       "0005ac76-50fe-42f1-8168-8b6fc046e40f advice for building owners: large-scale wall sy... advice for building owners: large-scale wall sy... advice for building owners on the large-scale w...  NaN   \n",
       "\n",
       "level2taxon_code                                                                                                                                                                               6    \\\n",
       "content_id                           combined_text                                      title                                              description                                               \n",
       "00029fa4-9b60-4285-898c-85ae8a6367f5 emma jones - small business crown representativ... emma jones - small business crown representative   as small business crown representative emma is ...  NaN   \n",
       "00037b70-5b08-44c2-bf0a-fa8eb636a60b land remediation: bringing brownfield sites bac... land remediation: bringing brownfield sites bac... brochure showing uk expertise in land remediati...  NaN   \n",
       "00037ee5-7b5e-452d-a233-af2c134f5bce steps 2 success:ni statistics from october 2014... steps 2 success:ni statistics from october 2014... details on the number of referrals and starts o...  NaN   \n",
       "0004c63d-ae16-432a-bb35-c0f949b1e27c student support applications for higher educati... student support applications for higher educati... data includes the number of applications receiv...  NaN   \n",
       "0005ac76-50fe-42f1-8168-8b6fc046e40f advice for building owners: large-scale wall sy... advice for building owners: large-scale wall sy... advice for building owners on the large-scale w...  NaN   \n",
       "\n",
       "level2taxon_code                                                                                                                                                                               7    \\\n",
       "content_id                           combined_text                                      title                                              description                                               \n",
       "00029fa4-9b60-4285-898c-85ae8a6367f5 emma jones - small business crown representativ... emma jones - small business crown representative   as small business crown representative emma is ...  NaN   \n",
       "00037b70-5b08-44c2-bf0a-fa8eb636a60b land remediation: bringing brownfield sites bac... land remediation: bringing brownfield sites bac... brochure showing uk expertise in land remediati...  NaN   \n",
       "00037ee5-7b5e-452d-a233-af2c134f5bce steps 2 success:ni statistics from october 2014... steps 2 success:ni statistics from october 2014... details on the number of referrals and starts o...  NaN   \n",
       "0004c63d-ae16-432a-bb35-c0f949b1e27c student support applications for higher educati... student support applications for higher educati... data includes the number of applications receiv...  NaN   \n",
       "0005ac76-50fe-42f1-8168-8b6fc046e40f advice for building owners: large-scale wall sy... advice for building owners: large-scale wall sy... advice for building owners on the large-scale w...  NaN   \n",
       "\n",
       "level2taxon_code                                                                                                                                                                               8    \\\n",
       "content_id                           combined_text                                      title                                              description                                               \n",
       "00029fa4-9b60-4285-898c-85ae8a6367f5 emma jones - small business crown representativ... emma jones - small business crown representative   as small business crown representative emma is ...  NaN   \n",
       "00037b70-5b08-44c2-bf0a-fa8eb636a60b land remediation: bringing brownfield sites bac... land remediation: bringing brownfield sites bac... brochure showing uk expertise in land remediati...  NaN   \n",
       "00037ee5-7b5e-452d-a233-af2c134f5bce steps 2 success:ni statistics from october 2014... steps 2 success:ni statistics from october 2014... details on the number of referrals and starts o...  NaN   \n",
       "0004c63d-ae16-432a-bb35-c0f949b1e27c student support applications for higher educati... student support applications for higher educati... data includes the number of applications receiv...  NaN   \n",
       "0005ac76-50fe-42f1-8168-8b6fc046e40f advice for building owners: large-scale wall sy... advice for building owners: large-scale wall sy... advice for building owners on the large-scale w...  NaN   \n",
       "\n",
       "level2taxon_code                                                                                                                                                                               9    \\\n",
       "content_id                           combined_text                                      title                                              description                                               \n",
       "00029fa4-9b60-4285-898c-85ae8a6367f5 emma jones - small business crown representativ... emma jones - small business crown representative   as small business crown representative emma is ...  NaN   \n",
       "00037b70-5b08-44c2-bf0a-fa8eb636a60b land remediation: bringing brownfield sites bac... land remediation: bringing brownfield sites bac... brochure showing uk expertise in land remediati...  NaN   \n",
       "00037ee5-7b5e-452d-a233-af2c134f5bce steps 2 success:ni statistics from october 2014... steps 2 success:ni statistics from october 2014... details on the number of referrals and starts o...  NaN   \n",
       "0004c63d-ae16-432a-bb35-c0f949b1e27c student support applications for higher educati... student support applications for higher educati... data includes the number of applications receiv...  NaN   \n",
       "0005ac76-50fe-42f1-8168-8b6fc046e40f advice for building owners: large-scale wall sy... advice for building owners: large-scale wall sy... advice for building owners on the large-scale w...  NaN   \n",
       "\n",
       "level2taxon_code                                                                                                                                                                               10   \\\n",
       "content_id                           combined_text                                      title                                              description                                               \n",
       "00029fa4-9b60-4285-898c-85ae8a6367f5 emma jones - small business crown representativ... emma jones - small business crown representative   as small business crown representative emma is ...  NaN   \n",
       "00037b70-5b08-44c2-bf0a-fa8eb636a60b land remediation: bringing brownfield sites bac... land remediation: bringing brownfield sites bac... brochure showing uk expertise in land remediati...  NaN   \n",
       "00037ee5-7b5e-452d-a233-af2c134f5bce steps 2 success:ni statistics from october 2014... steps 2 success:ni statistics from october 2014... details on the number of referrals and starts o...  NaN   \n",
       "0004c63d-ae16-432a-bb35-c0f949b1e27c student support applications for higher educati... student support applications for higher educati... data includes the number of applications receiv...  NaN   \n",
       "0005ac76-50fe-42f1-8168-8b6fc046e40f advice for building owners: large-scale wall sy... advice for building owners: large-scale wall sy... advice for building owners on the large-scale w...  NaN   \n",
       "\n",
       "level2taxon_code                                                                                                                                                                              ...   \\\n",
       "content_id                           combined_text                                      title                                              description                                        ...    \n",
       "00029fa4-9b60-4285-898c-85ae8a6367f5 emma jones - small business crown representativ... emma jones - small business crown representative   as small business crown representative emma is ... ...    \n",
       "00037b70-5b08-44c2-bf0a-fa8eb636a60b land remediation: bringing brownfield sites bac... land remediation: bringing brownfield sites bac... brochure showing uk expertise in land remediati... ...    \n",
       "00037ee5-7b5e-452d-a233-af2c134f5bce steps 2 success:ni statistics from october 2014... steps 2 success:ni statistics from october 2014... details on the number of referrals and starts o... ...    \n",
       "0004c63d-ae16-432a-bb35-c0f949b1e27c student support applications for higher educati... student support applications for higher educati... data includes the number of applications receiv... ...    \n",
       "0005ac76-50fe-42f1-8168-8b6fc046e40f advice for building owners: large-scale wall sy... advice for building owners: large-scale wall sy... advice for building owners on the large-scale w... ...    \n",
       "\n",
       "level2taxon_code                                                                                                                                                                               201  \\\n",
       "content_id                           combined_text                                      title                                              description                                               \n",
       "00029fa4-9b60-4285-898c-85ae8a6367f5 emma jones - small business crown representativ... emma jones - small business crown representative   as small business crown representative emma is ...  NaN   \n",
       "00037b70-5b08-44c2-bf0a-fa8eb636a60b land remediation: bringing brownfield sites bac... land remediation: bringing brownfield sites bac... brochure showing uk expertise in land remediati...  NaN   \n",
       "00037ee5-7b5e-452d-a233-af2c134f5bce steps 2 success:ni statistics from october 2014... steps 2 success:ni statistics from october 2014... details on the number of referrals and starts o...  NaN   \n",
       "0004c63d-ae16-432a-bb35-c0f949b1e27c student support applications for higher educati... student support applications for higher educati... data includes the number of applications receiv...  NaN   \n",
       "0005ac76-50fe-42f1-8168-8b6fc046e40f advice for building owners: large-scale wall sy... advice for building owners: large-scale wall sy... advice for building owners on the large-scale w...  NaN   \n",
       "\n",
       "level2taxon_code                                                                                                                                                                               202  \\\n",
       "content_id                           combined_text                                      title                                              description                                               \n",
       "00029fa4-9b60-4285-898c-85ae8a6367f5 emma jones - small business crown representativ... emma jones - small business crown representative   as small business crown representative emma is ...  NaN   \n",
       "00037b70-5b08-44c2-bf0a-fa8eb636a60b land remediation: bringing brownfield sites bac... land remediation: bringing brownfield sites bac... brochure showing uk expertise in land remediati...  NaN   \n",
       "00037ee5-7b5e-452d-a233-af2c134f5bce steps 2 success:ni statistics from october 2014... steps 2 success:ni statistics from october 2014... details on the number of referrals and starts o...  NaN   \n",
       "0004c63d-ae16-432a-bb35-c0f949b1e27c student support applications for higher educati... student support applications for higher educati... data includes the number of applications receiv...  NaN   \n",
       "0005ac76-50fe-42f1-8168-8b6fc046e40f advice for building owners: large-scale wall sy... advice for building owners: large-scale wall sy... advice for building owners on the large-scale w...  NaN   \n",
       "\n",
       "level2taxon_code                                                                                                                                                                               203  \\\n",
       "content_id                           combined_text                                      title                                              description                                               \n",
       "00029fa4-9b60-4285-898c-85ae8a6367f5 emma jones - small business crown representativ... emma jones - small business crown representative   as small business crown representative emma is ...  NaN   \n",
       "00037b70-5b08-44c2-bf0a-fa8eb636a60b land remediation: bringing brownfield sites bac... land remediation: bringing brownfield sites bac... brochure showing uk expertise in land remediati...  NaN   \n",
       "00037ee5-7b5e-452d-a233-af2c134f5bce steps 2 success:ni statistics from october 2014... steps 2 success:ni statistics from october 2014... details on the number of referrals and starts o...  NaN   \n",
       "0004c63d-ae16-432a-bb35-c0f949b1e27c student support applications for higher educati... student support applications for higher educati... data includes the number of applications receiv...  NaN   \n",
       "0005ac76-50fe-42f1-8168-8b6fc046e40f advice for building owners: large-scale wall sy... advice for building owners: large-scale wall sy... advice for building owners on the large-scale w...  NaN   \n",
       "\n",
       "level2taxon_code                                                                                                                                                                               204  \\\n",
       "content_id                           combined_text                                      title                                              description                                               \n",
       "00029fa4-9b60-4285-898c-85ae8a6367f5 emma jones - small business crown representativ... emma jones - small business crown representative   as small business crown representative emma is ...  NaN   \n",
       "00037b70-5b08-44c2-bf0a-fa8eb636a60b land remediation: bringing brownfield sites bac... land remediation: bringing brownfield sites bac... brochure showing uk expertise in land remediati...  NaN   \n",
       "00037ee5-7b5e-452d-a233-af2c134f5bce steps 2 success:ni statistics from october 2014... steps 2 success:ni statistics from october 2014... details on the number of referrals and starts o...  NaN   \n",
       "0004c63d-ae16-432a-bb35-c0f949b1e27c student support applications for higher educati... student support applications for higher educati... data includes the number of applications receiv...  NaN   \n",
       "0005ac76-50fe-42f1-8168-8b6fc046e40f advice for building owners: large-scale wall sy... advice for building owners: large-scale wall sy... advice for building owners on the large-scale w...  NaN   \n",
       "\n",
       "level2taxon_code                                                                                                                                                                               205  \\\n",
       "content_id                           combined_text                                      title                                              description                                               \n",
       "00029fa4-9b60-4285-898c-85ae8a6367f5 emma jones - small business crown representativ... emma jones - small business crown representative   as small business crown representative emma is ...  NaN   \n",
       "00037b70-5b08-44c2-bf0a-fa8eb636a60b land remediation: bringing brownfield sites bac... land remediation: bringing brownfield sites bac... brochure showing uk expertise in land remediati...  NaN   \n",
       "00037ee5-7b5e-452d-a233-af2c134f5bce steps 2 success:ni statistics from october 2014... steps 2 success:ni statistics from october 2014... details on the number of referrals and starts o...  NaN   \n",
       "0004c63d-ae16-432a-bb35-c0f949b1e27c student support applications for higher educati... student support applications for higher educati... data includes the number of applications receiv...  NaN   \n",
       "0005ac76-50fe-42f1-8168-8b6fc046e40f advice for building owners: large-scale wall sy... advice for building owners: large-scale wall sy... advice for building owners on the large-scale w...  NaN   \n",
       "\n",
       "level2taxon_code                                                                                                                                                                               206  \\\n",
       "content_id                           combined_text                                      title                                              description                                               \n",
       "00029fa4-9b60-4285-898c-85ae8a6367f5 emma jones - small business crown representativ... emma jones - small business crown representative   as small business crown representative emma is ...  NaN   \n",
       "00037b70-5b08-44c2-bf0a-fa8eb636a60b land remediation: bringing brownfield sites bac... land remediation: bringing brownfield sites bac... brochure showing uk expertise in land remediati...  NaN   \n",
       "00037ee5-7b5e-452d-a233-af2c134f5bce steps 2 success:ni statistics from october 2014... steps 2 success:ni statistics from october 2014... details on the number of referrals and starts o...  NaN   \n",
       "0004c63d-ae16-432a-bb35-c0f949b1e27c student support applications for higher educati... student support applications for higher educati... data includes the number of applications receiv...  NaN   \n",
       "0005ac76-50fe-42f1-8168-8b6fc046e40f advice for building owners: large-scale wall sy... advice for building owners: large-scale wall sy... advice for building owners on the large-scale w...  NaN   \n",
       "\n",
       "level2taxon_code                                                                                                                                                                               207  \\\n",
       "content_id                           combined_text                                      title                                              description                                               \n",
       "00029fa4-9b60-4285-898c-85ae8a6367f5 emma jones - small business crown representativ... emma jones - small business crown representative   as small business crown representative emma is ...  NaN   \n",
       "00037b70-5b08-44c2-bf0a-fa8eb636a60b land remediation: bringing brownfield sites bac... land remediation: bringing brownfield sites bac... brochure showing uk expertise in land remediati...  NaN   \n",
       "00037ee5-7b5e-452d-a233-af2c134f5bce steps 2 success:ni statistics from october 2014... steps 2 success:ni statistics from october 2014... details on the number of referrals and starts o...  NaN   \n",
       "0004c63d-ae16-432a-bb35-c0f949b1e27c student support applications for higher educati... student support applications for higher educati... data includes the number of applications receiv...  NaN   \n",
       "0005ac76-50fe-42f1-8168-8b6fc046e40f advice for building owners: large-scale wall sy... advice for building owners: large-scale wall sy... advice for building owners on the large-scale w...  NaN   \n",
       "\n",
       "level2taxon_code                                                                                                                                                                               208  \\\n",
       "content_id                           combined_text                                      title                                              description                                               \n",
       "00029fa4-9b60-4285-898c-85ae8a6367f5 emma jones - small business crown representativ... emma jones - small business crown representative   as small business crown representative emma is ...  NaN   \n",
       "00037b70-5b08-44c2-bf0a-fa8eb636a60b land remediation: bringing brownfield sites bac... land remediation: bringing brownfield sites bac... brochure showing uk expertise in land remediati...  NaN   \n",
       "00037ee5-7b5e-452d-a233-af2c134f5bce steps 2 success:ni statistics from october 2014... steps 2 success:ni statistics from october 2014... details on the number of referrals and starts o...  NaN   \n",
       "0004c63d-ae16-432a-bb35-c0f949b1e27c student support applications for higher educati... student support applications for higher educati... data includes the number of applications receiv...  NaN   \n",
       "0005ac76-50fe-42f1-8168-8b6fc046e40f advice for building owners: large-scale wall sy... advice for building owners: large-scale wall sy... advice for building owners on the large-scale w...  NaN   \n",
       "\n",
       "level2taxon_code                                                                                                                                                                               209  \\\n",
       "content_id                           combined_text                                      title                                              description                                               \n",
       "00029fa4-9b60-4285-898c-85ae8a6367f5 emma jones - small business crown representativ... emma jones - small business crown representative   as small business crown representative emma is ...  NaN   \n",
       "00037b70-5b08-44c2-bf0a-fa8eb636a60b land remediation: bringing brownfield sites bac... land remediation: bringing brownfield sites bac... brochure showing uk expertise in land remediati...  NaN   \n",
       "00037ee5-7b5e-452d-a233-af2c134f5bce steps 2 success:ni statistics from october 2014... steps 2 success:ni statistics from october 2014... details on the number of referrals and starts o...  NaN   \n",
       "0004c63d-ae16-432a-bb35-c0f949b1e27c student support applications for higher educati... student support applications for higher educati... data includes the number of applications receiv...  NaN   \n",
       "0005ac76-50fe-42f1-8168-8b6fc046e40f advice for building owners: large-scale wall sy... advice for building owners: large-scale wall sy... advice for building owners on the large-scale w...  NaN   \n",
       "\n",
       "level2taxon_code                                                                                                                                                                               210  \n",
       "content_id                           combined_text                                      title                                              description                                              \n",
       "00029fa4-9b60-4285-898c-85ae8a6367f5 emma jones - small business crown representativ... emma jones - small business crown representative   as small business crown representative emma is ...  NaN  \n",
       "00037b70-5b08-44c2-bf0a-fa8eb636a60b land remediation: bringing brownfield sites bac... land remediation: bringing brownfield sites bac... brochure showing uk expertise in land remediati...  NaN  \n",
       "00037ee5-7b5e-452d-a233-af2c134f5bce steps 2 success:ni statistics from october 2014... steps 2 success:ni statistics from october 2014... details on the number of referrals and starts o...  NaN  \n",
       "0004c63d-ae16-432a-bb35-c0f949b1e27c student support applications for higher educati... student support applications for higher educati... data includes the number of applications receiv...  NaN  \n",
       "0005ac76-50fe-42f1-8168-8b6fc046e40f advice for building owners: large-scale wall sy... advice for building owners: large-scale wall sy... advice for building owners on the large-scale w...  NaN  \n",
       "\n",
       "[5 rows x 210 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10',\n",
       "       ...\n",
       "       '201', '202', '203', '204', '205', '206', '207', '208', '209', '210'],\n",
       "      dtype='object', name='level2taxon_code', length=210)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel.columns.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#THIS IS WHY INDEXING IS NOT ZERO-BASED\n",
    "#convert the number_of_taxons_per_content values to 1, meaning there was an entry for this taxon and this content_id, 0 otherwise\n",
    "binary_multilabel = multilabel.notnull().astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92338"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_size = binary_multilabel.shape[0]\n",
    "total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_test samples: 9233\n",
      "nb_dev samples: 18467\n",
      "nb_training samples: 73870\n"
     ]
    }
   ],
   "source": [
    "nb_test_samples = int(0.1 * total_size) #test split\n",
    "print('nb_test samples:', nb_test_samples)\n",
    "\n",
    "nb_dev_samples = int(0.2 * total_size) #dev split\n",
    "print('nb_dev samples:', nb_dev_samples)\n",
    "\n",
    "nb_training_samples = int(0.8 * total_size) #train split\n",
    "print('nb_training samples:', nb_training_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00029fa4-9b60-4285-898c-85ae8a6367f5\n",
      "00037b70-5b08-44c2-bf0a-fa8eb636a60b\n",
      "00037ee5-7b5e-452d-a233-af2c134f5bce\n",
      "0004c63d-ae16-432a-bb35-c0f949b1e27c\n",
      "0005ac76-50fe-42f1-8168-8b6fc046e40f\n",
      "0006811c-ad80-4cd0-a732-04cc983ec8c2\n",
      "0008f82f-9713-4074-8793-0d266d53930c\n",
      "000aa34d-c3c0-4176-ad8a-50e801056df1\n",
      "000b6a38-c69a-4ac9-918b-717a79cbdad2\n",
      "000b8c7e-4671-4586-9eff-97c0c374126b\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    print(binary_multilabel.index[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "00029fa4-9b60-4285-898c-85ae8a6367f5\n",
    "00037b70-5b08-44c2-bf0a-fa8eb636a60b\n",
    "00037ee5-7b5e-452d-a233-af2c134f5bce\n",
    "0004c63d-ae16-432a-bb35-c0f949b1e27c\n",
    "0005ac76-50fe-42f1-8168-8b6fc046e40f\n",
    "0006811c-ad80-4cd0-a732-04cc983ec8c2\n",
    "0008f82f-9713-4074-8793-0d266d53930c\n",
    "000aa34d-c3c0-4176-ad8a-50e801056df1\n",
    "000b6a38-c69a-4ac9-918b-717a79cbdad2\n",
    "000b8c7e-4671-4586-9eff-97c0c374126b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_multilabel = shuffle(binary_multilabel,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1372d620-2c7b-4c06-a6e7-c60cacdb4d58\n",
      "d8132578-37d9-4f47-a438-86530b0ff259\n",
      "5c8fa231-7631-11e4-a3cb-005056011aef\n",
      "5f2bc84b-6fb0-48f7-9fab-41387b1d72fe\n",
      "5df423c9-7631-11e4-a3cb-005056011aef\n",
      "a1c32b79-e6b9-40b1-8095-150727418ea1\n",
      "5bfd33c7-63bb-42d0-a6c7-9c2c03739165\n",
      "5dc916ad-7631-11e4-a3cb-005056011aef\n",
      "dabfc6b3-d88c-458f-a9fb-f286b987509b\n",
      "5c71ba56-7631-11e4-a3cb-005056011aef\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    print(binary_multilabel.index[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df76ffdf-70d6-4a38-9d60-a1765c18914e\n",
    "dca1f897-c8bd-4e35-a839-5953ee94d54e\n",
    "3bec5cd0-76bd-48b1-924a-567bd3361ec0\n",
    "5eb7cd3c-7631-11e4-a3cb-005056011aef\n",
    "a67385c3-8562-4dc1-96ba-d96ff215943b\n",
    "5e35118a-7631-11e4-a3cb-005056011aef\n",
    "5feb658b-7631-11e4-a3cb-005056011aef\n",
    "144a86f9-6902-444c-87bc-b389a6f3b275\n",
    "5e139390-7631-11e4-a3cb-005056011aef\n",
    "e5741923-bc21-46bd-8832-886706f59e81"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsample minority classes to address imbalance leading to ~2, 465, 570 rows of data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access taxon columns with indexing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ENCODING] Taxon min indx: 1 Taxon max indx: 210\n"
     ]
    }
   ],
   "source": [
    "print(\"[ENCODING] Taxon min indx:\",binary_multilabel.columns[0],\"Taxon max indx:\",\n",
    "      binary_multilabel.columns[len(binary_multilabel.columns)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92338,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_multilabel[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(binary_multilabel.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Array with indices to upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73870\n"
     ]
    }
   ],
   "source": [
    "index = [binary_multilabel.index[i][0] for i in range(0,nb_training_samples)]\n",
    "print(len(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_multilabel[binary_multilabel[1]==1].loc[index].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why are we deleting this?\n",
    "del binary_multilabel.columns.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAKES FOREVER TO RUN!\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "upsampled_training = pd.DataFrame()\n",
    "upper = len(binary_multilabel.columns)+1\n",
    "\n",
    "for taxon in range(1, upper):\n",
    "    num_samples = binary_multilabel[binary_multilabel[taxon]==1].shape[0] \n",
    "    if num_samples<500:\n",
    "        print(\"Taxon code:\",taxon,\"Taxon name:\",labels_index[taxon])\n",
    "        print(\"SMALL SUPPORT:\",num_samples)\n",
    "        df_minority = binary_multilabel[binary_multilabel[taxon]==1].loc[index]\n",
    "        if not df_minority.empty:\n",
    "        # Upsample minority class\n",
    "            print(df_minority.shape)\n",
    "            df_minority_upsampled = resample(df_minority, \n",
    "                                                 replace=True,     # sample with replacement\n",
    "                                                 n_samples=(500),    # to match majority class, switch to max_content_freq if works\n",
    "                                                 random_state=123) # reproducible results\n",
    "            \n",
    "            print(\"FIRST 5 IDs:\",[df_minority_upsampled.index[i][0] for i in range(0,5)])\n",
    "\n",
    "            # Combine majority class with upsampled minority class\n",
    "            upsampled_training = pd.concat([upsampled_training, df_minority_upsampled])\n",
    "\n",
    "            # Display new shape\n",
    "            print(\"UPSAMPLING:\",upsampled_training.shape)\n",
    "\n",
    "upsampled_training = shuffle(upsampled_training,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doublecheck dataframe contents before merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_multilabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_multilabel.index[91770][0] # final sample before merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_multilabel = pd.concat([binary_multilabel, upsampled_training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_multilabel.index[total_size][0] # first sample of duplicated training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not remove index because the text data lives there.\n",
    "**TODO** Consider reworking how datasets are set up at some point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binary_multilabel.to_csv(os.path.join(DATADIR, 'balanced_level2_training_set_sampled.csv.gz'), compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD OVERSAMPLED DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "balanced_df = pd.read_csv(os.path.join(DATADIR, 'balanced_level2_training_set_sampled.csv.gz'), dtype=object, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "balanced_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#will convert columns to an array of shape\n",
    "print('Shape of Y multilabel array before train/val/test split:{}'.format(balanced_df[list(balanced_df.columns)].values.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont' overwirte blanced_df as it take sages to read in\n",
    "balanced_df_taxons = balanced_df.iloc[:,4:215]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df_taxons.columns = balanced_df_taxons.columns.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df_taxons = balanced_df_taxons.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#convert columns to an array. Each row represents a content item, each column an individual taxon\n",
    "binary_multilabel = balanced_df_taxons[list(balanced_df_taxons.columns)].values\n",
    "print('Example row of multilabel array {}'.format(binary_multilabel[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "balanced_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format metadata/X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#extract content_id index to df\n",
    "meta1 = pd.DataFrame(balanced_df['content_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(meta1.shape)\n",
    "meta1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metas = ['document_type','first_published_at','publishing_app','primary_publishing_organisation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index(x):\n",
    "    index_dict = {}\n",
    "    index_dict['index'] = 0\n",
    "    for i,elem in enumerate(x):\n",
    "        index_dict[elem] = i+1\n",
    "    return index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IF THIS FUNCTION TURNS OUT FASTER KEEP\n",
    "#apply meta data to content\n",
    "print(\"STARTED:\",time.strftime(\"%H:%M:%S\"))\n",
    "for meta in metas:\n",
    "    print(\"WORKON:\",meta)\n",
    "    meta1[meta] = meta1['content_id'].map(dict(zip(labelled_level2['content_id'], labelled_level2[meta])))\n",
    "print(\"FINISHED:\",time.strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta1 = meta1.replace(np.nan, '', regex=True) #conver nans to empty strings for labelencoder types\n",
    "meta1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cat_to_hot(column):\n",
    "    doctype_encoder = LabelEncoder()\n",
    "    new_col = column+\"_cat\"\n",
    "    meta1[new_col] = doctype_encoder.fit_transform(meta1[column])\n",
    "    tf.cast(meta1[new_col], tf.float32)\n",
    "    return to_categorical(meta1[new_col])\n",
    "\n",
    "dict_of_encodings = {}\n",
    "for meta in metas:\n",
    "    if meta != \"first_published_at\":\n",
    "        print(meta)\n",
    "        dict_of_encodings[meta] = to_cat_to_hot(meta)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(meta1['first_published_at'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta1['first_published_at'] = pd.to_datetime(meta1['first_published_at'])\n",
    "print(meta1['first_published_at'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_published = np.array(meta1['first_published_at']).reshape(meta1['first_published_at'].shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(first_published.dtype,first_published.shape,type(first_published))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_published[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta1['first_published_at'].loc[meta1['first_published_at'] < '1970']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_published[first_published < np.datetime64('1970')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "first_published_scaled =scaler.fit_transform(first_published)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "print(stats.describe(first_published_scaled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta1['textlen'] = len(balanced_df['combined_text'])\n",
    "scaler = MinMaxScaler()\n",
    "textlen = np.array(meta1['textlen']).reshape(meta1['textlen'].shape[0], 1)\n",
    "textlen_scaled =scaler.fit_transform(textlen)\n",
    "print(stats.describe(textlen_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_encodings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = np.concatenate((dict_of_encodings['document_type'], \n",
    "                               dict_of_encodings['primary_publishing_organisation'], \n",
    "                               dict_of_encodings['publishing_app'], \n",
    "                      first_published_scaled, \n",
    "                      textlen_scaled), \n",
    "                              axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_metavars = meta.shape[1]\n",
    "print(nb_metavars)\n",
    "print(meta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize text fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer = Class for vectorizing texts, or/and turning texts into sequences (=list of word indexes, where the word of rank i in the dataset (starting at 1) has index i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(local_tokenizer,input_data,onehot):\n",
    "# apply tokenizer to our text data\n",
    "    data = []\n",
    "    local_tokenizer.fit_on_texts(input_data)\n",
    "# list of word indexes, where the word of rank i in the dataset (starting at 1) has index i\n",
    "    word_index = local_tokenizer.word_index\n",
    "    sequences = local_tokenizer.texts_to_sequences(input_data)\n",
    "     \n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "    if not onehot:\n",
    "        data = pad_sequences(sequences, maxlen= MAX_SEQUENCE_LENGTH)\n",
    "    else:\n",
    "        data = local_tokenizer.sequences_to_matrix(sequences)\n",
    "    return data, word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# True for sequences to matrix, False otherwise.\n",
    "texts = balanced_df['combined_text']\n",
    "tokenizer_texts = Tokenizer(num_words=NUM_WORDS)\n",
    "data, word_index = tokenize(tokenizer_texts,texts,False)\n",
    "\n",
    "\n",
    "titles = balanced_df['title']\n",
    "tokenizer_tit = Tokenizer(num_words=10000)\n",
    "onehot_tit, _ = tokenize(tokenizer_tit,titles,True)\n",
    "\n",
    "descs = balanced_df['description']\n",
    "tokenizer_desc = Tokenizer(num_words=10000)\n",
    "onehot_desc, _ = tokenize(tokenizer_desc,descs,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(onehot_tit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Shape of label tensor:', binary_multilabel.shape)\n",
    "print('Shape of data tensor:', data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split\n",
    "- Training data = 80%\n",
    "- Development data = 10%\n",
    "- Test data = 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original sizes, keep for reference.\n",
    "    nb_test samples: 9177\n",
    "    nb_dev samples: 18354\n",
    "    nb_training samples: 73416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nb_training_samples,nb_dev_samples,nb_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data,splits):\n",
    "    l = []\n",
    "    for (start,end) in splits:\n",
    "        l.append(data[start:end])\n",
    "    return tuple([x for x in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = len(data)-total_size+1\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [(0,-(nb_dev_samples+diff)),(-(nb_dev_samples+diff),-(nb_test_samples+diff)),(-(nb_test_samples+diff),total_size)]\n",
    "re_split = [(total_size,len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_dev, x_test = split(data,splits)\n",
    "x_resampled = split(data,re_split)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape,x_resampled.shape)\n",
    "print(x_dev.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate([x_train,x_resampled],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train, meta_dev, meta_test = split(meta,splits)\n",
    "meta_resampled = split(meta,re_split)[0]\n",
    "meta_train = np.concatenate([meta_train,meta_resampled],axis=0)\n",
    "                                                                  \n",
    "title_train, title_dev, title_test = split(onehot_tit,splits)\n",
    "title_resampled = split(onehot_tit,re_split)[0]   \n",
    "title_train = np.concatenate([title_train,title_resampled],axis=0)\n",
    "                                                                  \n",
    "desc_train, desc_dev, desc_test = split(onehot_desc,splits)\n",
    "desc_resampled = split(onehot_desc,re_split)[0] \n",
    "desc_train = np.concatenate([desc_train,desc_resampled],axis=0)\n",
    "                                                                  \n",
    "y_train, y_dev, y_test = split(binary_multilabel,splits)\n",
    "y_resampled = split(binary_multilabel,re_split)[0]\n",
    "y_train = np.concatenate([y_train,y_resampled],axis=0)                                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Shape of x_train:', x_train.shape)\n",
    "print('Shape of metax_train:', meta_train.shape)\n",
    "print('Shape of titlex_train:', title_train.shape)\n",
    "print('Shape of descx_train:', desc_train.shape)\n",
    "print('Shape of y_train:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Shape of x_dev:', x_dev.shape)\n",
    "print('Shape of meta_dev:', meta_dev.shape)\n",
    "print('Shape of titlex_dev:', title_dev.shape)\n",
    "print('Shape of descx_dev:', desc_dev.shape)\n",
    "print('Shape of y_dev:', y_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Shape of x_test:', x_test.shape)\n",
    "print('Shape of metax_test:', meta_test.shape)\n",
    "print('Shape of titlex_test:', title_test.shape)\n",
    "print('Shape of descx_test:', desc_test.shape)\n",
    "print('Shape of y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing the Embedding layer\n",
    "\n",
    "NB stopwords haven't been removed yet..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1, \n",
    "                            EMBEDDING_DIM, \n",
    "                            input_length=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Embedding layer should be fed sequences of integers, i.e. a 2D input of shape (samples, indices). These input sequences should be padded so that they all have the same length in a batch of input data (although an Embedding layer is capable of processing sequence of heterogenous length, if you don't pass an explicit input_length argument to the layer).\n",
    "\n",
    "All that the Embedding layer does is to map the integer inputs to the vectors found at the corresponding index in the embedding matrix, i.e. the sequence [1, 2] would be converted to [embeddings[1], embeddings[2]]. This means that the output of the Embedding layer will be a 3D tensor of shape (samples, sequence_length, embedding_dim)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate class weights for unbalanced datasets.\n",
    "paramter to model.fit = __class_weight__: Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
    "\n",
    "Implement class_weight from sklearn:\n",
    "\n",
    "- Import the module \n",
    "\n",
    "`from sklearn.utils import class_weight`\n",
    "- calculate the class weight, If ‘balanced’, class weights will be given by n_samples / (n_classes * np.bincount(y)):\n",
    "\n",
    "`class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)`\n",
    "\n",
    "- change it to a dict in order to work with Keras.\n",
    "\n",
    "`class_weight_dict = dict(enumerate(class_weight))`\n",
    "\n",
    "- Add to model fitting\n",
    "\n",
    "`model.fit(X_train, y_train, class_weight=class_weight)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "# class_weight_dict = dict(enumerate(class_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class WeightedBinaryCrossEntropy(object):\n",
    "\n",
    "    def __init__(self, pos_ratio):\n",
    "        neg_ratio = 1. - pos_ratio\n",
    "        #self.pos_ratio = tf.constant(pos_ratio, tf.float32)\n",
    "        self.pos_ratio = pos_ratio\n",
    "        #self.weights = tf.constant(neg_ratio / pos_ratio, tf.float32)\n",
    "        self.weights = neg_ratio / pos_ratio\n",
    "        self.__name__ = \"weighted_binary_crossentropy({0})\".format(pos_ratio)\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        return self.weighted_binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "    def weighted_binary_crossentropy(self, y_true, y_pred):\n",
    "            # Transform to logits\n",
    "            epsilon = tf.convert_to_tensor(K.common._EPSILON, y_pred.dtype.base_dtype)\n",
    "            y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
    "            y_pred = tf.log(y_pred / (1 - y_pred))\n",
    "\n",
    "            cost = tf.nn.weighted_cross_entropy_with_logits(y_true, y_pred, self.weights)\n",
    "            return K.mean(cost * self.pos_ratio, axis=-1)\n",
    "    \n",
    "y_true_arr = np.array([0,1,0,1], dtype=\"float32\")\n",
    "y_pred_arr = np.array([0,0,1,1], dtype=\"float32\")\n",
    "y_true = tf.constant(y_true_arr)\n",
    "y_pred = tf.constant(y_pred_arr)\n",
    "\n",
    "with tf.Session().as_default(): \n",
    "    print(WeightedBinaryCrossEntropy(0.5)(y_true, y_pred).eval())\n",
    "    print(binary_crossentropy(y_true, y_pred).eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### difficulty getting global precision/recall metrics . CAUTION interpreting monitoring metrics\n",
    "fcholltet: \"Basically these are all global metrics that were approximated\n",
    "batch-wise, which is more misleading than helpful. This was mentioned in\n",
    "the docs but it's much cleaner to remove them altogether. It was a mistake\n",
    "to merge them in the first place.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    \"\"\"Use Recall  and precision metrics to calculate harmonic mean (F1 score).\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1 = 2*((precision*recall)/(precision+recall))\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a 1D convnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NB_CLASSES = y_train.shape[1]\n",
    "NB_METAVARS = meta_train.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='wordindex') #MAX_SEQUENCE_LENGTH\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Dropout(0.2, name = 'dropout_embedded')(embedded_sequences)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv0')(x)\n",
    "\n",
    "x = MaxPooling1D(5, name = 'max_pool0')(x)\n",
    "\n",
    "x = Dropout(0.5, name = 'dropout0')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv1')(x)\n",
    "\n",
    "x = MaxPooling1D(5 , name = 'max_pool1')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv2')(x)\n",
    "\n",
    "x = MaxPooling1D(35, name = 'global_max_pool')(x)  # global max pooling\n",
    "\n",
    "x = Flatten()(x) #reduce dimensions from 3 to 2; convert to vector + FULLYCONNECTED\n",
    "\n",
    "meta_input = Input(shape=(NB_METAVARS,), name='meta')\n",
    "meta_hidden = Dense(128, activation='relu', name = 'hidden_meta')(meta_input)\n",
    "meta_hidden = Dropout(0.2, name = 'dropout_meta')(meta_hidden)\n",
    "\n",
    "\n",
    "title_input = Input(shape=(title_train.shape[1],), name='titles')\n",
    "title_hidden = Dense(128, activation='relu', name = 'hidden_title')(title_input)\n",
    "title_hidden = Dropout(0.2, name = 'dropout_title')(title_hidden)\n",
    "\n",
    "desc_input = Input(shape=(desc_train.shape[1],), name='descs')\n",
    "desc_hidden = Dense(128, activation='relu', name = 'hidden_desc')(desc_input)\n",
    "desc_hidden = Dropout(0.2, name = 'dropout_desc')(desc_hidden)\n",
    "\n",
    "concatenated = concatenate([meta_hidden, title_hidden, desc_hidden, x])\n",
    "\n",
    "x = Dense(400, activation='relu', name = 'fully_connected0')(concatenated)\n",
    "\n",
    "x = Dropout(0.2, name = 'dropout1')(x)\n",
    "\n",
    "x = Dense(NB_CLASSES, activation='sigmoid', name = 'fully_connected1')(x)\n",
    "\n",
    "# # The Model class turns an input tensor and output tensor into a model\n",
    "# This creates Keras model instance, will use this instance to train/test the model.\n",
    "model = Model(inputs=[meta_input, title_input, desc_input, sequence_input], outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.compile(loss=WeightedBinaryCrossEntropy(POS_RATIO),\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['binary_accuracy', f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric values are recorded at the end of each epoch on the training dataset. If a validation dataset is also provided, then the metric recorded is also calculated for the validation dataset.\n",
    "\n",
    "All metrics are reported in verbose output and in the history object returned from calling the fit() function. In both cases, the name of the metric function is used as the key for the metric values. In the case of metrics for the validation dataset, the “val_” prefix is added to the key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have now built a function to describe your model. To train and test this model, there are four steps in Keras:\n",
    "1. Create the model by calling the function above\n",
    "2. Compile the model by calling `model.compile(optimizer = \"...\", loss = \"...\", metrics = [\"accuracy\"])`\n",
    "3. Train the model on train data by calling `model.fit(x = ..., y = ..., epochs = ..., batch_size = ...)`\n",
    "4. Test the model on test data by calling `model.evaluate(x = ..., y = ...)`\n",
    "\n",
    "If you want to know more about `model.compile()`, `model.fit()`, `model.evaluate()` and their arguments, refer to the official [Keras documentation](https://keras.io/models/model/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard callbacks /metrics /monitor training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **Size of these files is killing storage during training. Is it histograms?**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tb = TensorBoard(log_dir='./learn_embedding_logs', histogram_freq=1, write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = os.path.join(DATADIR, 'model_checkpoint.hdf5')\n",
    "\n",
    "cp = ModelCheckpoint(\n",
    "                     filepath = CHECKPOINT_PATH, \n",
    "                     monitor='val_loss', \n",
    "                     verbose=0, \n",
    "                     save_best_only=False, \n",
    "                     save_weights_only=False, \n",
    "                     mode='auto', \n",
    "                     period=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class Metrics(Callback):\n",
    "#     def on_train_begin(self, logs={}):\n",
    "#         self.val_f1s = []\n",
    "#         self.val_recalls = []\n",
    "#         self.val_precisions = []\n",
    " \n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#         val_predict = (np.asarray(self.model.predict(self.model.validation_data[0]))).round()\n",
    "#         val_targ = self.model.validation_data[1]\n",
    "        \n",
    "#         self.val_f1s.append(f1_score(val_targ, val_predict, average='micro'))\n",
    "#         self.val_recalls.append(recall_score(val_targ, val_predict))\n",
    "#         self.val_precisions.append(precision_score(val_targ, val_predict))\n",
    "#         print(\"- val_f1: %f — val_precision: %f — val_recall %f\" \n",
    "#                 %(f1_score(val_targ, val_predict, average='micro'), \n",
    "#                   precision_score(val_targ, val_predict),\n",
    "#                    recall_score(val_targ, val_predict)))\n",
    "#         return\n",
    " \n",
    "# metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "#model.fit(x, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# metrics callback causes: CCCCCCR55555555511155\n",
    "# So disable for now\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "# Replicates `model` on 8 GPUs.\n",
    "# This assumes that your machine has 8 available GPUs.\n",
    "parallel_model = multi_gpu_model(model, gpus=8)\n",
    "parallel_model.compile(loss=WeightedBinaryCrossEntropy(POS_RATIO),\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['binary_accuracy', f1])\n",
    "\n",
    "# This `fit` call will be distributed on 8 GPUs.\n",
    "# Since the batch size is 256, each GPU will process 32 samples.\n",
    "history = parallel_model.fit(\n",
    "    {'meta': meta_train, 'titles': title_train, 'descs': desc_train, 'wordindex': x_train},\n",
    "    y_train, \n",
    "    validation_data=([meta_dev, title_dev, desc_dev, x_dev], y_dev), \n",
    "    epochs=10, batch_size=128, callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "\n",
    "# history = model.fit(\n",
    "#     {'meta': metax_train, 'titles': titlex_train, 'descs': descx_train, 'wordindex': x_train},\n",
    "#     y_train, \n",
    "#     validation_data=([metax_dev, titlex_dev, descx_dev, x_dev], y_dev), \n",
    "#     epochs=10, batch_size=128, callbacks=[early_stopping]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, 6)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')           \n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')      \n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.clf()    \n",
    "\n",
    "f1_values = history_dict['f1']\n",
    "val_f1_values = history_dict['val_f1']\n",
    "\n",
    "plt.plot(epochs, f1_values, 'bo', label='Training f1')\n",
    "plt.plot(epochs, val_f1_values, 'b', label='Validation f1')\n",
    "plt.title('Training and validation batch-level f1-micro')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1-micro')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_file(array,name):\n",
    "    df = pd.DataFrame(data = array.tolist(),columns=[i for i in range(1,211)])\n",
    "    df.to_csv(os.path.join(DATADIR, name+'_results.csv.gz'),compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_run = time.strftime(\"_%H%M_%d%m_\")\n",
    "date_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = parallel_model.predict([meta_train, title_train, desc_train, x_train])\n",
    "to_file(y_prob,\"train\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_prob.copy()\n",
    "y_pred[y_pred>=P_THRESHOLD] = 1\n",
    "y_pred[y_pred<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('micro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='micro', sample_weight=None)))\n",
    "print('macro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='macro', sample_weight=None)))\n",
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='weighted', sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_dev = parallel_model.predict([meta_dev, title_dev, desc_dev, x_dev])\n",
    "to_file(y_prob_dev,\"dev\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dev = y_prob_dev.copy()\n",
    "y_pred_dev[y_pred_dev>=P_THRESHOLD] = 1\n",
    "y_pred_dev[y_pred_dev<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('micro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='micro', sample_weight=None)))\n",
    "print('macro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='macro', sample_weight=None)))\n",
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='weighted', sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average=None, sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_train,\"true_train\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_dev,\"true_dev\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "keep_output": true,
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
