{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional NN to classify govuk content to level2 taxons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on:\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load requirements and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.utils import to_categorical, layer_utils, plot_model\n",
    "\n",
    "from keras.layers import (Embedding, Input, Dense, Dropout, \n",
    "                          Activation, Conv1D, MaxPooling1D, Flatten, concatenate, Reshape)\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.callbacks import TensorBoard, Callback, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score \n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import functools\n",
    "\n",
    "import h5py\n",
    "\n",
    "from scipy import sparse\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environmental vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATADIR=\"/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print data version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm running on data extracted from content store on /data\n"
     ]
    }
   ],
   "source": [
    "print('algorithm running on data extracted from content store on {}'.format(DATADIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuition for POS_RATIO is that it penalises the prediction of zero for everything, which is attractive to the model because the multilabel y matrix is super sparse. \n",
    "\n",
    "Increasing POS_RATIO should penalise predicting zeros more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MAX_NB_WORDS\n",
    "MAX_SEQUENCE_LENGTH =1000\n",
    "EMBEDDING_DIM = 100 # keras embedding layer output_dim = Dimension of the dense embedding\n",
    "P_THRESHOLD = 0.5 #Threshold for probability of being assigned to class\n",
    "POS_RATIO = 0.5 #ratio of positive to negative for each class in weighted binary cross entropy loss function\n",
    "NUM_WORDS=20000 #keras tokenizer num_words: None or int. Maximum number of words to work with \n",
    "#(if set, tokenization will be restricted to the top num_words most common words in the dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = np.load(os.path.join(DATADIR, 'train_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'meta', 'title', 'desc', 'y']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (161020, 1000)\n",
      "meta_train.shape = (161020, 452)\n",
      "title_train.shape = (161020, 10000)\n",
      "desc_train.shape = (161020, 10000)\n",
      "y_train.shape = (161020, 218)\n"
     ]
    }
   ],
   "source": [
    "x_train = sparse.csr_matrix(train['x'].all()).todense()\n",
    "meta_train = sparse.csr_matrix(train['meta'].all()).todense()\n",
    "title_train = sparse.csr_matrix(train['title'].all()).todense()\n",
    "desc_train = sparse.csr_matrix(train['desc'].all()).todense()\n",
    "y_train = sparse.csr_matrix(train['y'].all()).todense()\n",
    "\n",
    "print('x_train.shape = {}'.format(x_train.shape))\n",
    "print('meta_train.shape = {}'.format(meta_train.shape))\n",
    "print('title_train.shape = {}'.format(title_train.shape))\n",
    "print('desc_train.shape = {}'.format(desc_train.shape))\n",
    "print('y_train.shape = {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dev = np.load(os.path.join(DATADIR, 'dev_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_dev.shape = (10377, 1000)\n",
      "meta_dev.shape = (10377, 452)\n",
      "title_dev.shape = (10377, 10000)\n",
      "desc_dev.shape = (10377, 10000)\n",
      "y_dev.shape = (10377, 218)\n"
     ]
    }
   ],
   "source": [
    "x_dev = sparse.csr_matrix(dev['x'].all()).todense()\n",
    "meta_dev = sparse.csr_matrix(dev['meta'].all()).todense()\n",
    "title_dev = sparse.csr_matrix(dev['title'].all()).todense()\n",
    "desc_dev = sparse.csr_matrix(dev['desc'].all()).todense()\n",
    "y_dev = sparse.csr_matrix(dev['y'].all()).todense()\n",
    "\n",
    "print('x_dev.shape = {}'.format(x_dev.shape))\n",
    "print('meta_dev.shape = {}'.format(meta_dev.shape))\n",
    "print('title_dev.shape = {}'.format(title_dev.shape))\n",
    "print('desc_dev.shape = {}'.format(desc_dev.shape))\n",
    "print('y_dev.shape = {}'.format(y_dev.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = np.load(os.path.join(DATADIR, 'test_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test.shape = (10379, 1000)\n",
      "meta_test.shape = (10379, 452)\n",
      "title_test.shape = (10379, 10000)\n",
      "desc_test.shape = (10379, 10000)\n",
      "y_test.shape = (10379, 218)\n"
     ]
    }
   ],
   "source": [
    "x_test = sparse.csr_matrix(test['x'].all()).todense()\n",
    "meta_test = sparse.csr_matrix(test['meta'].all()).todense()\n",
    "title_test = sparse.csr_matrix(test['title'].all()).todense()\n",
    "desc_test = sparse.csr_matrix(test['desc'].all()).todense()\n",
    "y_test = sparse.csr_matrix(test['y'].all()).todense()\n",
    "\n",
    "print('x_test.shape = {}'.format(x_test.shape))\n",
    "print('meta_test.shape = {}'.format(meta_test.shape))\n",
    "print('title_test.shape = {}'.format(title_test.shape))\n",
    "print('desc_test.shape = {}'.format(desc_test.shape))\n",
    "print('y_test.shape = {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### previous shapes in old data \n",
    "Shape of x_train: (150870, 1000)\n",
    "Shape of metax_train: (150870, 436)\n",
    "Shape of titlex_train: (150870, 10000)\n",
    "Shape of descx_train: (150870, 10000)\n",
    "Shape of y_train: (150870, 210)\n",
    "\n",
    "Shape of x_dev: (9234, 1000)\n",
    "Shape of meta_dev: (9234, 436)\n",
    "Shape of titlex_dev: (9234, 10000)\n",
    "Shape of descx_dev: (9234, 10000)\n",
    "Shape of y_dev: (9234, 210)\n",
    "\n",
    "Shape of x_test: (9234, 1000)\n",
    "Shape of metax_test: (9234, 436)\n",
    "Shape of titlex_test: (9234, 10000)\n",
    "Shape of descx_test: (9234, 10000)\n",
    "Shape of y_test: (9234, 210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing the Embedding layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "def load_tokenizer_from_file(filename):\n",
    "    \n",
    "    tokenizer = Tokenizer()\n",
    "\n",
    "    with open(filename, 'r') as infile:\n",
    "        tokenizer_data = json.load(infile)\n",
    "\n",
    "    tokenizer.word_counts = OrderedDict(tokenizer_data['word_counts'])\n",
    "    tokenizer.word_docs = tokenizer_data['word_docs']\n",
    "    tokenizer.word_index = tokenizer_data['word_index']\n",
    "    tokenizer.document_count = tokenizer_data['document_count']\n",
    "    tokenizer.index_docs = tokenizer_data['index_docs']\n",
    "\n",
    "    return tokenizer\n",
    "\n",
    "tokenizer_combined_text = load_tokenizer_from_file(os.path.join(DATADIR, \"combined_text_tokenizer.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(tokenizer_combined_text.word_index) + 1, \n",
    "                            EMBEDDING_DIM, \n",
    "                            input_length=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Embedding layer should be fed sequences of integers, i.e. a 2D input of shape (samples, indices). These input sequences should be padded so that they all have the same length in a batch of input data (although an Embedding layer is capable of processing sequence of heterogenous length, if you don't pass an explicit input_length argument to the layer).\n",
    "\n",
    "All that the Embedding layer does is to map the integer inputs to the vectors found at the corresponding index in the embedding matrix, i.e. the sequence [1, 2] would be converted to [embeddings[1], embeddings[2]]. This means that the output of the Embedding layer will be a 3D tensor of shape (samples, sequence_length, embedding_dim)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate class weights for unbalanced datasets.\n",
    "paramter to model.fit = __class_weight__: Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
    "\n",
    "Implement class_weight from sklearn:\n",
    "\n",
    "- Import the module \n",
    "\n",
    "`from sklearn.utils import class_weight`\n",
    "- calculate the class weight, If ‘balanced’, class weights will be given by n_samples / (n_classes * np.bincount(y)):\n",
    "\n",
    "`class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)`\n",
    "\n",
    "- change it to a dict in order to work with Keras.\n",
    "\n",
    "`class_weight_dict = dict(enumerate(class_weight))`\n",
    "\n",
    "- Add to model fitting\n",
    "\n",
    "`model.fit(X_train, y_train, class_weight=class_weight)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "# class_weight_dict = dict(enumerate(class_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.00756\n",
      "8.01512\n"
     ]
    }
   ],
   "source": [
    "class WeightedBinaryCrossEntropy(object):\n",
    "\n",
    "    def __init__(self, pos_ratio):\n",
    "        neg_ratio = 1. - pos_ratio\n",
    "        #self.pos_ratio = tf.constant(pos_ratio, tf.float32)\n",
    "        self.pos_ratio = pos_ratio\n",
    "        #self.weights = tf.constant(neg_ratio / pos_ratio, tf.float32)\n",
    "        self.weights = neg_ratio / pos_ratio\n",
    "        self.__name__ = \"weighted_binary_crossentropy({0})\".format(pos_ratio)\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        return self.weighted_binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "    def weighted_binary_crossentropy(self, y_true, y_pred):\n",
    "            # Transform to logits\n",
    "            epsilon = tf.convert_to_tensor(K.common._EPSILON, y_pred.dtype.base_dtype)\n",
    "            y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
    "            y_pred = tf.log(y_pred / (1 - y_pred))\n",
    "\n",
    "            cost = tf.nn.weighted_cross_entropy_with_logits(y_true, y_pred, self.weights)\n",
    "            return K.mean(cost * self.pos_ratio, axis=-1)\n",
    "    \n",
    "y_true_arr = np.array([0,1,0,1], dtype=\"float32\")\n",
    "y_pred_arr = np.array([0,0,1,1], dtype=\"float32\")\n",
    "y_true = tf.constant(y_true_arr)\n",
    "y_pred = tf.constant(y_pred_arr)\n",
    "\n",
    "with tf.Session().as_default(): \n",
    "    print(WeightedBinaryCrossEntropy(0.5)(y_true, y_pred).eval())\n",
    "    print(binary_crossentropy(y_true, y_pred).eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### difficulty getting global precision/recall metrics . CAUTION interpreting monitoring metrics\n",
    "fcholltet: \"Basically these are all global metrics that were approximated\n",
    "batch-wise, which is more misleading than helpful. This was mentioned in\n",
    "the docs but it's much cleaner to remove them altogether. It was a mistake\n",
    "to merge them in the first place.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    \"\"\"Use Recall  and precision metrics to calculate harmonic mean (F1 score).\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1 = 2*((precision*recall)/(precision+recall))\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a 1D convnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NB_CLASSES = y_train.shape[1]\n",
    "NB_METAVARS = meta_train.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='wordindex') #MAX_SEQUENCE_LENGTH\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Dropout(0.2, name = 'dropout_embedded')(embedded_sequences)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv0')(x)\n",
    "\n",
    "x = MaxPooling1D(5, name = 'max_pool0')(x)\n",
    "\n",
    "x = Dropout(0.5, name = 'dropout0')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv1')(x)\n",
    "\n",
    "x = MaxPooling1D(5 , name = 'max_pool1')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv2')(x)\n",
    "\n",
    "x = MaxPooling1D(35, name = 'global_max_pool')(x)  # global max pooling\n",
    "\n",
    "x = Flatten()(x) #reduce dimensions from 3 to 2; convert to vector + FULLYCONNECTED\n",
    "\n",
    "meta_input = Input(shape=(NB_METAVARS,), name='meta')\n",
    "meta_hidden = Dense(128, activation='relu', name = 'hidden_meta')(meta_input)\n",
    "meta_hidden = Dropout(0.2, name = 'dropout_meta')(meta_hidden)\n",
    "\n",
    "\n",
    "title_input = Input(shape=(title_train.shape[1],), name='titles')\n",
    "title_hidden = Dense(128, activation='relu', name = 'hidden_title')(title_input)\n",
    "title_hidden = Dropout(0.2, name = 'dropout_title')(title_hidden)\n",
    "\n",
    "desc_input = Input(shape=(desc_train.shape[1],), name='descs')\n",
    "desc_hidden = Dense(128, activation='relu', name = 'hidden_desc')(desc_input)\n",
    "desc_hidden = Dropout(0.2, name = 'dropout_desc')(desc_hidden)\n",
    "\n",
    "concatenated = concatenate([meta_hidden, title_hidden, desc_hidden, x])\n",
    "\n",
    "x = Dense(400, activation='relu', name = 'fully_connected0')(concatenated)\n",
    "\n",
    "x = Dropout(0.2, name = 'dropout1')(x)\n",
    "\n",
    "x = Dense(NB_CLASSES, activation='sigmoid', name = 'fully_connected1')(x)\n",
    "\n",
    "# # The Model class turns an input tensor and output tensor into a model\n",
    "# This creates Keras model instance, will use this instance to train/test the model.\n",
    "model = Model(inputs=[meta_input, title_input, desc_input, sequence_input], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "wordindex (InputLayer)          (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 100)    31285300    wordindex[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_embedded (Dropout)      (None, 1000, 100)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv1D)                  (None, 996, 128)     64128       dropout_embedded[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pool0 (MaxPooling1D)        (None, 199, 128)     0           conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout0 (Dropout)              (None, 199, 128)     0           max_pool0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv1D)                  (None, 195, 128)     82048       dropout0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pool1 (MaxPooling1D)        (None, 39, 128)      0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "meta (InputLayer)               (None, 452)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "titles (InputLayer)             (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "descs (InputLayer)              (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv1D)                  (None, 35, 128)      82048       max_pool1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hidden_meta (Dense)             (None, 128)          57984       meta[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "hidden_title (Dense)            (None, 128)          1280128     titles[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "hidden_desc (Dense)             (None, 128)          1280128     descs[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pool (MaxPooling1D)  (None, 1, 128)       0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_meta (Dropout)          (None, 128)          0           hidden_meta[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_title (Dropout)         (None, 128)          0           hidden_title[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_desc (Dropout)          (None, 128)          0           hidden_desc[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           global_max_pool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           dropout_meta[0][0]               \n",
      "                                                                 dropout_title[0][0]              \n",
      "                                                                 dropout_desc[0][0]               \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fully_connected0 (Dense)        (None, 400)          205200      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 400)          0           fully_connected0[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fully_connected1 (Dense)        (None, 218)          87418       dropout1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 34,424,382\n",
      "Trainable params: 34,424,382\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard callbacks /metrics /monitor training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **Size of these files is killing storage during training. Is it histograms?**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tb = TensorBoard(log_dir='./learn_embedding_logs', histogram_freq=1, write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = os.path.join(DATADIR, 'model_checkpoint.hdf5')\n",
    "\n",
    "cp = ModelCheckpoint(\n",
    "                     filepath = CHECKPOINT_PATH, \n",
    "                     monitor='val_loss', \n",
    "                     verbose=0, \n",
    "                     save_best_only=False, \n",
    "                     save_weights_only=False, \n",
    "                     mode='auto', \n",
    "                     period=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "#model.fit(x, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 & 3. Train & compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 161020 samples, validate on 10377 samples\n",
      "Epoch 1/10\n",
      "161020/161020 [==============================] - 117s 729us/step - loss: 0.0096 - binary_accuracy: 0.9946 - f1: nan - val_loss: 0.0048 - val_binary_accuracy: 0.9968 - val_f1: 0.7391\n",
      "Epoch 2/10\n",
      "161020/161020 [==============================] - 109s 675us/step - loss: 0.0033 - binary_accuracy: 0.9978 - f1: 0.8613 - val_loss: 0.0042 - val_binary_accuracy: 0.9972 - val_f1: 0.7824\n",
      "Epoch 3/10\n",
      "161020/161020 [==============================] - 108s 674us/step - loss: 0.0025 - binary_accuracy: 0.9984 - f1: 0.8987 - val_loss: 0.0041 - val_binary_accuracy: 0.9973 - val_f1: 0.7954\n",
      "Epoch 4/10\n",
      "161020/161020 [==============================] - 108s 674us/step - loss: 0.0021 - binary_accuracy: 0.9986 - f1: 0.9167 - val_loss: 0.0040 - val_binary_accuracy: 0.9974 - val_f1: 0.8044\n",
      "Epoch 5/10\n",
      "161020/161020 [==============================] - 108s 673us/step - loss: 0.0018 - binary_accuracy: 0.9988 - f1: 0.9279 - val_loss: 0.0041 - val_binary_accuracy: 0.9973 - val_f1: 0.8038\n",
      "Epoch 6/10\n",
      "161020/161020 [==============================] - 109s 674us/step - loss: 0.0016 - binary_accuracy: 0.9989 - f1: 0.9356 - val_loss: 0.0043 - val_binary_accuracy: 0.9974 - val_f1: 0.8054\n"
     ]
    }
   ],
   "source": [
    "# metrics callback causes: CCCCCCR55555555511155\n",
    "# So disable for now\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "# Replicates `model` on 8 GPUs.\n",
    "# This assumes that your machine has 8 available GPUs.\n",
    "parallel_model = multi_gpu_model(model, gpus=8)\n",
    "parallel_model.compile(loss=WeightedBinaryCrossEntropy(POS_RATIO),\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['binary_accuracy', f1])\n",
    "\n",
    "# This `fit` call will be distributed on 8 GPUs.\n",
    "# Since the batch size is 256, each GPU will process 32 samples.\n",
    "history = parallel_model.fit(\n",
    "    {'meta': meta_train, 'titles': title_train, 'descs': desc_train, 'wordindex': x_train},\n",
    "    y_train, \n",
    "    validation_data=([meta_dev, title_dev, desc_dev, x_dev], y_dev), \n",
    "    epochs=10, batch_size=128, callbacks=[early_stopping]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_binary_accuracy', 'val_f1', 'loss', 'binary_accuracy', 'f1'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XuYFdWd7vHvy/0qKJJRAW0MRGkQ\nFTuohxBEvGCMckwYA2KijgmJj8YkTs4JmkximPCM5njU6JA8IVHHKIoMxoQkRnKBiXomgzTEoICM\nhIs23gABRRRs+J0/qrrZtLuvu6s33f1+nqeerlq1qmpVN+zfXmtVraWIwMzMrKk6FLsAZmbWujmQ\nmJlZQRxIzMysIA4kZmZWEAcSMzMriAOJmZkVxIHEik5SR0m7JB3bnHmLSdIQSc3+bL2kcyRtzNle\nK2lsQ/I24Vo/lXRTU4+v47zfk/RvzX1eK55OxS6AtT6SduVs9gD2APvS7S9GxNzGnC8i9gG9mjtv\nexARJzTHeSR9Hrg8Is7KOffnm+Pc1vY5kFijRUT1B3n6jffzEfGH2vJL6hQRlS1RNjNreW7asmaX\nNl08IulhSW8Dl0s6U9J/Sdoh6VVJd0nqnObvJCkklaTbD6b7fyvpbUl/ljS4sXnT/RdI+m9JOyXd\nLen/SbqylnI3pIxflLRO0nZJd+Uc21HSHZK2SVoPTKzj9/NNSfNqpM2WdHu6/nlJa9L7+VtaW6jt\nXBWSzkrXe0h6IC3bKuC0Gnm/JWl9et5Vki5O008C/hUYmzYbbs353d6cc/yX0nvfJukXko5uyO+m\nPpIuScuzQ9JiSSfk7LtJ0iuS3pL0Qs69niFpRZr+uqT/09DrWQYiwouXJi/ARuCcGmnfA/YCF5F8\nWekOfBQ4naQWfDzw38B1af5OQAAl6faDwFagDOgMPAI82IS8HwLeBial+24A3geurOVeGlLGXwJ9\ngBLgzap7B64DVgEDgX7Ak8l/r7zXOR7YBfTMOfcbQFm6fVGaR8DZwLvAyHTfOcDGnHNVAGel67cB\n/wEcDhwHrK6R91Lg6PRvcllahr9L930e+I8a5XwQuDldPy8t4ylAN+CHwOKG/G7y3P/3gH9L14el\n5Tg7/RvdBKxN14cDm4Cj0ryDgePT9WXA1HS9N3B6sf8vtOfFNRLLytMR8auI2B8R70bEsohYGhGV\nEbEemAOMq+P4BRFRHhHvA3NJPsAam/eTwLMR8ct03x0kQSevBpbxXyJiZ0RsJPnQrrrWpcAdEVER\nEduAW+q4znrgeZIAB3AusD0iytP9v4qI9ZFYDPwRyNuhXsOlwPciYntEbCKpZeRed35EvJr+TR4i\n+RJQ1oDzAkwDfhoRz0bEe8AMYJykgTl5avvd1GUKsDAiFqd/o1tIgtHpQCVJ0BqeNo9uSH93kHwh\nGCqpX0S8HRFLG3gflgEHEsvKy7kbkk6U9BtJr0l6C5gJHFnH8a/lrO+m7g722vIek1uOiAiSb/B5\nNbCMDboWyTfpujwETE3XL0u3q8rxSUlLJb0paQdJbaCu31WVo+sqg6QrJf01bULaAZzYwPNCcn/V\n54uIt4DtwICcPI35m9V23v0kf6MBEbEW+EeSv8MbaVPpUWnWq4BSYK2kZyR9ooH3YRlwILGs1Hz0\n9cck38KHRMRhwLdJmm6y9CpJUxMAksTBH3w1FVLGV4FBOdv1PZ48HzhH0gCSmslDaRm7AwuAfyFp\nduoL/K6B5XittjJIOh74EXAN0C897ws5563vUeVXSJrLqs7Xm6QJbXMDytWY83Yg+ZttBoiIByNi\nDEmzVkeS3wsRsTYippA0X/5f4FFJ3QosizWRA4m1lN7ATuAdScOAL7bANX8NjJJ0kaROwFeA/hmV\ncT7wVUkDJPUDvlFX5oh4DXga+DdgbUS8mO7qCnQBtgD7JH0SmNCIMtwkqa+S92yuy9nXiyRYbCGJ\nqV8gqZFUeR0YWPVwQR4PA1dLGimpK8kH+lMRUWsNrxFlvljSWem1/xdJv9ZSScMkjU+v92667Ce5\ngc9KOjKtwexM721/gWWxJnIgsZbyj8AVJB8SPybpFM9URLwOfAa4HdgGfBj4C8l7L81dxh+R9GU8\nR9IRvKABxzxE0nle3awVETuArwGPkXRYTyYJiA3xHZKa0Ubgt8DPcs67ErgbeCbNcwKQ26/we+BF\n4HVJuU1UVcc/QdLE9Fh6/LEk/SYFiYhVJL/zH5EEuYnAxWl/SVfg+yT9Wq+R1IC+mR76CWCNkqcC\nbwM+ExF7Cy2PNY2SZmOztk9SR5KmlMkR8VSxy2PWVrhGYm2apIlpU09X4J9InvZ5psjFMmtTHEis\nrfsYsJ6k2eR84JKIqK1py8yawE1bZmZWENdIzMysIO1i0MYjjzwySkpKil0MM7NWY/ny5Vsjoq7H\n5au1i0BSUlJCeXl5sYthZtZqSKpvdIZqbtoyM7OCOJCYmVlBHEjMzKwg7aKPxMxa1vvvv09FRQXv\nvfdesYti9ejWrRsDBw6kc+fahlmrnwOJmTW7iooKevfuTUlJCcmgy3Yoigi2bdtGRUUFgwcPrv+A\nWrhpqxZz50JJCXTokPycO7fYJTJrPd577z369evnIHKIk0S/fv0Krjm6RpLH3LkwfTrs3p1sb9qU\nbANMK3i8U7P2wUGkdWiOv5NrJHl885sHgkiV3buTdDMzO5gDSR4vvdS4dDM7dGzbto1TTjmFU045\nhaOOOooBAwZUb+/d27ApS6666irWrl1bZ57Zs2czt5navD/2sY/x7LPPNsu5isFNW3kce2zSnJUv\n3cya39y5SY3/pZeS/2ezZjW9Gblfv37VH8o333wzvXr14utf//pBeSKCiKBDh/zfpe+77756r3Pt\ntdc2rYBtkGskecyaBT16HJzWo0eSbmbNq6pPctMmiDjQJ9ncD7isW7eO0tJSpk2bxvDhw3n11VeZ\nPn06ZWVlDB8+nJkzZ1bnraohVFZW0rdvX2bMmMHJJ5/MmWeeyRtvvAHAt771Le68887q/DNmzGD0\n6NGccMIJ/Od//icA77zzDp/+9KcpLS1l8uTJlJWV1VvzePDBBznppJMYMWIEN910EwCVlZV89rOf\nrU6/6667ALjjjjsoLS1l5MiRXH755c37C2sE10jyqPom1FzfkMysdnX1STb3/7kXXniBn/3sZ5SV\nlQFwyy23cMQRR1BZWcn48eOZPHkypaWlBx2zc+dOxo0bxy233MINN9zAvffey4wZMz5w7ojgmWee\nYeHChcycOZMnnniCu+++m6OOOopHH32Uv/71r4waNarO8lVUVPCtb32L8vJy+vTpwznnnMOvf/1r\n+vfvz9atW3nuuecA2LFjBwDf//732bRpE126dKlOKwbXSGoxbRps3Aj79yc/HUTMstGSfZIf/vCH\nq4MIwMMPP8yoUaMYNWoUa9asYfXq1R84pnv37lxwwQUAnHbaaWzcuDHvuT/1qU99IM/TTz/NlClT\nADj55JMZPnx4neVbunQpZ599NkceeSSdO3fmsssu48knn2TIkCGsXbuW66+/nkWLFtGnTx8Ahg8f\nzuWXX87cuXMLeqGwUA4kZlZUtfU9ZtEn2bNnz+r1F198kR/84AcsXryYlStXMnHixLzvU3Tp0qV6\nvWPHjlRWVuY9d9euXevN01T9+vVj5cqVjB07ltmzZ/PFL34RgEWLFvGlL32JZcuWMXr0aPbt29es\n120oBxIzK6pi9Um+9dZb9O7dm8MOO4xXX32VRYsWNfs1xowZw/z58wF47rnn8tZ4cp1++uksWbKE\nbdu2UVlZybx58xg3bhxbtmwhIvj7v/97Zs6cyYoVK9i3bx8VFRWcffbZfP/732fr1q3srtlG2ELc\nR2JmRVWsPslRo0ZRWlrKiSeeyHHHHceYMWOa/Rpf/vKX+dznPkdpaWn1UtUslc/AgQP553/+Z846\n6ywigosuuogLL7yQFStWcPXVVxMRSOLWW2+lsrKSyy67jLfffpv9+/fz9a9/nd69ezf7PTREu5iz\nvaysLDyxlVnLWbNmDcOGDSt2MYqusrKSyspKunXrxosvvsh5553Hiy++SKdOh9Z3+Hx/L0nLI6Ks\nlkMOcmjdjZlZG7Jr1y4mTJhAZWUlEcGPf/zjQy6INIe2d0dmZoeIvn37snz58mIXI3OZdrZLmihp\nraR1kj7w4LWkrpIeSfcvlVSSs+/GNH2tpPNz0r8i6XlJqyR9Ncvym5lZ/TILJJI6ArOBC4BSYKqk\n0hrZrga2R8QQ4A7g1vTYUmAKMByYCPxQUkdJI4AvAKOBk4FPShqS1T2YmVn9sqyRjAbWRcT6iNgL\nzAMm1cgzCbg/XV8ATFAypvEkYF5E7ImIDcC69HzDgKURsTsiKoE/AZ/K8B7MzKweWQaSAcDLOdsV\naVrePGlg2An0q+PY54GxkvpJ6gF8AhiU7+KSpksql1S+ZcuWZrgdMzPLp1W9kBgRa0iav34HPAE8\nC+R9lTMi5kREWUSU9e/fvwVLaWbFNn78+A+8YHjnnXdyzTXX1Hlcr169AHjllVeYPHly3jxnnXUW\n9b1OcOeddx70cuAnPvGJZhkL6+abb+a2224r+DzNLctAspmDawsD07S8eSR1AvoA2+o6NiLuiYjT\nIuLjwHbgvzMpvZm1WlOnTmXevHkHpc2bN4+pU6c26PhjjjmGBQsWNPn6NQPJ448/Tt++fZt8vkNd\nloFkGTBU0mBJXUg6zxfWyLMQuCJdnwwsjuQNyYXAlPSprsHAUOAZAEkfSn8eS9I/8lCG92BmrdDk\nyZP5zW9+Uz2R1caNG3nllVcYO3Zs9bsdo0aN4qSTTuKXv/zlB47fuHEjI0aMAODdd99lypQpDBs2\njEsuuYR33323Ot8111xTPQz9d77zHQDuuusuXnnlFcaPH8/48eMBKCkpYevWrQDcfvvtjBgxghEj\nRlQPQ79x40aGDRvGF77wBYYPH85555130HXyefbZZznjjDMYOXIkl1xyCdu3b6++ftXQ8lUDRv7p\nT3+qntzr1FNP5e23327y7zafzN4jiYhKSdcBi4COwL0RsUrSTKA8IhYC9wAPSFoHvEkSbEjzzQdW\nA5XAtRFR1YT1qKR+wPtpevHGTjazen31q9Dck/+dcgqkn8F5HXHEEYwePZrf/va3TJo0iXnz5nHp\npZciiW7duvHYY49x2GGHsXXrVs444wwuvvjiWucu/9GPfkSPHj1Ys2YNK1euPGgo+FmzZnHEEUew\nb98+JkyYwMqVK7n++uu5/fbbWbJkCUceeeRB51q+fDn33XcfS5cuJSI4/fTTGTduHIcffjgvvvgi\nDz/8MD/5yU+49NJLefTRR+ucY+Rzn/scd999N+PGjePb3/423/3ud7nzzju55ZZb2LBhA127dq1u\nTrvtttuYPXs2Y8aMYdeuXXTr1q0Rv+36ZdpHEhGPR8RHIuLDETErTft2GkSIiPci4u8jYkhEjI6I\n9TnHzkqPOyEifpuTPjYiSiPi5Ij4Y5blN7PWK7d5K7dZKyK46aabGDlyJOeccw6bN2/m9ddfr/U8\nTz75ZPUH+siRIxk5cmT1vvnz5zNq1ChOPfVUVq1aVe+gjE8//TSXXHIJPXv2pFevXnzqU5/iqaee\nAmDw4MGccsopQN3D1UMyR8qOHTsYN24cAFdccQVPPvlkdRmnTZvGgw8+WP0W/ZgxY7jhhhu46667\n2LFjR7O/Xe83280sU3XVHLI0adIkvva1r7FixQp2797NaaedBsDcuXPZsmULy5cvp3PnzpSUlOQd\nPr4+GzZs4LbbbmPZsmUcfvjhXHnllU06T5WqYeghGYq+vqat2vzmN7/hySef5Fe/+hWzZs3iueee\nY8aMGVx44YU8/vjjjBkzhkWLFnHiiSc2uaw1taqntszMGqpXr16MHz+ef/iHfziok33nzp186EMf\nonPnzixZsoRNmzbVeZ6Pf/zjPPRQ0hX7/PPPs3LlSiAZhr5nz5706dOH119/nd/+trrhhN69e+ft\nhxg7diy/+MUv2L17N++88w6PPfYYY8eObfS99enTh8MPP7y6NvPAAw8wbtw49u/fz8svv8z48eO5\n9dZb2blzJ7t27eJvf/sbJ510Et/4xjf46Ec/ygsvvNDoa9bFNRIza7OmTp3KJZdcctATXNOmTeOi\niy7ipJNOoqysrN5v5tdccw1XXXUVw4YNY9iwYdU1m5NPPplTTz2VE088kUGDBh00DP306dOZOHEi\nxxxzDEuWLKlOHzVqFFdeeSWjR48G4POf/zynnnpqnc1Ytbn//vv50pe+xO7duzn++OO577772Ldv\nH5dffjk7d+4kIrj++uvp27cv//RP/8SSJUvo0KEDw4cPr57xsbl4GHkza3YeRr51KXQYeTdtmZlZ\nQRxIzMysIA4kZpaJ9tBs3hY0x9/JgcTMml23bt3Ytm2bg8khLiLYtm1bwS8o+qktM2t2AwcOpKKi\nAo+8fejr1q0bAwcOLOgcDiRm1uw6d+7M4MGDi10MayFu2jIzs4I4kJiZWUEcSMzMrCAOJGZmVhAH\nEjMzK4gDiZmZFSTTQCJpoqS1ktZJmpFnf1dJj6T7l0oqydl3Y5q+VtL5Oelfk7RK0vOSHpbUvFN9\nmZlZo2QWSCR1BGYDFwClwFRJpTWyXQ1sj4ghwB3AremxpSTT7g4HJgI/lNRR0gDgeqAsIkaQTOE7\nJat7MDOz+mVZIxkNrIuI9RGxF5gHTKqRZxJwf7q+AJigZOLkScC8iNgTERuAden5IHmJsrukTkAP\n4JUM78HMzOqRZSAZALycs12RpuXNExGVwE6gX23HRsRm4DbgJeBVYGdE/C7fxSVNl1QuqdzDNJiZ\nZadVdbZLOpyktjIYOAboKenyfHkjYk5ElEVEWf/+/VuymGZm7UqWgWQzMChne2CaljdP2lTVB9hW\nx7HnABsiYktEvA/8HPgfmZTezMwaJMtAsgwYKmmwpC4kneILa+RZCFyRrk8GFkcy7vRCYEr6VNdg\nYCjwDEmT1hmSeqR9KROANRneg5mZ1SOz0X8jolLSdcAikqer7o2IVZJmAuURsRC4B3hA0jrgTdIn\nsNJ884HVQCVwbUTsA5ZKWgCsSNP/AszJ6h7MzKx+ag8Tz5SVlUV5eXmxi2Fm1mpIWh4RZQ3J26o6\n283M7NDjQGJmZgVxIDEzs4I4kJiZWUEcSMzMrCAOJGZmVhAHEjMzK4gDiZmZFcSBxMzMCuJAYmZm\nBXEgMTOzgjiQmJlZQRxIzMysIA4kZmZWEAcSMzMriAOJmZkVJNNAImmipLWS1kmakWd/V0mPpPuX\nSirJ2Xdjmr5W0vlp2gmSns1Z3pL01SzvwczM6pbZVLuSOgKzgXOBCmCZpIURsTon29XA9ogYImkK\ncCvwGUmlJNPuDgeOAf4g6SMRsRY4Jef8m4HHsroHMzOrX5Y1ktHAuohYHxF7gXnApBp5JgH3p+sL\ngAmSlKbPi4g9EbEBWJeeL9cE4G8RsSmzOzAzs3plGUgGAC/nbFekaXnzREQlsBPo18BjpwAP13Zx\nSdMllUsq37JlS5NuwMzM6tcqO9sldQEuBv69tjwRMSciyiKirH///i1XODOzdibLQLIZGJSzPTBN\ny5tHUiegD7CtAcdeAKyIiNebucxmZtZIWQaSZcBQSYPTGsQUYGGNPAuBK9L1ycDiiIg0fUr6VNdg\nYCjwTM5xU6mjWcvMzFpOZk9tRUSlpOuARUBH4N6IWCVpJlAeEQuBe4AHJK0D3iQJNqT55gOrgUrg\n2ojYByCpJ8mTYF/MquxmZtZwSioAbVtZWVmUl5cXuxhmZq2GpOURUdaQvK2ys93MzA4dDiRmZlYQ\nBxIzMyuIA4mZmRXEgcTMzAriQGJmZgVxIDEzs4I4kJiZWUEcSMzMrCAOJGZmVhAHEjMzK4gDiZmZ\nFcSBxMzMCuJAYmZmBXEgMTOzgjiQmJlZQTINJJImSloraZ2kGXn2d5X0SLp/qaSSnH03pulrJZ2f\nk95X0gJJL0haI+nMLO/BzMzqllkgkdQRmA1cAJQCUyWV1sh2NbA9IoYAdwC3pseWkky7OxyYCPww\nPR/AD4AnIuJE4GRgTVb3YGZm9cuyRjIaWBcR6yNiLzAPmFQjzyTg/nR9ATBBktL0eRGxJyI2AOuA\n0ZL6AB8nmeudiNgbETsyvAczM6tHloFkAPByznZFmpY3T0RUAjuBfnUcOxjYAtwn6S+SfiqpZ76L\nS5ouqVxS+ZYtW5rjfszMLI/W1tneCRgF/CgiTgXeAT7Q9wIQEXMioiwiyvr379+SZTQza1caFEgk\nfVhS13T9LEnXS+pbz2GbgUE52wPTtLx5JHUC+gDb6ji2AqiIiKVp+gKSwGJmZkXS0BrJo8A+SUOA\nOSQf8g/Vc8wyYKikwZK6kHSeL6yRZyFwRbo+GVgcEZGmT0mf6hoMDAWeiYjXgJclnZAeMwFY3cB7\nMDOzDHRqYL79EVEp6RLg7oi4W9Jf6jogzX8dsAjoCNwbEaskzQTKI2IhSaf5A5LWAW+SBBvSfPNJ\ngkQlcG1E7EtP/WVgbhqc1gNXNeqOzcysWSmpANSTSVoK3Al8E7goIjZIej4iRmRdwOZQVlYW5eXl\nxS6GmVmrIWl5RJQ1JG9Dm7auAs4EZqVBZDDwQFMLaGZmbUeDmrYiYjVwPYCkw4HeEXFrlgUzM7PW\noaFPbf2HpMMkHQGsAH4i6fZsi2ZmZq1BQ5u2+kTEW8CngJ9FxOnAOdkVy8zMWouGBpJOko4GLgV+\nnWF5zMyslWloIJlJ8hjv3yJimaTjgRezK5aZmbUWDe1s/3fg33O21wOfzqpQZmbWejS0s32gpMck\nvZEuj0oamHXhzMzs0NfQpq37SIYtOSZdfpWmmZlZO9fQQNI/Iu6LiMp0+TfAQ+qamVmDA8k2SZdL\n6pgul5OM0mtmZu1cQwPJP5A8+vsa8CrJSL1XZlQmMzNrRRoUSCJiU0RcHBH9I+JDEfE/8VNbZmZG\nYTMk3tBspTAzs1arkECiZiuFmZm1WoUEkvonMjEzszavzkAi6W1Jb+VZ3iZ5n6ROkiZKWitpnaQZ\nefZ3lfRIun+ppJKcfTem6WslnZ+TvlHSc5KeleTZqszMiqzOIVIiondTTyypIzAbOBeoAJZJWpjO\nbVLlamB7RAyRNAW4FfiMpFKSaXeHkwSsP0j6SM50u+MjYmtTy2ZmZs2nkKat+owG1kXE+ojYC8wD\nJtXIMwm4P11fAEyQpDR9XkTsiYgNwLr0fGZmdojJMpAMAF7O2a5I0/LmiYhKYCfQr55jA/idpOWS\nptd2cUnTJZVLKt+yZUtBN2JmZrXLMpBk5WMRMQq4ALhW0sfzZYqIORFRFhFl/ft7NBczs6xkGUg2\nA4NytgemaXnzSOoE9CEZeqXWYyOi6ucbwGNk2OQVfi7NzKxeWQaSZcBQSYMldSHpPF9YI89C4Ip0\nfTKwOCIiTZ+SPtU1GBgKPCOpp6TeAJJ6AucBz2dR+AgoLYULL4S77oK1ax1YzMzyadDEVk0REZWS\nriOZWbEjcG9ErJI0EyiPiIXAPcADktYBb5IEG9J884HVQCVwbUTsk/R3wGNJfzydgIci4oksyv/e\ne3DOObBoETz+eJJ23HFw3nlw/vkwYQL07ZvFlc3MWhdFO/iaXVZWFuXlTX/lZMOGJKD87nfwxz/C\nW29Bx45w+ukHAstHP5qkmZm1BZKWR0RZg/I6kDTO++/D0qUHAsuyZUmTV9++SQ3m/POTZdCg+s9l\nZnaociCpoTkDSU3btsEf/nAgsGxOHycYNuxAbWXcOOjRI5PLm5llwoGkhiwDSa4IWL06CSqLFsGT\nTyZ9LV27wtixBwLLSSeBPOSlmR3CHEhqaKlAUtO778JTTx2orTyfPl929NFJUDnvPDj3XPBrLmZ2\nqHEgqaFYgaSmzZuTgLJoEfz+9/Dmm0nNZNSoA7WVM8+ELl2KXVIza+8cSGo4VAJJrn37YMWKA81g\nf/5zktarF5x99oHAMmRIsUtqZu2RA0kNh2IgqWnnTliy5EBg2bAhST/++CSgnHdeEmAOO6y45TSz\n9sGBpIbWEEhyRcDf/nYgqCxeDO+8A506JU1fVYHltNOgQ2scLc3MDnkOJDW0tkBS0969SdNXVWBZ\nsSJJ79cv6ayvagY7pt6pxszMGsaBpIbWHkhqeuONg99dee21JH3EiAO1lbFjoXv34pbTzFovB5Ia\n2logyRUBK1ceeBrsqaeSGky3bsmLkFWBpbTU766YWcM5kNTQlgNJTe+8k7wIWdUM9sILSfrAgQcP\nONmvX3HLaWZNs2dP8urAm2/C9u0H1vNtd+sGv/xl067TmECS2ei/Vhw9e8IFFyQLwEsvHait/Pzn\ncO+9Sc3kox89MC7Y6acnHflm1jIiksFfGxIMam6/+27t5+3QAQ4/HI44Illa6ilP10jakcrKZJDJ\nqsCydCns35/8Y5swIQkq556bDDjZuXOxS2t26Nu7N/mgr+vDP9++7duT98Zq0737gWCQGxhy1/Nt\n9+7dfE9yummrBgeS/LZvT4bFrwosL710YF+nTkntpkePpv2sL0+3bu6zsUNDRNIk3JhaQdX2rl21\nn1dKRgWv78M/33a3bi13/7WX/xAJJJImAj8gmdjqpxFxS439XYGfAaeRTLH7mYjYmO67Ebga2Adc\nHxGLco7rCJQDmyPik/WVw4GkfhHJLJBLliQjGu/enfznaujP999v3PWkpgephvzs0cPzw7QX+/bB\n228nL/W+9Vbty86dtQeHysraz9+ly8Ef9A0NBn36tO5/g4dEH0n6YT8bOBeoAJZJWhgRq3OyXQ1s\nj4ghkqYAtwKfkVRKMlvicOAY4A+SPhIRVZXBrwBrAL/n3UwkOPHEZGmK999vfPCp7efrr38wva52\n4dp07dq42lPV0r37wdu1Ld27u2+pEO+/X/cHf9WHf3153nmn/mtJSbNP7of9wIG1B4Pc9e7dXXuu\nT5b/DUYD6yJiPYCkecAkkulzq0wCbk7XFwD/qmQe3UnAvIjYA2xIp+IdDfxZ0kDgQmAWcEOG5bdG\n6Nw5+QbWp08259+/PwkmDQlE9eXZsQNeeeWD6fv3N75cnTs3LOg0JkDVzN+9+6H1zXbPnsZ/2OfL\n+9579V+rQ4ekDy93OfLIZOhZ3oFEAAAL80lEQVSgmun5lj59kp89e3oUiCxlGUgGAC/nbFcAp9eW\nJ53jfSfQL03/rxrHDkjX7wT+N9A7gzLbIapDhwO1hyxEHKhV1bW8+279earyvfZa/n1NaU3u2rX5\nglT37klzza5dTasJ7N1bf3k7dTrwIV61HHUUfOQjdX/g11x69HBtoDVoVRVzSZ8E3oiI5ZLOqifv\ndGA6wLHHHtsCpbPWTEo+XLt0STpIsxKRfKNvSnCqLe+bb+bP1xRdu37ww3zQoIZ96Ocufpiifcky\nkGwGcmcuH5im5ctTIakT0Iek0722Yy8GLpb0CaAbcJikByPi8poXj4g5wBxIOtub5Y7MCiQlH7Ld\nuiXt71mJSJqOagtIe/YkfQa5waF37ySQmDVWloFkGTBU0mCSIDAFuKxGnoXAFcCfgcnA4ogISQuB\nhyTdTtLZPhR4JiL+DNwIkNZIvp4viJi1d1LShNW9u0cxsOxlFkjSPo/rgEUkj//eGxGrJM0EyiNi\nIXAP8EDamf4mSbAhzTefpGO+Erg254ktMzM7hPiFRDMz+4DGvEfiB+LMzKwgDiRmZlYQBxIzMyuI\nA4mZmRXEgcTMzAriQGJmZgVxIDEzs4I4kJiZWUEcSMzMrCAOJFZt7lwoKUmGbC8pSbbNzOrTqoaR\nt+zMnQvTpycjwwJs2pRsA0ybVrxymdmhzzUSA+Cb3zwQRKrs3p2km5nVxYHEAHjppcalm5lVcSAx\nAGqbRNKTS5pZfRxIDIBZs5L5sXP16JGkm5nVxYHEgKRDfc4cOO64ZHa9445Ltt3Rbmb1yTSQSJoo\naa2kdZJm5NnfVdIj6f6lkkpy9t2Ypq+VdH6a1k3SM5L+KmmVpO9mWf72Zto02LgR9u9PfjqImFlD\nZBZIJHUEZgMXAKXAVEmlNbJdDWyPiCHAHcCt6bGlJNPuDgcmAj9Mz7cHODsiTgZOASZKOiOrezAz\ns/plWSMZDayLiPURsReYB0yqkWcScH+6vgCYIElp+ryI2BMRG4B1wOhI7Erzd06Xtj9XsJnZISzL\nQDIAeDlnuyJNy5snIiqBnUC/uo6V1FHSs8AbwO8jYmm+i0uaLqlcUvmWLVua4XbMzCyfVtfZHhH7\nIuIUYCAwWtKIWvLNiYiyiCjr379/yxbSzKwdyTKQbAYG5WwPTNPy5pHUCegDbGvIsRGxA1hC0odi\nZmZFkmUgWQYMlTRYUheSzvOFNfIsBK5I1ycDiyMi0vQp6VNdg4GhwDOS+kvqCyCpO3Au8EKG92Bm\nZvXIbNDGiKiUdB2wCOgI3BsRqyTNBMojYiFwD/CApHXAmyTBhjTffGA1UAlcGxH7JB0N3J8+wdUB\nmB8Rv87qHszMrH5KKgBtW1lZWZSXlxe7GGZmrYak5RFR1pC8ra6z3czMDi0OJGZmVhAHEjMzK4gD\niZmZFcSBxMzMCuJAYu3a3LlQUgIdOiQ/584tdonMWp/M3iMxO9TNnQvTpx+Yq37TpmQbPIS+WWO4\nRmLt1je/eSCIVNm9O0k3s4ZzILF266WXGpduZvk5kFi7deyxjUs3s/wcSKzdmjULevQ4OK1HjyTd\nzBrOgcTarWnTYM4cOO44kJKfc+a4o92ssfzUlrVr06Y5cJgVyjUSMzMriAOJmZkVxIHErB3xm/yW\nhUwDiaSJktZKWidpRp79XSU9ku5fKqkkZ9+NafpaSeenaYMkLZG0WtIqSV/JsvxmbUnVm/ybNkHE\ngTf5HUysUJkFknQ63NnABUApMFVSaY1sVwPbI2IIcAdwa3psKcm0u8OBicAP0/NVAv8YEaXAGcC1\nec5pZnn4TX7LSpY1ktHAuohYHxF7gXnApBp5JgH3p+sLgAmSlKbPi4g9EbEBWAeMjohXI2IFQES8\nDawBBmR4D2Ztht/kt6xkGUgGAC/nbFfwwQ/96jwRUQnsBPo15Ni0GexUYGm+i0uaLqlcUvmWLVua\nfBNmbYXf5LestMrOdkm9gEeBr0bEW/nyRMSciCiLiLL+/fu3bAHNDkF+k9+ykmUg2QwMytkemKbl\nzSOpE9AH2FbXsZI6kwSRuRHx80xKbtYGtdc3+f2kWvayDCTLgKGSBkvqQtJ5vrBGnoXAFen6ZGBx\nRESaPiV9qmswMBR4Ju0/uQdYExG3Z1h2szZp2jTYuBH2709+tocg4ifVspdZIEn7PK4DFpF0is+P\niFWSZkq6OM12D9BP0jrgBmBGeuwqYD6wGngCuDYi9gFjgM8CZ0t6Nl0+kdU9mFnr5ifVWoaSCkDb\nVlZWFuXl5cUuhpm1sA4dkppITVJSK7PaSVoeEWUNydsqO9vNzBrCT6q1DAcSM2uz2uuTai39gIED\niZm1We3xSbViPGDgPhIzszakpCQJHjUdd1zypF5DuY/EzKydKsZQOA4kZmZtSDEeMHAgMTNrQ4rx\ngIEDiZlZG1KMBww6ZXdqMzMrhmnTWvbJNNdIzMysIA4kZmZWEAcSMzMriAOJmZkVxIHEzMwK0i6G\nSJG0BcgzaECDHAlsbcbitAa+57avvd0v+J4b67iIaNA85e0ikBRCUnlDx5tpK3zPbV97u1/wPWfJ\nTVtmZlYQBxIzMyuIA0n95hS7AEXge2772tv9gu85M+4jMTOzgrhGYmZmBXEgMTOzgjiQ1ELSvZLe\nkPR8scvSEiQNkrRE0mpJqyR9pdhlypqkbpKekfTX9J6/W+wytRRJHSX9RdKvi12WliBpo6TnJD0r\nqV3Muy2pr6QFkl6QtEbSmZldy30k+Un6OLAL+FlEjCh2ebIm6Wjg6IhYIak3sBz4nxGxushFy4wk\nAT0jYpekzsDTwFci4r+KXLTMSboBKAMOi4hPFrs8WZO0ESiLiHbzQqKk+4GnIuKnkroAPSJiRxbX\nco2kFhHxJPBmscvRUiLi1YhYka6/DawBBhS3VNmKxK50s3O6tPlvVpIGAhcCPy12WSwbkvoAHwfu\nAYiIvVkFEXAgsTwklQCnAkuLW5LspU08zwJvAL+PiDZ/z8CdwP8G9he7IC0ogN9JWi5perEL0wIG\nA1uA+9ImzJ9K6pnVxRxI7CCSegGPAl+NiLeKXZ6sRcS+iDgFGAiMltSmmzElfRJ4IyKWF7ssLexj\nETEKuAC4Nm26bss6AaOAH0XEqcA7wIysLuZAYtXSfoJHgbkR8fNil6clpdX+JcDEYpclY2OAi9M+\ng3nA2ZIeLG6RshcRm9OfbwCPAaOLW6LMVQAVOTXsBSSBJRMOJAZUdzzfA6yJiNuLXZ6WIKm/pL7p\nenfgXOCF4pYqWxFxY0QMjIgSYAqwOCIuL3KxMiWpZ/oACWnzznlAm34aMyJeA16WdEKaNAHI7MGZ\nTlmduLWT9DBwFnCkpArgOxFxT3FLlakxwGeB59I+A4CbIuLxIpYpa0cD90vqSPKlan5EtIvHYduZ\nvwMeS74r0Ql4KCKeKG6RWsSXgbnpE1vrgauyupAf/zUzs4K4acvMzAriQGJmZgVxIDEzs4I4kJiZ\nWUEcSMzMrCAOJGZNJGlfOpps1dJsbw5LKmkvI09b6+f3SMya7t10eBWzds01ErNmls598f10/otn\nJA1J00skLZa0UtIfJR2bpv+dpMfSeVH+Kul/pKfqKOkn6Vwpv0vfvkfS9em8MSslzSvSbZpVcyAx\na7ruNZq2PpOzb2dEnAT8K8louwB3A/dHxEhgLnBXmn4X8KeIOJlkPKRVafpQYHZEDAd2AJ9O02cA\np6bn+VJWN2fWUH6z3ayJJO2KiF550jcCZ0fE+nQgzNciop+krSSTh72fpr8aEUdK2gIMjIg9Oeco\nIRnWfmi6/Q2gc0R8T9ITJJOu/QL4Rc6cKmZF4RqJWTailvXG2JOzvo8DfZoXArNJai/LJLmv04rK\ngcQsG5/J+fnndP0/SUbcBZgGPJWu/xG4Bqon2upT20kldQAGRcQS4BtAH+ADtSKzluRvMmZN1z1n\npGSAJyKi6hHgwyWtJKlVTE3TvkwyY93/Ipm9rmo01q8AcyRdTVLzuAZ4tZZrdgQeTIONgLuynELV\nrCHcR2LWzNI+krKI2Frsspi1BDdtmZlZQVwjMTOzgrhGYmZmBXEgMTOzgjiQmJlZQRxIzMysIA4k\nZmZWkP8PsBmIuaCi1dAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdaa38e6e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, 7)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')           \n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')      \n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM8vL/wfk/z4KDeuzfQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdaa38414e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()    \n",
    "\n",
    "f1_values = history_dict['f1']\n",
    "val_f1_values = history_dict['val_f1']\n",
    "\n",
    "plt.plot(epochs, f1_values, 'bo', label='Training f1')\n",
    "plt.plot(epochs, val_f1_values, 'b', label='Validation f1')\n",
    "plt.title('Training and validation batch-level f1-micro')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1-micro')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_file(array,name):\n",
    "    df = pd.DataFrame(data = array.tolist(),columns=[i for i in range(1,y_train.shape[1]+1)])\n",
    "    df.to_csv(os.path.join(DATADIR, name+'.csv.gz'),compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_1149_0603_'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_run = time.strftime(\"_%H%M_%d%m_\")\n",
    "date_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = parallel_model.predict([meta_train, title_train, desc_train, x_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_prob,\"train_results\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_prob.copy()\n",
    "y_pred[y_pred>=P_THRESHOLD] = 1\n",
    "y_pred[y_pred<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro: (0.96550705420418204, 0.95414008846763598, 0.95978991725772356, None)\n",
      "macro: (0.97665066927709854, 0.97615234920539118, 0.97619486361415109, None)\n",
      "weightedmacro: (0.96555963463189509, 0.95414008846763598, 0.95946660957512531, None)\n"
     ]
    }
   ],
   "source": [
    "print('micro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='micro', sample_weight=None)))\n",
    "print('macro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='macro', sample_weight=None)))\n",
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='weighted', sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_dev = parallel_model.predict([meta_dev, title_dev, desc_dev, x_dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_prob_dev,\"dev_results\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dev = y_prob_dev.copy()\n",
    "y_pred_dev[y_pred_dev>=P_THRESHOLD] = 1\n",
    "y_pred_dev[y_pred_dev<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro: (0.82705689725747034, 0.78516839378238346, 0.80556847631071826, None)\n",
      "macro: (0.74028850220694231, 0.80507739477918894, 0.76078350782955473, None)\n",
      "weightedmacro: (0.83193502024226085, 0.78516839378238346, 0.80442425272928553, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('micro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='micro', sample_weight=None)))\n",
    "print('macro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='macro', sample_weight=None)))\n",
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='weighted', sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weightedmacro: (array([ 0.        ,  0.8       ,  0.87903226,  0.72222222,  1.        ,\n",
      "        0.6122449 ,  0.55555556,  0.80769231,  1.        ,  0.9       ,\n",
      "        1.        ,  0.8       ,  0.        ,  1.        ,  0.625     ,\n",
      "        0.        ,  0.75      ,  1.        ,  0.        ,  0.81481481,\n",
      "        0.88653367,  0.74      ,  0.87628866,  0.        ,  1.        ,\n",
      "        0.        ,  0.75      ,  1.        ,  1.        ,  0.88235294,\n",
      "        0.57142857,  0.8       ,  0.71428571,  0.        ,  0.71428571,\n",
      "        0.83944954,  0.83333333,  0.57894737,  0.69470405,  0.80952381,\n",
      "        0.71929825,  0.        ,  0.69230769,  0.86826347,  1.        ,\n",
      "        1.        ,  0.71428571,  1.        ,  0.        ,  0.83333333,\n",
      "        0.75      ,  1.        ,  1.        ,  0.54545455,  1.        ,\n",
      "        1.        ,  1.        ,  0.        ,  0.9352518 ,  0.30769231,\n",
      "        0.73006135,  0.6       ,  0.875     ,  0.52941176,  0.8372093 ,\n",
      "        0.33333333,  0.73658537,  0.77777778,  1.        ,  0.98876404,\n",
      "        0.68181818,  1.        ,  1.        ,  1.        ,  0.72916667,\n",
      "        0.75757576,  0.91764706,  0.87029289,  1.        ,  0.83512545,\n",
      "        1.        ,  0.88888889,  0.81818182,  0.84337349,  0.80631579,\n",
      "        1.        ,  0.        ,  0.69767442,  0.        ,  1.        ,\n",
      "        0.875     ,  0.85714286,  1.        ,  0.8489011 ,  0.85843373,\n",
      "        0.81927711,  1.        ,  1.        ,  0.66666667,  0.875     ,\n",
      "        0.67741935,  0.73722628,  0.9260355 ,  0.63414634,  0.        ,\n",
      "        0.84210526,  0.66666667,  0.7804878 ,  0.        ,  0.4       ,\n",
      "        0.45454545,  1.        ,  0.55555556,  0.93333333,  0.8       ,\n",
      "        1.        ,  1.        ,  0.        ,  0.33333333,  0.72906404,\n",
      "        0.71111111,  0.68518519,  0.48275862,  0.75      ,  0.97297297,\n",
      "        0.96581197,  1.        ,  0.73333333,  1.        ,  0.98958333,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.86486486,  0.46666667,  0.8460076 ,  0.82857143,  0.5       ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  0.80555556,\n",
      "        1.        ,  0.8       ,  0.85365854,  0.625     ,  1.        ,\n",
      "        1.        ,  0.        ,  0.93089431,  0.        ,  1.        ,\n",
      "        0.        ,  0.78787879,  0.97512438,  0.80769231,  0.92857143,\n",
      "        1.        ,  0.83333333,  0.90575916,  0.9625    ,  0.8627451 ,\n",
      "        0.8490566 ,  0.70588235,  0.68115942,  0.93589744,  0.84705882,\n",
      "        0.87179487,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.70866142,  0.67857143,  0.86734694,  1.        ,  0.25      ,\n",
      "        0.        ,  1.        ,  1.        ,  0.73333333,  0.85714286,\n",
      "        0.82608696,  0.94174757,  0.71428571,  0.58064516,  0.82718447,\n",
      "        1.        ,  0.        ,  0.78632479,  0.88888889,  0.5       ,\n",
      "        1.        ,  1.        ,  0.74088542,  0.66666667,  0.70212766,\n",
      "        0.5       ,  0.90909091,  0.66666667,  0.94339623,  0.        ,\n",
      "        0.        ,  0.93641618,  0.83739837,  0.66666667,  0.625     ,\n",
      "        0.88888889,  0.79888268,  0.        ,  0.76470588,  1.        ,\n",
      "        0.        ,  1.        ,  0.96132597]), array([ 0.        ,  1.        ,  0.94782609,  0.92857143,  1.        ,\n",
      "        0.46875   ,  1.        ,  0.67741935,  1.        ,  0.75      ,\n",
      "        1.        ,  0.94117647,  0.        ,  1.        ,  0.83333333,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.76923077,\n",
      "        0.71028971,  0.7254902 ,  0.89005236,  0.        ,  1.        ,\n",
      "        0.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.88235294,\n",
      "        0.7593361 ,  1.        ,  0.91666667,  0.62816901,  0.94444444,\n",
      "        0.45054945,  0.        ,  0.75      ,  0.82386364,  1.        ,\n",
      "        1.        ,  0.83333333,  1.        ,  0.        ,  0.96774194,\n",
      "        0.83458647,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.        ,  0.8496732 ,  1.        ,\n",
      "        0.66111111,  1.        ,  1.        ,  1.        ,  0.87804878,\n",
      "        1.        ,  0.60159363,  0.66141732,  1.        ,  0.92631579,\n",
      "        0.83333333,  1.        ,  1.        ,  1.        ,  0.55555556,\n",
      "        0.89285714,  0.87640449,  0.76190476,  1.        ,  0.88593156,\n",
      "        1.        ,  0.72727273,  1.        ,  0.8       ,  0.86067416,\n",
      "        1.        ,  0.        ,  0.67039106,  0.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.85359116,  0.78296703,\n",
      "        0.8       ,  1.        ,  1.        ,  0.8       ,  0.93333333,\n",
      "        0.75      ,  0.84166667,  0.86944444,  0.92857143,  0.        ,\n",
      "        0.88888889,  1.        ,  0.96969697,  0.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.        ,  1.        ,  0.71497585,\n",
      "        0.86486486,  0.80434783,  0.77777778,  1.        ,  0.88888889,\n",
      "        0.904     ,  1.        ,  0.66165414,  1.        ,  0.95      ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.78923767,  1.        ,  0.87598425,  0.8877551 ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  0.77333333,\n",
      "        1.        ,  0.8       ,  0.72916667,  1.        ,  1.        ,\n",
      "        1.        ,  0.        ,  0.84501845,  0.        ,  1.        ,\n",
      "        0.        ,  0.89655172,  0.92890995,  0.54545455,  1.        ,\n",
      "        1.        ,  1.        ,  0.84390244,  0.77      ,  0.69109948,\n",
      "        0.95744681,  0.92307692,  0.7704918 ,  0.81564246,  0.74482759,\n",
      "        0.70833333,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.60402685,  0.95      ,  0.70247934,  1.        ,  1.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.91666667,  1.        ,\n",
      "        0.95      ,  0.86607143,  0.83333333,  0.94736842,  0.72696246,\n",
      "        1.        ,  0.        ,  0.78632479,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.61182796,  1.        ,  0.78571429,\n",
      "        1.        ,  0.90909091,  1.        ,  0.92592593,  0.        ,\n",
      "        0.        ,  0.90502793,  0.73049645,  0.88      ,  0.83333333,\n",
      "        0.77419355,  0.74479167,  0.        ,  1.        ,  1.        ,\n",
      "        0.        ,  1.        ,  0.96666667]), array([ 0.        ,  0.88888889,  0.91213389,  0.8125    ,  1.        ,\n",
      "        0.53097345,  0.71428571,  0.73684211,  1.        ,  0.81818182,\n",
      "        1.        ,  0.86486486,  0.        ,  1.        ,  0.71428571,\n",
      "        0.        ,  0.85714286,  1.        ,  0.        ,  0.79136691,\n",
      "        0.78868552,  0.73267327,  0.88311688,  0.        ,  1.        ,\n",
      "        0.        ,  0.85714286,  1.        ,  1.        ,  0.9375    ,\n",
      "        0.72727273,  0.88888889,  0.83333333,  0.        ,  0.78947368,\n",
      "        0.79738562,  0.90909091,  0.70967742,  0.65976331,  0.87179487,\n",
      "        0.55405405,  0.        ,  0.72      ,  0.84548105,  1.        ,\n",
      "        1.        ,  0.76923077,  1.        ,  0.        ,  0.89552239,\n",
      "        0.79003559,  1.        ,  1.        ,  0.70588235,  1.        ,\n",
      "        1.        ,  1.        ,  0.        ,  0.89041096,  0.47058824,\n",
      "        0.69387755,  0.75      ,  0.93333333,  0.69230769,  0.85714286,\n",
      "        0.5       ,  0.6622807 ,  0.71489362,  1.        ,  0.95652174,\n",
      "        0.75      ,  1.        ,  1.        ,  1.        ,  0.63063063,\n",
      "        0.81967213,  0.89655172,  0.8125    ,  1.        ,  0.8597786 ,\n",
      "        1.        ,  0.8       ,  0.9       ,  0.82111437,  0.8326087 ,\n",
      "        1.        ,  0.        ,  0.68376068,  0.        ,  1.        ,\n",
      "        0.93333333,  0.92307692,  1.        ,  0.85123967,  0.81896552,\n",
      "        0.80952381,  1.        ,  1.        ,  0.72727273,  0.90322581,\n",
      "        0.71186441,  0.78599222,  0.89684814,  0.75362319,  0.        ,\n",
      "        0.86486486,  0.8       ,  0.86486486,  0.        ,  0.57142857,\n",
      "        0.625     ,  1.        ,  0.71428571,  0.96551724,  0.88888889,\n",
      "        1.        ,  1.        ,  0.        ,  0.5       ,  0.72195122,\n",
      "        0.7804878 ,  0.74      ,  0.59574468,  0.85714286,  0.92903226,\n",
      "        0.9338843 ,  1.        ,  0.69565217,  1.        ,  0.96938776,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.82532239,  0.63636364,  0.86073501,  0.85714286,  0.66666667,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  0.78911565,\n",
      "        1.        ,  0.8       ,  0.78651685,  0.76923077,  1.        ,\n",
      "        1.        ,  0.        ,  0.88588008,  0.        ,  1.        ,\n",
      "        0.        ,  0.83870968,  0.95145631,  0.65116279,  0.96296296,\n",
      "        1.        ,  0.90909091,  0.87373737,  0.85555556,  0.76744186,\n",
      "        0.9       ,  0.8       ,  0.72307692,  0.87164179,  0.79266055,\n",
      "        0.7816092 ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.65217391,  0.79166667,  0.77625571,  1.        ,  0.4       ,\n",
      "        0.        ,  1.        ,  1.        ,  0.81481481,  0.92307692,\n",
      "        0.88372093,  0.90232558,  0.76923077,  0.72      ,  0.77384196,\n",
      "        1.        ,  0.        ,  0.78632479,  0.94117647,  0.66666667,\n",
      "        1.        ,  1.        ,  0.67020024,  0.8       ,  0.74157303,\n",
      "        0.66666667,  0.90909091,  0.8       ,  0.93457944,  0.        ,\n",
      "        0.        ,  0.92045455,  0.78030303,  0.75862069,  0.71428571,\n",
      "        0.82758621,  0.77088949,  0.        ,  0.86666667,  1.        ,\n",
      "        0.        ,  1.        ,  0.96398892]), array([   0,    8,  115,   14,   48,   64,   10,  186,    1,   12,    3,\n",
      "         51,    0,    1,   36,    0,   33,    1,    0,  143, 1001,  204,\n",
      "        191,    0,    3,    0,    3,    1,    3,   15,    4,   12,    5,\n",
      "          0,   34,  482,    5,   24,  355,   18,   91,    0,   60,  176,\n",
      "          2,    2,   36,    5,    0,   31,  133,    2,    4,    6,    2,\n",
      "          1,    1,    0,  306,    8,  180,    6,    7,    9,   41,    1,\n",
      "        251,  127,    3,   95,   18,    1,    5,    7,   63,   28,   89,\n",
      "        273,    1,  263,    1,   11,    9,  175,  890,    2,    0,  179,\n",
      "          0,    4,    7,   12,    1,  362,  364,   85,    2,    1,    5,\n",
      "         15,   28,  120,  360,   28,    0,   18,    6,   33,    0,    2,\n",
      "         10,    1,    5,   14,    4,    1,    3,    0,    2,  207,   37,\n",
      "         46,   18,   12,   81,  125,    5,  133,    2,  100,    1,    2,\n",
      "          2,    1,    6,  446,    7,  508,   98,    1,    7,    2,    2,\n",
      "          1,   75,   16,  100,   48,    5,    6,    2,    0,  542,    0,\n",
      "          2,    0,   29,  211,   77,   13,    1,    5,  205,  100,  191,\n",
      "         47,   13,   61,  179,  290,   96,    2,    1,    5,    1,  149,\n",
      "         20,  121,    7,    1,    0,    5,   10,   12,    6,   20,  112,\n",
      "          6,   19,  586,   18,    0,  117,    8,    7,    2,    2,  930,\n",
      "          2,   42,    1,   11,   16,   54,    0,    0,  179,  141,   25,\n",
      "          6,   62,  192,    0,   13,    1,    0,    4,  180]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average=None, sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_train,\"true_train\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_dev,\"true_dev\"+date_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arrays = os.path.join(DATADIR, new_arraynpz_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(new_arrays):\n",
    "    arrays = np.load(new_arrays)\n",
    "    \n",
    "    x_new = sparse.csr_matrix(arrays['x'].all()).todense()\n",
    "    meta_new = sparse.csr_matrix(arrays['meta'].all()).todense()\n",
    "    title_new = sparse.csr_matrix(arrays['title'].all()).todense()\n",
    "    desc_new = sparse.csr_matrix(arrays['desc'].all()).todense()\n",
    "   \n",
    "    y_pred_new = model.predict([meta_new, title_new, desc_new, x_new])\n",
    "    \n",
    "    to_file(y_pred_new, \"new_predictions\"+date_run)\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "keep_output": true,
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
