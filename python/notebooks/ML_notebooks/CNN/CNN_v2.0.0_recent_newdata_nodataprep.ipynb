{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional NN to classify govuk content to level2 taxons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on:\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load requirements and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.utils import to_categorical, layer_utils, plot_model\n",
    "\n",
    "from keras.layers import (Embedding, Input, Dense, Dropout, \n",
    "                          Activation, Conv1D, MaxPooling1D, Flatten, concatenate, Reshape)\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.callbacks import TensorBoard, Callback, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score \n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import functools\n",
    "\n",
    "import h5py\n",
    "\n",
    "from scipy import sparse\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environmental vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATADIR=\"/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print data version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm running on data extracted from content store on /data\n"
     ]
    }
   ],
   "source": [
    "print('algorithm running on data extracted from content store on {}'.format(DATADIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuition for POS_RATIO is that it penalises the prediction of zero for everything, which is attractive to the model because the multilabel y matrix is super sparse. \n",
    "\n",
    "Increasing POS_RATIO should penalise predicting zeros more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MAX_NB_WORDS\n",
    "MAX_SEQUENCE_LENGTH =1000\n",
    "EMBEDDING_DIM = 100 # keras embedding layer output_dim = Dimension of the dense embedding\n",
    "P_THRESHOLD = 0.5 #Threshold for probability of being assigned to class\n",
    "POS_RATIO = 0.5 #ratio of positive to negative for each class in weighted binary cross entropy loss function\n",
    "NUM_WORDS=20000 #keras tokenizer num_words: None or int. Maximum number of words to work with \n",
    "#(if set, tokenization will be restricted to the top num_words most common words in the dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = np.load(os.path.join(DATADIR, 'train_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'meta', 'title', 'desc', 'y', 'content_id']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (161020, 1000)\n",
      "meta_train.shape = (161020, 452)\n",
      "title_train.shape = (161020, 10000)\n",
      "desc_train.shape = (161020, 10000)\n",
      "y_train.shape = (161020, 218)\n"
     ]
    }
   ],
   "source": [
    "x_train = sparse.csr_matrix(train['x']).todense()\n",
    "meta_train = sparse.csr_matrix(train['meta'].all()).todense()\n",
    "title_train = sparse.csr_matrix(train['title'].all()).todense()\n",
    "desc_train = sparse.csr_matrix(train['desc'].all()).todense()\n",
    "y_train = sparse.csr_matrix(train['y'].all()).todense()\n",
    "\n",
    "print('x_train.shape = {}'.format(x_train.shape))\n",
    "print('meta_train.shape = {}'.format(meta_train.shape))\n",
    "print('title_train.shape = {}'.format(title_train.shape))\n",
    "print('desc_train.shape = {}'.format(desc_train.shape))\n",
    "print('y_train.shape = {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dev = np.load(os.path.join(DATADIR, 'dev_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_dev.shape = (10377, 1000)\n",
      "meta_dev.shape = (10377, 452)\n",
      "title_dev.shape = (10377, 10000)\n",
      "desc_dev.shape = (10377, 10000)\n",
      "y_dev.shape = (10377, 218)\n"
     ]
    }
   ],
   "source": [
    "x_dev = sparse.csr_matrix(dev['x']).todense()\n",
    "meta_dev = sparse.csr_matrix(dev['meta'].all()).todense()\n",
    "title_dev = sparse.csr_matrix(dev['title'].all()).todense()\n",
    "desc_dev = sparse.csr_matrix(dev['desc'].all()).todense()\n",
    "y_dev = sparse.csr_matrix(dev['y'].all()).todense()\n",
    "\n",
    "print('x_dev.shape = {}'.format(x_dev.shape))\n",
    "print('meta_dev.shape = {}'.format(meta_dev.shape))\n",
    "print('title_dev.shape = {}'.format(title_dev.shape))\n",
    "print('desc_dev.shape = {}'.format(desc_dev.shape))\n",
    "print('y_dev.shape = {}'.format(y_dev.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = np.load(os.path.join(DATADIR, 'test_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test.shape = (10379, 1000)\n",
      "meta_test.shape = (10379, 452)\n",
      "title_test.shape = (10379, 10000)\n",
      "desc_test.shape = (10379, 10000)\n",
      "y_test.shape = (10379, 218)\n"
     ]
    }
   ],
   "source": [
    "x_test = sparse.csr_matrix(test['x']).todense()\n",
    "meta_test = sparse.csr_matrix(test['meta'].all()).todense()\n",
    "title_test = sparse.csr_matrix(test['title'].all()).todense()\n",
    "desc_test = sparse.csr_matrix(test['desc'].all()).todense()\n",
    "y_test = sparse.csr_matrix(test['y'].all()).todense()\n",
    "\n",
    "print('x_test.shape = {}'.format(x_test.shape))\n",
    "print('meta_test.shape = {}'.format(meta_test.shape))\n",
    "print('title_test.shape = {}'.format(title_test.shape))\n",
    "print('desc_test.shape = {}'.format(desc_test.shape))\n",
    "print('y_test.shape = {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### previous shapes in old data \n",
    "Shape of x_train: (150870, 1000)\n",
    "Shape of metax_train: (150870, 436)\n",
    "Shape of titlex_train: (150870, 10000)\n",
    "Shape of descx_train: (150870, 10000)\n",
    "Shape of y_train: (150870, 210)\n",
    "\n",
    "Shape of x_dev: (9234, 1000)\n",
    "Shape of meta_dev: (9234, 436)\n",
    "Shape of titlex_dev: (9234, 10000)\n",
    "Shape of descx_dev: (9234, 10000)\n",
    "Shape of y_dev: (9234, 210)\n",
    "\n",
    "Shape of x_test: (9234, 1000)\n",
    "Shape of metax_test: (9234, 436)\n",
    "Shape of titlex_test: (9234, 10000)\n",
    "Shape of descx_test: (9234, 10000)\n",
    "Shape of y_test: (9234, 210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing the Embedding layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "def load_tokenizer_from_file(filename):\n",
    "    \n",
    "    tokenizer = Tokenizer()\n",
    "\n",
    "    with open(filename, 'r') as infile:\n",
    "        tokenizer_data = json.load(infile)\n",
    "\n",
    "    tokenizer.word_counts = OrderedDict(tokenizer_data['word_counts'])\n",
    "    tokenizer.word_docs = tokenizer_data['word_docs']\n",
    "    tokenizer.word_index = tokenizer_data['word_index']\n",
    "    tokenizer.document_count = tokenizer_data['document_count']\n",
    "    tokenizer.index_docs = tokenizer_data['index_docs']\n",
    "\n",
    "    return tokenizer\n",
    "\n",
    "tokenizer_combined_text = load_tokenizer_from_file(os.path.join(DATADIR, \"combined_text_tokenizer.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(tokenizer_combined_text.word_index) + 1, \n",
    "                            EMBEDDING_DIM, \n",
    "                            input_length=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Embedding layer should be fed sequences of integers, i.e. a 2D input of shape (samples, indices). These input sequences should be padded so that they all have the same length in a batch of input data (although an Embedding layer is capable of processing sequence of heterogenous length, if you don't pass an explicit input_length argument to the layer).\n",
    "\n",
    "All that the Embedding layer does is to map the integer inputs to the vectors found at the corresponding index in the embedding matrix, i.e. the sequence [1, 2] would be converted to [embeddings[1], embeddings[2]]. This means that the output of the Embedding layer will be a 3D tensor of shape (samples, sequence_length, embedding_dim)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate class weights for unbalanced datasets.\n",
    "paramter to model.fit = __class_weight__: Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
    "\n",
    "Implement class_weight from sklearn:\n",
    "\n",
    "- Import the module \n",
    "\n",
    "`from sklearn.utils import class_weight`\n",
    "- calculate the class weight, If ‘balanced’, class weights will be given by n_samples / (n_classes * np.bincount(y)):\n",
    "\n",
    "`class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)`\n",
    "\n",
    "- change it to a dict in order to work with Keras.\n",
    "\n",
    "`class_weight_dict = dict(enumerate(class_weight))`\n",
    "\n",
    "- Add to model fitting\n",
    "\n",
    "`model.fit(X_train, y_train, class_weight=class_weight)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "# class_weight_dict = dict(enumerate(class_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.00756\n",
      "8.01512\n"
     ]
    }
   ],
   "source": [
    "class WeightedBinaryCrossEntropy(object):\n",
    "\n",
    "    def __init__(self, pos_ratio):\n",
    "        neg_ratio = 1. - pos_ratio\n",
    "        #self.pos_ratio = tf.constant(pos_ratio, tf.float32)\n",
    "        self.pos_ratio = pos_ratio\n",
    "        #self.weights = tf.constant(neg_ratio / pos_ratio, tf.float32)\n",
    "        self.weights = neg_ratio / pos_ratio\n",
    "        self.__name__ = \"weighted_binary_crossentropy({0})\".format(pos_ratio)\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        return self.weighted_binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "    def weighted_binary_crossentropy(self, y_true, y_pred):\n",
    "            # Transform to logits\n",
    "            epsilon = tf.convert_to_tensor(K.common._EPSILON, y_pred.dtype.base_dtype)\n",
    "            y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
    "            y_pred = tf.log(y_pred / (1 - y_pred))\n",
    "\n",
    "            cost = tf.nn.weighted_cross_entropy_with_logits(y_true, y_pred, self.weights)\n",
    "            return K.mean(cost * self.pos_ratio, axis=-1)\n",
    "    \n",
    "y_true_arr = np.array([0,1,0,1], dtype=\"float32\")\n",
    "y_pred_arr = np.array([0,0,1,1], dtype=\"float32\")\n",
    "y_true = tf.constant(y_true_arr)\n",
    "y_pred = tf.constant(y_pred_arr)\n",
    "\n",
    "with tf.Session().as_default(): \n",
    "    print(WeightedBinaryCrossEntropy(0.5)(y_true, y_pred).eval())\n",
    "    print(binary_crossentropy(y_true, y_pred).eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### difficulty getting global precision/recall metrics . CAUTION interpreting monitoring metrics\n",
    "fcholltet: \"Basically these are all global metrics that were approximated\n",
    "batch-wise, which is more misleading than helpful. This was mentioned in\n",
    "the docs but it's much cleaner to remove them altogether. It was a mistake\n",
    "to merge them in the first place.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    \"\"\"Use Recall  and precision metrics to calculate harmonic mean (F1 score).\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1 = 2*((precision*recall)/(precision+recall))\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a 1D convnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NB_CLASSES = y_train.shape[1]\n",
    "NB_METAVARS = meta_train.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='wordindex') #MAX_SEQUENCE_LENGTH\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Dropout(0.2, name = 'dropout_embedded')(embedded_sequences)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv0')(x)\n",
    "\n",
    "x = MaxPooling1D(5, name = 'max_pool0')(x)\n",
    "\n",
    "x = Dropout(0.5, name = 'dropout0')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv1')(x)\n",
    "\n",
    "x = MaxPooling1D(5 , name = 'max_pool1')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv2')(x)\n",
    "\n",
    "x = MaxPooling1D(35, name = 'global_max_pool')(x)  # global max pooling\n",
    "\n",
    "x = Flatten()(x) #reduce dimensions from 3 to 2; convert to vector + FULLYCONNECTED\n",
    "\n",
    "meta_input = Input(shape=(NB_METAVARS,), name='meta')\n",
    "meta_hidden = Dense(128, activation='relu', name = 'hidden_meta')(meta_input)\n",
    "meta_hidden = Dropout(0.2, name = 'dropout_meta')(meta_hidden)\n",
    "\n",
    "\n",
    "title_input = Input(shape=(title_train.shape[1],), name='titles')\n",
    "title_hidden = Dense(128, activation='relu', name = 'hidden_title')(title_input)\n",
    "title_hidden = Dropout(0.2, name = 'dropout_title')(title_hidden)\n",
    "\n",
    "desc_input = Input(shape=(desc_train.shape[1],), name='descs')\n",
    "desc_hidden = Dense(128, activation='relu', name = 'hidden_desc')(desc_input)\n",
    "desc_hidden = Dropout(0.2, name = 'dropout_desc')(desc_hidden)\n",
    "\n",
    "concatenated = concatenate([meta_hidden, title_hidden, desc_hidden, x])\n",
    "\n",
    "x = Dense(400, activation='relu', name = 'fully_connected0')(concatenated)\n",
    "\n",
    "x = Dropout(0.2, name = 'dropout1')(x)\n",
    "\n",
    "x = Dense(NB_CLASSES, activation='sigmoid', name = 'fully_connected1')(x)\n",
    "\n",
    "# # The Model class turns an input tensor and output tensor into a model\n",
    "# This creates Keras model instance, will use this instance to train/test the model.\n",
    "model = Model(inputs=[meta_input, title_input, desc_input, sequence_input], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "wordindex (InputLayer)          (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 100)    31285300    wordindex[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_embedded (Dropout)      (None, 1000, 100)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv1D)                  (None, 996, 128)     64128       dropout_embedded[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pool0 (MaxPooling1D)        (None, 199, 128)     0           conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout0 (Dropout)              (None, 199, 128)     0           max_pool0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv1D)                  (None, 195, 128)     82048       dropout0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pool1 (MaxPooling1D)        (None, 39, 128)      0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "meta (InputLayer)               (None, 452)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "titles (InputLayer)             (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "descs (InputLayer)              (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv1D)                  (None, 35, 128)      82048       max_pool1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hidden_meta (Dense)             (None, 128)          57984       meta[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "hidden_title (Dense)            (None, 128)          1280128     titles[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "hidden_desc (Dense)             (None, 128)          1280128     descs[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pool (MaxPooling1D)  (None, 1, 128)       0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_meta (Dropout)          (None, 128)          0           hidden_meta[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_title (Dropout)         (None, 128)          0           hidden_title[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_desc (Dropout)          (None, 128)          0           hidden_desc[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           global_max_pool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           dropout_meta[0][0]               \n",
      "                                                                 dropout_title[0][0]              \n",
      "                                                                 dropout_desc[0][0]               \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fully_connected0 (Dense)        (None, 400)          205200      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 400)          0           fully_connected0[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fully_connected1 (Dense)        (None, 218)          87418       dropout1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 34,424,382\n",
      "Trainable params: 34,424,382\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard callbacks /metrics /monitor training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **Size of these files is killing storage during training. Is it histograms?**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tb = TensorBoard(log_dir='./learn_embedding_logs', histogram_freq=1, write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = os.path.join(DATADIR, 'model_checkpoint.hdf5')\n",
    "\n",
    "cp = ModelCheckpoint(\n",
    "                     filepath = CHECKPOINT_PATH, \n",
    "                     monitor='val_loss', \n",
    "                     verbose=0, \n",
    "                     save_best_only=False, \n",
    "                     save_weights_only=False, \n",
    "                     mode='auto', \n",
    "                     period=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "#model.fit(x, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 & 3. Train & compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 161020 samples, validate on 10377 samples\n",
      "Epoch 1/10\n",
      "161020/161020 [==============================] - 118s 731us/step - loss: 0.0095 - binary_accuracy: 0.9946 - f1: nan - val_loss: 0.0048 - val_binary_accuracy: 0.9968 - val_f1: 0.7419\n",
      "Epoch 2/10\n",
      "161020/161020 [==============================] - 109s 677us/step - loss: 0.0033 - binary_accuracy: 0.9978 - f1: 0.8619 - val_loss: 0.0042 - val_binary_accuracy: 0.9972 - val_f1: 0.7777\n",
      "Epoch 3/10\n",
      "161020/161020 [==============================] - 109s 678us/step - loss: 0.0025 - binary_accuracy: 0.9984 - f1: 0.8988 - val_loss: 0.0040 - val_binary_accuracy: 0.9973 - val_f1: 0.7958\n",
      "Epoch 4/10\n",
      "161020/161020 [==============================] - 109s 678us/step - loss: 0.0020 - binary_accuracy: 0.9986 - f1: 0.9172 - val_loss: 0.0040 - val_binary_accuracy: 0.9974 - val_f1: 0.8037\n",
      "Epoch 5/10\n",
      "161020/161020 [==============================] - 109s 677us/step - loss: 0.0018 - binary_accuracy: 0.9988 - f1: 0.9277 - val_loss: 0.0041 - val_binary_accuracy: 0.9974 - val_f1: 0.8063\n",
      "Epoch 6/10\n",
      "161020/161020 [==============================] - 109s 677us/step - loss: 0.0016 - binary_accuracy: 0.9989 - f1: 0.9352 - val_loss: 0.0042 - val_binary_accuracy: 0.9974 - val_f1: 0.8073\n"
     ]
    }
   ],
   "source": [
    "# metrics callback causes: CCCCCCR55555555511155\n",
    "# So disable for now\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "# Replicates `model` on 8 GPUs.\n",
    "# This assumes that your machine has 8 available GPUs.\n",
    "parallel_model = multi_gpu_model(model, gpus=8)\n",
    "parallel_model.compile(loss=WeightedBinaryCrossEntropy(POS_RATIO),\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['binary_accuracy', f1])\n",
    "\n",
    "# This `fit` call will be distributed on 8 GPUs.\n",
    "# Since the batch size is 256, each GPU will process 32 samples.\n",
    "history = parallel_model.fit(\n",
    "    {'meta': meta_train, 'titles': title_train, 'descs': desc_train, 'wordindex': x_train},\n",
    "    y_train, \n",
    "    validation_data=([meta_dev, title_dev, desc_dev, x_dev], y_dev), \n",
    "    epochs=10, batch_size=128, callbacks=[early_stopping]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_binary_accuracy', 'val_f1', 'loss', 'binary_accuracy', 'f1'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3427eedb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, 7)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')           \n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')      \n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJxIzM8uJE4mZmeXEicTMzHLy/wFENClbed8BAwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3427ab7a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()    \n",
    "\n",
    "f1_values = history_dict['f1']\n",
    "val_f1_values = history_dict['val_f1']\n",
    "\n",
    "plt.plot(epochs, f1_values, 'bo', label='Training f1')\n",
    "plt.plot(epochs, val_f1_values, 'b', label='Validation f1')\n",
    "plt.title('Training and validation batch-level f1-micro')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1-micro')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_file(array,name):\n",
    "    df = pd.DataFrame(data = array.tolist(),columns=[i for i in range(1,y_train.shape[1]+1)])\n",
    "    df.to_csv(os.path.join(DATADIR, name+'.csv.gz'),compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_1437_0603_'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_run = time.strftime(\"_%H%M_%d%m_\")\n",
    "date_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = parallel_model.predict([meta_train, title_train, desc_train, x_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_prob,\"train_results\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_prob.copy()\n",
    "y_pred[y_pred>=P_THRESHOLD] = 1\n",
    "y_pred[y_pred<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro: (0.9654091497714955, 0.95664882150652986, 0.96100902178972814, None)\n",
      "macro: (0.97794899438677263, 0.97655571199172997, 0.9770144091440488, None)\n",
      "weightedmacro: (0.96546126738713356, 0.95664882150652986, 0.9607047407217586, None)\n"
     ]
    }
   ],
   "source": [
    "print('micro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='micro', sample_weight=None)))\n",
    "print('macro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='macro', sample_weight=None)))\n",
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='weighted', sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_dev = parallel_model.predict([meta_dev, title_dev, desc_dev, x_dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_prob_dev,\"dev_results\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dev = y_prob_dev.copy()\n",
    "y_pred_dev[y_pred_dev>=P_THRESHOLD] = 1\n",
    "y_pred_dev[y_pred_dev<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro: (0.82602804688029263, 0.78970207253886016, 0.80745670673156522, None)\n",
      "macro: (0.74092624556624642, 0.80591858180296294, 0.7621251601675737, None)\n",
      "weightedmacro: (0.82978428242106561, 0.78970207253886016, 0.80593867704081656, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('micro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='micro', sample_weight=None)))\n",
    "print('macro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='macro', sample_weight=None)))\n",
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='weighted', sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weightedmacro: (array([ 0.        ,  0.66666667,  0.90909091,  0.63636364,  1.        ,\n",
      "        0.69565217,  0.66666667,  0.80124224,  1.        ,  0.90909091,\n",
      "        1.        ,  0.87272727,  0.        ,  1.        ,  0.67391304,\n",
      "        0.        ,  0.74418605,  1.        ,  0.        ,  0.75151515,\n",
      "        0.86748466,  0.74634146,  0.87765957,  0.        ,  1.        ,\n",
      "        0.        ,  0.75      ,  1.        ,  1.        ,  0.83333333,\n",
      "        0.57142857,  0.92307692,  1.        ,  0.        ,  0.70731707,\n",
      "        0.81663113,  0.83333333,  0.61764706,  0.74747475,  0.75      ,\n",
      "        0.76923077,  0.        ,  0.75      ,  0.81025641,  0.66666667,\n",
      "        1.        ,  0.75675676,  1.        ,  0.        ,  0.875     ,\n",
      "        0.71515152,  1.        ,  1.        ,  0.4       ,  1.        ,\n",
      "        0.5       ,  1.        ,  0.        ,  0.93309859,  0.61538462,\n",
      "        0.75816993,  0.85714286,  0.875     ,  0.69230769,  0.6031746 ,\n",
      "        0.5       ,  0.75126904,  0.75700935,  1.        ,  1.        ,\n",
      "        0.6       ,  1.        ,  1.        ,  1.        ,  0.63461538,\n",
      "        0.72222222,  0.925     ,  0.83534137,  1.        ,  0.87250996,\n",
      "        1.        ,  0.875     ,  0.75      ,  0.88888889,  0.83388704,\n",
      "        1.        ,  0.        ,  0.78169014,  0.        ,  0.8       ,\n",
      "        0.875     ,  0.85714286,  1.        ,  0.8611898 ,  0.8189415 ,\n",
      "        0.81944444,  0.66666667,  1.        ,  0.83333333,  0.93333333,\n",
      "        0.63636364,  0.82857143,  0.92857143,  0.52083333,  0.        ,\n",
      "        0.8       ,  0.66666667,  0.79487179,  0.        ,  0.33333333,\n",
      "        0.83333333,  1.        ,  0.625     ,  0.93333333,  1.        ,\n",
      "        1.        ,  1.        ,  0.        ,  0.33333333,  0.73366834,\n",
      "        0.80487805,  0.72727273,  0.58333333,  0.75      ,  0.95945946,\n",
      "        0.98275862,  1.        ,  0.6953125 ,  0.66666667,  0.95049505,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.84597156,  0.5       ,  0.8372093 ,  0.85436893,  1.        ,\n",
      "        0.77777778,  1.        ,  1.        ,  1.        ,  0.90909091,\n",
      "        1.        ,  0.72380952,  0.8372093 ,  0.38461538,  0.85714286,\n",
      "        1.        ,  0.        ,  0.91568627,  0.        ,  1.        ,\n",
      "        0.        ,  0.73529412,  0.94230769,  0.74      ,  0.92857143,\n",
      "        0.5       ,  1.        ,  0.82743363,  0.87      ,  0.86754967,\n",
      "        0.83333333,  0.63157895,  0.82692308,  0.9017341 ,  0.86419753,\n",
      "        0.875     ,  1.        ,  1.        ,  0.55555556,  1.        ,\n",
      "        0.71653543,  0.73076923,  0.78095238,  1.        ,  0.5       ,\n",
      "        0.        ,  0.71428571,  1.        ,  0.6875    ,  0.85714286,\n",
      "        0.95      ,  0.93137255,  0.85714286,  0.70833333,  0.81238938,\n",
      "        0.94736842,  0.        ,  0.83673469,  1.        ,  0.53846154,\n",
      "        1.        ,  1.        ,  0.71809745,  0.5       ,  0.67346939,\n",
      "        1.        ,  1.        ,  0.83333333,  0.96363636,  0.        ,\n",
      "        0.        ,  0.92655367,  0.90909091,  0.80769231,  0.45454545,\n",
      "        0.80327869,  0.85393258,  0.        ,  1.        ,  1.        ,\n",
      "        0.        ,  1.        ,  0.94021739]), array([ 0.        ,  1.        ,  0.95652174,  1.        ,  1.        ,\n",
      "        0.5       ,  1.        ,  0.69354839,  1.        ,  0.83333333,\n",
      "        1.        ,  0.94117647,  0.        ,  1.        ,  0.86111111,\n",
      "        0.        ,  0.96969697,  1.        ,  0.        ,  0.86713287,\n",
      "        0.70629371,  0.75      ,  0.86387435,  0.        ,  1.        ,\n",
      "        0.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.85294118,\n",
      "        0.79460581,  1.        ,  0.875     ,  0.62535211,  1.        ,\n",
      "        0.43956044,  0.        ,  0.65      ,  0.89772727,  1.        ,\n",
      "        1.        ,  0.77777778,  1.        ,  0.        ,  0.90322581,\n",
      "        0.88721805,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.        ,  0.86601307,  1.        ,\n",
      "        0.64444444,  1.        ,  1.        ,  1.        ,  0.92682927,\n",
      "        1.        ,  0.58964143,  0.63779528,  1.        ,  0.92631579,\n",
      "        0.83333333,  1.        ,  1.        ,  1.        ,  0.52380952,\n",
      "        0.92857143,  0.83146067,  0.76190476,  1.        ,  0.83269962,\n",
      "        1.        ,  0.63636364,  1.        ,  0.82285714,  0.84606742,\n",
      "        1.        ,  0.        ,  0.62011173,  0.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.83977901,  0.80769231,\n",
      "        0.69411765,  1.        ,  1.        ,  1.        ,  0.93333333,\n",
      "        0.75      ,  0.725     ,  0.83055556,  0.89285714,  0.        ,\n",
      "        0.88888889,  1.        ,  0.93939394,  0.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.        ,  1.        ,  0.70531401,\n",
      "        0.89189189,  0.86956522,  0.77777778,  1.        ,  0.87654321,\n",
      "        0.912     ,  1.        ,  0.66917293,  1.        ,  0.96      ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.80044843,  1.        ,  0.8503937 ,  0.89795918,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  0.8       ,\n",
      "        0.9375    ,  0.76      ,  0.75      ,  1.        ,  1.        ,\n",
      "        1.        ,  0.        ,  0.86162362,  0.        ,  1.        ,\n",
      "        0.        ,  0.86206897,  0.92890995,  0.48051948,  1.        ,\n",
      "        1.        ,  1.        ,  0.91219512,  0.87      ,  0.68586387,\n",
      "        0.95744681,  0.92307692,  0.70491803,  0.87150838,  0.72413793,\n",
      "        0.72916667,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.61073826,  0.95      ,  0.67768595,  1.        ,  1.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.91666667,  1.        ,\n",
      "        0.95      ,  0.84821429,  1.        ,  0.89473684,  0.78327645,\n",
      "        1.        ,  0.        ,  0.7008547 ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.6655914 ,  1.        ,  0.78571429,\n",
      "        1.        ,  1.        ,  0.9375    ,  0.98148148,  0.        ,\n",
      "        0.        ,  0.91620112,  0.70921986,  0.84      ,  0.83333333,\n",
      "        0.79032258,  0.79166667,  0.        ,  1.        ,  1.        ,\n",
      "        0.        ,  1.        ,  0.96111111]), array([ 0.        ,  0.8       ,  0.93220339,  0.77777778,  1.        ,\n",
      "        0.58181818,  0.8       ,  0.74351585,  1.        ,  0.86956522,\n",
      "        1.        ,  0.90566038,  0.        ,  1.        ,  0.75609756,\n",
      "        0.        ,  0.84210526,  1.        ,  0.        ,  0.80519481,\n",
      "        0.77863436,  0.74816626,  0.8707124 ,  0.        ,  1.        ,\n",
      "        0.        ,  0.85714286,  1.        ,  1.        ,  0.90909091,\n",
      "        0.72727273,  0.96      ,  1.        ,  0.        ,  0.77333333,\n",
      "        0.80546793,  0.90909091,  0.72413793,  0.6809816 ,  0.85714286,\n",
      "        0.55944056,  0.        ,  0.69642857,  0.85175202,  0.8       ,\n",
      "        1.        ,  0.76712329,  1.        ,  0.        ,  0.88888889,\n",
      "        0.79194631,  1.        ,  1.        ,  0.57142857,  1.        ,\n",
      "        0.66666667,  1.        ,  0.        ,  0.89830508,  0.76190476,\n",
      "        0.6966967 ,  0.92307692,  0.93333333,  0.81818182,  0.73076923,\n",
      "        0.66666667,  0.66071429,  0.69230769,  1.        ,  0.96174863,\n",
      "        0.69767442,  1.        ,  1.        ,  1.        ,  0.57391304,\n",
      "        0.8125    ,  0.87573964,  0.79693487,  1.        ,  0.85214008,\n",
      "        1.        ,  0.73684211,  0.85714286,  0.85459941,  0.83993307,\n",
      "        1.        ,  0.        ,  0.69158879,  0.        ,  0.88888889,\n",
      "        0.93333333,  0.92307692,  1.        ,  0.85034965,  0.81327801,\n",
      "        0.75159236,  0.8       ,  1.        ,  0.90909091,  0.93333333,\n",
      "        0.68852459,  0.77333333,  0.87683284,  0.65789474,  0.        ,\n",
      "        0.84210526,  0.8       ,  0.86111111,  0.        ,  0.5       ,\n",
      "        0.90909091,  1.        ,  0.76923077,  0.96551724,  1.        ,\n",
      "        1.        ,  1.        ,  0.        ,  0.5       ,  0.71921182,\n",
      "        0.84615385,  0.79207921,  0.66666667,  0.85714286,  0.91612903,\n",
      "        0.94605809,  1.        ,  0.68199234,  0.8       ,  0.95522388,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.82258065,  0.66666667,  0.84375   ,  0.87562189,  1.        ,\n",
      "        0.875     ,  1.        ,  1.        ,  1.        ,  0.85106383,\n",
      "        0.96774194,  0.74146341,  0.79120879,  0.55555556,  0.92307692,\n",
      "        1.        ,  0.        ,  0.8878327 ,  0.        ,  1.        ,\n",
      "        0.        ,  0.79365079,  0.93556086,  0.58267717,  0.96296296,\n",
      "        0.66666667,  1.        ,  0.86774942,  0.87      ,  0.76608187,\n",
      "        0.89108911,  0.75      ,  0.76106195,  0.88636364,  0.7879925 ,\n",
      "        0.79545455,  1.        ,  1.        ,  0.71428571,  1.        ,\n",
      "        0.65942029,  0.82608696,  0.72566372,  1.        ,  0.66666667,\n",
      "        0.        ,  0.83333333,  1.        ,  0.78571429,  0.92307692,\n",
      "        0.95      ,  0.88785047,  0.92307692,  0.79069767,  0.79756733,\n",
      "        0.97297297,  0.        ,  0.7627907 ,  1.        ,  0.7       ,\n",
      "        1.        ,  1.        ,  0.69084821,  0.66666667,  0.72527473,\n",
      "        1.        ,  1.        ,  0.88235294,  0.97247706,  0.        ,\n",
      "        0.        ,  0.92134831,  0.79681275,  0.82352941,  0.58823529,\n",
      "        0.79674797,  0.82162162,  0.        ,  1.        ,  1.        ,\n",
      "        0.        ,  1.        ,  0.95054945]), array([   0,    8,  115,   14,   48,   64,   10,  186,    1,   12,    3,\n",
      "         51,    0,    1,   36,    0,   33,    1,    0,  143, 1001,  204,\n",
      "        191,    0,    3,    0,    3,    1,    3,   15,    4,   12,    5,\n",
      "          0,   34,  482,    5,   24,  355,   18,   91,    0,   60,  176,\n",
      "          2,    2,   36,    5,    0,   31,  133,    2,    4,    6,    2,\n",
      "          1,    1,    0,  306,    8,  180,    6,    7,    9,   41,    1,\n",
      "        251,  127,    3,   95,   18,    1,    5,    7,   63,   28,   89,\n",
      "        273,    1,  263,    1,   11,    9,  175,  890,    2,    0,  179,\n",
      "          0,    4,    7,   12,    1,  362,  364,   85,    2,    1,    5,\n",
      "         15,   28,  120,  360,   28,    0,   18,    6,   33,    0,    2,\n",
      "         10,    1,    5,   14,    4,    1,    3,    0,    2,  207,   37,\n",
      "         46,   18,   12,   81,  125,    5,  133,    2,  100,    1,    2,\n",
      "          2,    1,    6,  446,    7,  508,   98,    1,    7,    2,    2,\n",
      "          1,   75,   16,  100,   48,    5,    6,    2,    0,  542,    0,\n",
      "          2,    0,   29,  211,   77,   13,    1,    5,  205,  100,  191,\n",
      "         47,   13,   61,  179,  290,   96,    2,    1,    5,    1,  149,\n",
      "         20,  121,    7,    1,    0,    5,   10,   12,    6,   20,  112,\n",
      "          6,   19,  586,   18,    0,  117,    8,    7,    2,    2,  930,\n",
      "          2,   42,    1,   11,   16,   54,    0,    0,  179,  141,   25,\n",
      "          6,   62,  192,    0,   13,    1,    0,    4,  180]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average=None, sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_train,\"true_train\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_dev,\"true_dev\"+date_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arrays = os.path.join(DATADIR, new_arraynpz_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(new_arrays):\n",
    "    arrays = np.load(new_arrays)\n",
    "    \n",
    "    x_new = sparse.csr_matrix(arrays['x'].all()).todense()\n",
    "    meta_new = sparse.csr_matrix(arrays['meta'].all()).todense()\n",
    "    title_new = sparse.csr_matrix(arrays['title'].all()).todense()\n",
    "    desc_new = sparse.csr_matrix(arrays['desc'].all()).todense()\n",
    "   \n",
    "    y_pred_new = model.predict([meta_new, title_new, desc_new, x_new])\n",
    "    \n",
    "    to_file(y_pred_new, \"new_predictions\"+date_run)\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "keep_output": true,
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
