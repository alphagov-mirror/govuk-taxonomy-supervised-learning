{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional NN to classify govuk content to level2 taxons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on:\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load requirements and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.utils import to_categorical, layer_utils, plot_model\n",
    "\n",
    "from keras.layers import (Embedding, Input, Dense, Dropout, \n",
    "                          Activation, Conv1D, MaxPooling1D, Flatten, concatenate, Reshape)\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.callbacks import TensorBoard, Callback, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score \n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import functools\n",
    "\n",
    "import h5py\n",
    "\n",
    "from scipy import sparse\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environmental vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATADIR = os.getenv('DATADIR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print data version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm running on data extracted from content store on /data/2018-07-10\n"
     ]
    }
   ],
   "source": [
    "print('algorithm running on data extracted from content store on {}'.format(DATADIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuition for POS_RATIO is that it penalises the prediction of zero for everything, which is attractive to the model because the multilabel y matrix is super sparse. \n",
    "\n",
    "Increasing POS_RATIO should penalise predicting zeros more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MAX_NB_WORDS\n",
    "MAX_SEQUENCE_LENGTH =1000\n",
    "EMBEDDING_DIM = 100 # keras embedding layer output_dim = Dimension of the dense embedding\n",
    "P_THRESHOLD = 0.5 #Threshold for probability of being assigned to class\n",
    "POS_RATIO = 0.5 #ratio of positive to negative for each class in weighted binary cross entropy loss function\n",
    "NUM_WORDS=20000 #keras tokenizer num_words: None or int. Maximum number of words to work with \n",
    "#(if set, tokenization will be restricted to the top num_words most common words in the dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = np.load(os.path.join(DATADIR, 'train_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'meta', 'title', 'desc', 'y', 'content_id']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (212885, 1000)\n",
      "meta_train.shape = (212885, 525)\n",
      "title_train.shape = (212885, 10000)\n",
      "desc_train.shape = (212885, 10000)\n",
      "y_train.shape = (212885, 214)\n"
     ]
    }
   ],
   "source": [
    "x_train = train['x']\n",
    "meta_train = train['meta'].all().todense()\n",
    "title_train = train['title'].all().todense()\n",
    "desc_train = train['desc'].all().todense()\n",
    "y_train = train['y'].all().todense()\n",
    "\n",
    "print('x_train.shape = {}'.format(x_train.shape))\n",
    "print('meta_train.shape = {}'.format(meta_train.shape))\n",
    "print('title_train.shape = {}'.format(title_train.shape))\n",
    "print('desc_train.shape = {}'.format(desc_train.shape))\n",
    "print('y_train.shape = {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dev = np.load(os.path.join(DATADIR, 'dev_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_dev.shape = (18048, 1000)\n",
      "meta_dev.shape = (18048, 525)\n",
      "title_dev.shape = (18048, 10000)\n",
      "desc_dev.shape = (18048, 10000)\n",
      "y_dev.shape = (18048, 214)\n"
     ]
    }
   ],
   "source": [
    "x_dev = dev['x']\n",
    "meta_dev = dev['meta'].all().todense()\n",
    "title_dev = dev['title'].all().todense()\n",
    "desc_dev = dev['desc'].all().todense()\n",
    "y_dev = dev['y'].all().todense()\n",
    "\n",
    "print('x_dev.shape = {}'.format(x_dev.shape))\n",
    "print('meta_dev.shape = {}'.format(meta_dev.shape))\n",
    "print('title_dev.shape = {}'.format(title_dev.shape))\n",
    "print('desc_dev.shape = {}'.format(desc_dev.shape))\n",
    "print('y_dev.shape = {}'.format(y_dev.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = np.load(os.path.join(DATADIR, 'test_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test.shape = (18049, 1000)\n",
      "meta_test.shape = (18049, 525)\n",
      "title_test.shape = (18049, 10000)\n",
      "desc_test.shape = (18049, 10000)\n",
      "y_test.shape = (18049, 214)\n"
     ]
    }
   ],
   "source": [
    "x_test = test['x']\n",
    "meta_test = test['meta'].all().todense()\n",
    "title_test = test['title'].all().todense()\n",
    "desc_test = test['desc'].all().todense()\n",
    "y_test = test['y'].all().todense()\n",
    "\n",
    "print('x_test.shape = {}'.format(x_test.shape))\n",
    "print('meta_test.shape = {}'.format(meta_test.shape))\n",
    "print('title_test.shape = {}'.format(title_test.shape))\n",
    "print('desc_test.shape = {}'.format(desc_test.shape))\n",
    "print('y_test.shape = {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### previous shapes in old data \n",
    "Shape of x_train: (150870, 1000)\n",
    "Shape of metax_train: (150870, 436)\n",
    "Shape of titlex_train: (150870, 10000)\n",
    "Shape of descx_train: (150870, 10000)\n",
    "Shape of y_train: (150870, 210)\n",
    "\n",
    "Shape of x_dev: (9234, 1000)\n",
    "Shape of meta_dev: (9234, 436)\n",
    "Shape of titlex_dev: (9234, 10000)\n",
    "Shape of descx_dev: (9234, 10000)\n",
    "Shape of y_dev: (9234, 210)\n",
    "\n",
    "Shape of x_test: (9234, 1000)\n",
    "Shape of metax_test: (9234, 436)\n",
    "Shape of titlex_test: (9234, 10000)\n",
    "Shape of descx_test: (9234, 10000)\n",
    "Shape of y_test: (9234, 210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing the Embedding layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "def load_tokenizer_from_file(filename):\n",
    "    \n",
    "    tokenizer = Tokenizer()\n",
    "\n",
    "    with open(filename, 'r') as infile:\n",
    "        tokenizer_data = json.load(infile)\n",
    "\n",
    "    tokenizer.word_counts = OrderedDict(tokenizer_data['word_counts'])\n",
    "    tokenizer.word_docs = tokenizer_data['word_docs']\n",
    "    tokenizer.word_index = tokenizer_data['word_index']\n",
    "    tokenizer.document_count = tokenizer_data['document_count']\n",
    "    tokenizer.index_docs = tokenizer_data['index_docs']\n",
    "\n",
    "    return tokenizer\n",
    "\n",
    "tokenizer_combined_text = load_tokenizer_from_file(os.path.join(DATADIR, \"combined_text_tokenizer.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(tokenizer_combined_text.word_index) + 1, \n",
    "                            EMBEDDING_DIM, \n",
    "                            input_length=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Embedding layer should be fed sequences of integers, i.e. a 2D input of shape (samples, indices). These input sequences should be padded so that they all have the same length in a batch of input data (although an Embedding layer is capable of processing sequence of heterogenous length, if you don't pass an explicit input_length argument to the layer).\n",
    "\n",
    "All that the Embedding layer does is to map the integer inputs to the vectors found at the corresponding index in the embedding matrix, i.e. the sequence [1, 2] would be converted to [embeddings[1], embeddings[2]]. This means that the output of the Embedding layer will be a 3D tensor of shape (samples, sequence_length, embedding_dim)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate class weights for unbalanced datasets.\n",
    "paramter to model.fit = __class_weight__: Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
    "\n",
    "Implement class_weight from sklearn:\n",
    "\n",
    "- Import the module \n",
    "\n",
    "`from sklearn.utils import class_weight`\n",
    "- calculate the class weight, If ‘balanced’, class weights will be given by n_samples / (n_classes * np.bincount(y)):\n",
    "\n",
    "`class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)`\n",
    "\n",
    "- change it to a dict in order to work with Keras.\n",
    "\n",
    "`class_weight_dict = dict(enumerate(class_weight))`\n",
    "\n",
    "- Add to model fitting\n",
    "\n",
    "`model.fit(X_train, y_train, class_weight=class_weight)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "# class_weight_dict = dict(enumerate(class_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.00756\n",
      "8.01512\n"
     ]
    }
   ],
   "source": [
    "class WeightedBinaryCrossEntropy(object):\n",
    "\n",
    "    def __init__(self, pos_ratio):\n",
    "        neg_ratio = 1. - pos_ratio\n",
    "        #self.pos_ratio = tf.constant(pos_ratio, tf.float32)\n",
    "        self.pos_ratio = pos_ratio\n",
    "        #self.weights = tf.constant(neg_ratio / pos_ratio, tf.float32)\n",
    "        self.weights = neg_ratio / pos_ratio\n",
    "        self.__name__ = \"weighted_binary_crossentropy({0})\".format(pos_ratio)\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        return self.weighted_binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "    def weighted_binary_crossentropy(self, y_true, y_pred):\n",
    "            # Transform to logits\n",
    "            epsilon = tf.convert_to_tensor(K.common._EPSILON, y_pred.dtype.base_dtype)\n",
    "            y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
    "            y_pred = tf.log(y_pred / (1 - y_pred))\n",
    "\n",
    "            cost = tf.nn.weighted_cross_entropy_with_logits(y_true, y_pred, self.weights)\n",
    "            return K.mean(cost * self.pos_ratio, axis=-1)\n",
    "    \n",
    "y_true_arr = np.array([0,1,0,1], dtype=\"float32\")\n",
    "y_pred_arr = np.array([0,0,1,1], dtype=\"float32\")\n",
    "y_true = tf.constant(y_true_arr)\n",
    "y_pred = tf.constant(y_pred_arr)\n",
    "\n",
    "with tf.Session().as_default(): \n",
    "    print(WeightedBinaryCrossEntropy(0.5)(y_true, y_pred).eval())\n",
    "    print(binary_crossentropy(y_true, y_pred).eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### difficulty getting global precision/recall metrics . CAUTION interpreting monitoring metrics\n",
    "fcholltet: \"Basically these are all global metrics that were approximated\n",
    "batch-wise, which is more misleading than helpful. This was mentioned in\n",
    "the docs but it's much cleaner to remove them altogether. It was a mistake\n",
    "to merge them in the first place.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    \"\"\"Use Recall  and precision metrics to calculate harmonic mean (F1 score).\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1 = 2*((precision*recall)/(precision+recall))\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a 1D convnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NB_CLASSES = y_train.shape[1]\n",
    "NB_METAVARS = meta_train.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='wordindex') #MAX_SEQUENCE_LENGTH\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Dropout(0.2, name = 'dropout_embedded')(embedded_sequences)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv0')(x)\n",
    "\n",
    "x = MaxPooling1D(5, name = 'max_pool0')(x)\n",
    "\n",
    "x = Dropout(0.5, name = 'dropout0')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv1')(x)\n",
    "\n",
    "x = MaxPooling1D(5 , name = 'max_pool1')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv2')(x)\n",
    "\n",
    "x = MaxPooling1D(35, name = 'global_max_pool')(x)  # global max pooling\n",
    "\n",
    "x = Flatten()(x) #reduce dimensions from 3 to 2; convert to vector + FULLYCONNECTED\n",
    "\n",
    "meta_input = Input(shape=(NB_METAVARS,), name='meta')\n",
    "meta_hidden = Dense(128, activation='relu', name = 'hidden_meta')(meta_input)\n",
    "meta_hidden = Dropout(0.2, name = 'dropout_meta')(meta_hidden)\n",
    "\n",
    "\n",
    "title_input = Input(shape=(title_train.shape[1],), name='titles')\n",
    "title_hidden = Dense(128, activation='relu', name = 'hidden_title')(title_input)\n",
    "title_hidden = Dropout(0.2, name = 'dropout_title')(title_hidden)\n",
    "\n",
    "desc_input = Input(shape=(desc_train.shape[1],), name='descs')\n",
    "desc_hidden = Dense(128, activation='relu', name = 'hidden_desc')(desc_input)\n",
    "desc_hidden = Dropout(0.2, name = 'dropout_desc')(desc_hidden)\n",
    "\n",
    "concatenated = concatenate([meta_hidden, title_hidden, desc_hidden, x])\n",
    "\n",
    "x = Dense(400, activation='relu', name = 'fully_connected0')(concatenated)\n",
    "\n",
    "x = Dropout(0.2, name = 'dropout1')(x)\n",
    "\n",
    "x = Dense(NB_CLASSES, activation='sigmoid', name = 'fully_connected1')(x)\n",
    "\n",
    "# # The Model class turns an input tensor and output tensor into a model\n",
    "# This creates Keras model instance, will use this instance to train/test the model.\n",
    "model = Model(inputs=[meta_input, title_input, desc_input, sequence_input], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "wordindex (InputLayer)          (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 100)    2000200     wordindex[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_embedded (Dropout)      (None, 1000, 100)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv1D)                  (None, 996, 128)     64128       dropout_embedded[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pool0 (MaxPooling1D)        (None, 199, 128)     0           conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout0 (Dropout)              (None, 199, 128)     0           max_pool0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv1D)                  (None, 195, 128)     82048       dropout0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pool1 (MaxPooling1D)        (None, 39, 128)      0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "meta (InputLayer)               (None, 525)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "titles (InputLayer)             (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "descs (InputLayer)              (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv1D)                  (None, 35, 128)      82048       max_pool1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hidden_meta (Dense)             (None, 128)          67328       meta[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "hidden_title (Dense)            (None, 128)          1280128     titles[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "hidden_desc (Dense)             (None, 128)          1280128     descs[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pool (MaxPooling1D)  (None, 1, 128)       0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_meta (Dropout)          (None, 128)          0           hidden_meta[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_title (Dropout)         (None, 128)          0           hidden_title[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_desc (Dropout)          (None, 128)          0           hidden_desc[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           global_max_pool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           dropout_meta[0][0]               \n",
      "                                                                 dropout_title[0][0]              \n",
      "                                                                 dropout_desc[0][0]               \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fully_connected0 (Dense)        (None, 400)          205200      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 400)          0           fully_connected0[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fully_connected1 (Dense)        (None, 214)          85814       dropout1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 5,147,022\n",
      "Trainable params: 5,147,022\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard callbacks /metrics /monitor training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **Size of these files is killing storage during training. Is it histograms?**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tb = TensorBoard(log_dir='./learn_embedding_logs', histogram_freq=1, write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = os.path.join(DATADIR, 'model_checkpoint.hdf5')\n",
    "\n",
    "cp = ModelCheckpoint(\n",
    "                     filepath = CHECKPOINT_PATH, \n",
    "                     monitor='val_loss', \n",
    "                     verbose=0, \n",
    "                     save_best_only=False, \n",
    "                     save_weights_only=False, \n",
    "                     mode='auto', \n",
    "                     period=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "#model.fit(x, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 & 3. Train & compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 212885 samples, validate on 18048 samples\n",
      "Epoch 1/10\n",
      "212885/212885 [==============================] - 179s 843us/step - loss: 0.0080 - binary_accuracy: 0.9954 - f1: nan - val_loss: 0.0037 - val_binary_accuracy: 0.9975 - val_f1: 0.7910\n",
      "Epoch 2/10\n",
      "212885/212885 [==============================] - 175s 824us/step - loss: 0.0031 - binary_accuracy: 0.9979 - f1: 0.8515 - val_loss: 0.0033 - val_binary_accuracy: 0.9977 - val_f1: 0.8187\n",
      "Epoch 3/10\n",
      "212885/212885 [==============================] - 175s 824us/step - loss: 0.0025 - binary_accuracy: 0.9983 - f1: 0.8848 - val_loss: 0.0032 - val_binary_accuracy: 0.9978 - val_f1: 0.8258\n",
      "Epoch 4/10\n",
      "212885/212885 [==============================] - 175s 823us/step - loss: 0.0022 - binary_accuracy: 0.9986 - f1: 0.9016 - val_loss: 0.0032 - val_binary_accuracy: 0.9979 - val_f1: 0.8322\n",
      "Epoch 5/10\n",
      "212885/212885 [==============================] - 176s 825us/step - loss: 0.0020 - binary_accuracy: 0.9987 - f1: 0.9120 - val_loss: 0.0033 - val_binary_accuracy: 0.9979 - val_f1: 0.8331\n",
      "Epoch 6/10\n",
      "212885/212885 [==============================] - 175s 824us/step - loss: 0.0018 - binary_accuracy: 0.9988 - f1: 0.9186 - val_loss: 0.0035 - val_binary_accuracy: 0.9979 - val_f1: 0.8354\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=WeightedBinaryCrossEntropy(POS_RATIO),\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['binary_accuracy', f1])\n",
    "\n",
    "# This `fit` call will be distributed on 8 GPUs.\n",
    "# Since the batch size is 256, each GPU will process 32 samples.\n",
    "history = model.fit(\n",
    "    {'meta': meta_train, 'titles': title_train, 'descs': desc_train, 'wordindex': x_train},\n",
    "    y_train, \n",
    "    validation_data=([meta_dev, title_dev, desc_dev, x_dev], y_dev), \n",
    "    epochs=10, batch_size=128, callbacks=[early_stopping]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_binary_accuracy', 'val_f1', 'loss', 'binary_accuracy', 'f1'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xt4FdW9//H3R0CQi6BIvYAarFQJ\nioIp6kGKiLVYqxxbaqFYL9VSfbS29lyK2qunPEetR62W9imtWqso5afHll7pBVq1PQcIiiggx1RR\no4iBAoqomPD9/TGTsIk7yYadySbJ5/U8+8nsNWtm1iSQT2at2bMUEZiZme2uvUrdADMza98cJGZm\nVhQHiZmZFcVBYmZmRXGQmJlZURwkZmZWFAeJlZykLpK2SDqsNeuWkqQjJbX6vfWSTpe0Juf9aklj\nCqm7G8f6saRrd3f7Zvb7bUk/ae39Wul0LXUDrP2RtCXnbU/gHaAuff/5iJi9K/uLiDqgd2vX7Qwi\n4qjW2I+kS4HzI+LUnH1f2hr7to7PQWK7LCIafpGnf/FeGhF/bKq+pK4RUdsWbTOztueuLWt1adfF\nzyQ9IOkN4HxJJ0v6X0mbJK2VdLukbmn9rpJCUln6/r50/W8lvSHpfyQN3tW66fozJf2fpM2S7pD0\nV0kXNdHuQtr4eUlVkjZKuj1n2y6SbpW0QdJzwIRmvj/XSZrTqGympFvS5UslrUrP5+/p1UJT+6qW\ndGq63FPSvWnbVgAnNKr7VUnPpftdIemctPxY4HvAmLTbcH3O9/abOdtflp77Bkk/l3RwId+blkg6\nN23PJkkLJB2Vs+5aSa9Iel3SMznnepKkx9PydZK+U+jxLAMR4Zdfu/0C1gCnNyr7NrANOJvkj5V9\ngA8CJ5JcBR8B/B9wZVq/KxBAWfr+PmA9UAF0A34G3Lcbdd8HvAFMTNd9GXgXuKiJcymkjb8A+gJl\nwD/qzx24ElgBDAL6A48k/73yHucIYAvQK2ffrwEV6fuz0zoCTgPeAoan604H1uTsqxo4NV2+Gfgz\nsB9wOLCyUd3zgIPTn8mn0zYcmK67FPhzo3beB3wzXT4jbePxQA/g+8CCQr43ec7/28BP0uWhaTtO\nS39G1wKr0+VhwAvAQWndwcAR6fISYEq63Ac4sdT/Fzrzy1cklpXHIuKXEbE9It6KiCURsSgiaiPi\nOWAWMLaZ7R+MiMqIeBeYTfILbFfrfgxYFhG/SNfdShI6eRXYxv+MiM0RsYbkl3b9sc4Dbo2I6ojY\nANzQzHGeA54mCTiADwMbI6IyXf/LiHguEguAPwF5B9QbOQ/4dkRsjIgXSK4yco87NyLWpj+T+0n+\nCKgoYL8AU4EfR8SyiHgbmA6MlTQop05T35vmTAbmRcSC9Gd0A0kYnQjUkoTWsLR79Pn0ewfJHwRD\nJPWPiDciYlGB52EZcJBYVl7KfSPpaEm/lvSqpNeB64EDmtn+1ZzlrTQ/wN5U3UNy2xERQfIXfF4F\ntrGgY5H8Jd2c+4Ep6fKn0/f17fiYpEWS/iFpE8nVQHPfq3oHN9cGSRdJejLtQtoEHF3gfiE5v4b9\nRcTrwEZgYE6dXfmZNbXf7SQ/o4ERsRr4F5Kfw2tpV+lBadWLgXJgtaTFkj5a4HlYBhwklpXGt77+\nkOSv8CMjYl/g6yRdN1laS9LVBIAksfMvvsaKaeNa4NCc9y3dnjwXOF3SQJIrk/vTNu4DPAj8J0m3\nUz/g9wW249Wm2iDpCOAHwOVA/3S/z+Tst6VblV8h6S6r318fki60lwto167sdy+Sn9nLABFxX0SM\nJunW6kLyfSEiVkfEZJLuy/8CHpLUo8i22G5ykFhb6QNsBt6UNBT4fBsc81fASElnS+oKfBEYkFEb\n5wJfkjRQUn/gK81VjohXgceAnwCrI+LZdFV3YG+gBqiT9DFg/C604VpJ/ZR8zubKnHW9ScKihiRT\nP0dyRVJvHTCo/uaCPB4ALpE0XFJ3kl/oj0ZEk1d4u9DmcySdmh7730jGtRZJGippXHq8t9LXdpIT\n+IykA9IrmM3puW0vsi22mxwk1lb+BbiQ5JfED0kGxTMVEeuATwG3ABuA9wNPkHzupbXb+AOSsYyn\nSAaCHyxgm/tJBs8burUiYhNwNfAwyYD1JJJALMQ3SK6M1gC/BX6as9/lwB3A4rTOUUDuuMIfgGeB\ndZJyu6jqt/8dSRfTw+n2h5GMmxQlIlaQfM9/QBJyE4Bz0vGS7sBNJONar5JcAV2XbvpRYJWSuwJv\nBj4VEduKbY/tHiXdxmYdn6QuJF0pkyLi0VK3x6yj8BWJdWiSJqRdPd2Br5Hc7bO4xM0y61AcJNbR\nnQI8R9Jt8hHg3IhoqmvLzHaDu7bMzKwoviIxM7OidIqHNh5wwAFRVlZW6maYmbUbS5cuXR8Rzd0u\n36BTBElZWRmVlZWlboaZWbshqaWnMzRw15aZmRXFQWJmZkVxkJiZWVE6xRiJmbWtd999l+rqat5+\n++1SN8Va0KNHDwYNGkS3bk09Zq1lDhIza3XV1dX06dOHsrIykocu254oItiwYQPV1dUMHjy45Q2a\nkGnXVvp4itXp9JvT86zvrmRK1qp0/oWynHXXpOWrJX0kp/zqdFrOp9P5CTJ5dPTs2VBWBnvtlXyd\nPTuLo5h1TG+//Tb9+/d3iOzhJNG/f/+irxwzC5L0AXkzgTNJJqCZIqm8UbVLSGaGO5Jk9rob023L\nSWZOG0byNNDvK5kTeyBwFcmUpMeQzE8wubXbPns2TJsGL7wAEcnXadMcJma7wiHSPrTGzynLK5JR\nQFU6Zeg2YA47phatNxG4J11+EBifTj40EZgTEe9ExPNAVbo/SLrj9knnl+hJ8jTXVnXddbB1685l\nW7cm5WZmtrMsg2QgO0/7Wc17Z6drqBMRtSQT1PRvatuIeJlk7oEXSeZE2BwRv893cEnTJFVKqqyp\nqdmlhr/44q6Vm9meY8OGDRx//PEcf/zxHHTQQQwcOLDh/bZthU1ZcvHFF7N69epm68ycOZPZrdRN\nccopp7Bs2bJW2VcptKvbfyXtR3K1Mphkrudeks7PVzciZkVERURUDBhQ0Kf8GxzWxCSpTZWbWXFa\nc0yyf//+LFu2jGXLlnHZZZdx9dVXN7zfe++9gWSQefv2pidUvPvuuznqqKOaPc4VV1zB1KlFz+3V\nIWQZJC+z8/zRDfMw56uTdlX1JZnJrqltTweej4iadAa1/wb+qbUbPmMG9Oy5c1nPnkm5mbWuthqT\nrKqqory8nKlTpzJs2DDWrl3LtGnTqKioYNiwYVx//fUNdeuvEGpra+nXrx/Tp0/nuOOO4+STT+a1\n114D4Ktf/Sq33XZbQ/3p06czatQojjrqKP72t78B8Oabb/KJT3yC8vJyJk2aREVFRYtXHvfddx/H\nHnssxxxzDNdeey0AtbW1fOYzn2kov/322wG49dZbKS8vZ/jw4Zx/ft6/qdtElkGyBBgiabCkvUkG\nxec1qjOPZJpNSKYUXRDJc+3nAZPTu7oGA0NIJiN6EThJUs90LGU8sKq1Gz51KsyaBYcfDlLyddas\npNzMWldbjkk+88wzXH311axcuZKBAwdyww03UFlZyZNPPskf/vAHVq5c+Z5tNm/ezNixY3nyySc5\n+eSTueuuu/LuOyJYvHgx3/nOdxpC6Y477uCggw5i5cqVfO1rX+OJJ55otn3V1dV89atfZeHChTzx\nxBP89a9/5Ve/+hVLly5l/fr1PPXUUzz99NNccMEFANx0000sW7aM5cuX873vfa/I787uyyxI0jGP\nK4H5JL/s50bECknXSzonrXYn0F9SFfBlYHq67QpgLrAS+B1wRUTURcQikkH5x0nmxt4LmJVF+6dO\nhTVrYPv25KtDxCwbbTkm+f73v5+KioqG9w888AAjR45k5MiRrFq1Km+Q7LPPPpx55pkAnHDCCaxZ\nsybvvj/+8Y+/p85jjz3G5MnJjaXHHXccw4YNa7Z9ixYt4rTTTuOAAw6gW7dufPrTn+aRRx7hyCOP\nZPXq1Vx11VXMnz+fvn37AjBs2DDOP/98Zs+eXdQHCouV6RhJRPwmIj4QEe+PiBlp2dcjYl66/HZE\nfDIijoyIURHxXM62M9LtjoqI3+aUfyMijo6IYyLiM57tzqx9a8sxyV69ejUsP/vss3z3u99lwYIF\nLF++nAkTJuT9PEX9uApAly5dqK2tzbvv7t27t1hnd/Xv35/ly5czZswYZs6cyec//3kA5s+fz2WX\nXcaSJUsYNWoUdXV1rXrcQrWrwXYz63hKNSb5+uuv06dPH/bdd1/Wrl3L/PnzW/0Yo0ePZu7cuQA8\n9dRTea94cp144oksXLiQDRs2UFtby5w5cxg7diw1NTVEBJ/85Ce5/vrrefzxx6mrq6O6uprTTjuN\nm266ifXr17O1cR9hG/EjUsyspOq7ja+7LunOOuywJESy7k4eOXIk5eXlHH300Rx++OGMHj261Y/x\nhS98gQsuuIDy8vKGV323VD6DBg3iP/7jPzj11FOJCM4++2zOOussHn/8cS655BIiAknceOON1NbW\n8ulPf5o33niD7du386//+q/06dOn1c+hEJ1izvaKiorwxFZmbWfVqlUMHTq01M0oudraWmpra+nR\nowfPPvssZ5xxBs8++yxdu+5Zf8Pn+3lJWhoRFU1sspM962zMzDqQLVu2MH78eGpra4kIfvjDH+5x\nIdIaOt4ZmZntIfr168fSpUtL3YzMebDdzMyK4iAxM7OiOEjMzKwoDhIzMyuKg8TMOpxx48a95wOG\nt912G5dffnmz2/Xu3RuAV155hUmTJuWtc+qpp9LSxwluu+22nT4c+NGPfpRNmzYV0vRmffOb3+Tm\nm28uej+tzUFiZh3OlClTmDNnzk5lc+bMYcqUKQVtf8ghh/Dggw/u9vEbB8lvfvMb+vXrt9v729M5\nSMysw5k0aRK//vWvGyayWrNmDa+88gpjxoxp+GzHyJEjOfbYY/nFL37xnu3XrFnDMcccA8Bbb73F\n5MmTGTp0KOeeey5vvfVWQ73LL7+84TH03/jGNwC4/fbbeeWVVxg3bhzjxo0DoKysjPXr1wNwyy23\ncMwxx3DMMcc0PIZ+zZo1DB06lM997nMMGzaMM844Y6fj5LNs2TJOOukkhg8fzrnnnsvGjRsbjl//\naPn6B0b+5S9/aZjca8SIEbzxxhu7/b3Nx58jMbNMfelL0NqT/x1/PKS/g/Paf//9GTVqFL/97W+Z\nOHEic+bM4bzzzkMSPXr04OGHH2bfffdl/fr1nHTSSZxzzjlNzl3+gx/8gJ49e7Jq1SqWL1/OyJEj\nG9bNmDGD/fffn7q6OsaPH8/y5cu56qqruOWWW1i4cCEHHHDATvtaunQpd999N4sWLSIiOPHEExk7\ndiz77bcfzz77LA888AA/+tGPOO+883jooYeanWPkggsu4I477mDs2LF8/etf51vf+ha33XYbN9xw\nA88//zzdu3dv6E67+eabmTlzJqNHj2bLli306NFjF77bLfMViZl1SLndW7ndWhHBtddey/Dhwzn9\n9NN5+eWXWbduXZP7eeSRRxp+oQ8fPpzhw4c3rJs7dy4jR45kxIgRrFixosWHMj722GOce+659OrV\ni969e/Pxj3+cRx99FIDBgwdz/PHHA80/rh6SOVI2bdrE2LFjAbjwwgt55JFHGto4depU7rvvvoZP\n0Y8ePZovf/nL3H777WzatKnVP13vKxIzy1RzVw5ZmjhxIldffTWPP/44W7du5YQTTgBg9uzZ1NTU\nsHTpUrp160ZZWVnex8e35Pnnn+fmm29myZIl7Lffflx00UW7tZ969Y+hh+RR9C11bTXl17/+NY88\n8gi//OUvmTFjBk899RTTp0/nrLPO4je/+Q2jR49m/vz5HH300bvd1sZ8RWJmHVLv3r0ZN24cn/3s\nZ3caZN+8eTPve9/76NatGwsXLuSFF15odj8f+tCHuP/++wF4+umnWb58OZA8hr5Xr1707duXdevW\n8dvfNkybRJ8+ffKOQ4wZM4af//znbN26lTfffJOHH36YMWPG7PK59e3bl/3226/haubee+9l7Nix\nbN++nZdeeolx48Zx4403snnzZrZs2cLf//53jj32WL7yla/wwQ9+kGeeeWaXj9kcX5GYWYc1ZcoU\nzj333J3u4Jo6dSpnn302xx57LBUVFS3+ZX755Zdz8cUXM3ToUIYOHdpwZXPccccxYsQIjj76aA49\n9NCdHkM/bdo0JkyYwCGHHMLChQsbykeOHMlFF13EqFGjALj00ksZMWJEs91YTbnnnnu47LLL2Lp1\nK0cccQR33303dXV1nH/++WzevJmI4KqrrqJfv3587WtfY+HChey1114MGzasYcbH1uLHyJtZq/Nj\n5NuXYh8j764tMzMrioPEzMyK4iAxs0x0hm7zjqA1fk4OEjNrdT169GDDhg0Okz1cRLBhw4aiP6Do\nu7bMrNUNGjSI6upqampqSt0Ua0GPHj0YNGhQUfvINEgkTQC+C3QBfhwRNzRa3x34KXACsAH4VESs\nSdddA1wC1AFXRcR8SUcBP8vZxRHA1yOiRB95MrN8unXrxuDBg0vdDGsjmQWJpC7ATODDQDWwRNK8\niMh9hsAlwMaIOFLSZOBG4FOSyoHJwDDgEOCPkj4QEauB43P2/zLwcFbnYGZmLctyjGQUUBURz0XE\nNmAOMLFRnYnAPenyg8B4JU9OmwjMiYh3IuJ5oCrdX67xwN8jovmPpZqZWaayDJKBwEs576vTsrx1\nIqIW2Az0L3DbycADTR1c0jRJlZIq3U9rZpaddnnXlqS9gXOA/9dUnYiYFREVEVExYMCAtmucmVkn\nk2WQvAwcmvN+UFqWt46krkBfkkH3lrY9E3g8Ipp+9rOZmbWJLINkCTBE0uD0CmIyMK9RnXnAheny\nJGBBJDeezwMmS+ouaTAwBFics90UmunWMjOztpPZXVsRUSvpSmA+ye2/d0XECknXA5URMQ+4E7hX\nUhXwD5KwIa03F1gJ1AJXREQdgKReJHeCfT6rtpuZWeH89F8zM3sPP/3XzMzajIPEzMyK4iAxM7Oi\nOEjMzKwoDhIzMyuKg8TMzIriIDEzs6I4SMzMrCgOEjMzK4qDxMzMiuIgMTOzojhIzMysKA4SMzMr\nioPEzMyK4iAxM7OiOEjMzKwoDhIzMyuKg8TMzIriIDEzs6I4SMzMrCgOEjMzK4qDxMzMiuIgMTOz\nomQaJJImSFotqUrS9Dzru0v6Wbp+kaSynHXXpOWrJX0kp7yfpAclPSNplaSTszwHMzNrXmZBIqkL\nMBM4EygHpkgqb1TtEmBjRBwJ3ArcmG5bDkwGhgETgO+n+wP4LvC7iDgaOA5YldU5mJlZy7K8IhkF\nVEXEcxGxDZgDTGxUZyJwT7r8IDBektLyORHxTkQ8D1QBoyT1BT4E3AkQEdsiYlOG52BmZi3IMkgG\nAi/lvK9Oy/LWiYhaYDPQv5ltBwM1wN2SnpD0Y0m98h1c0jRJlZIqa2pqWuN8zMwsj/Y22N4VGAn8\nICJGAG8C7xl7AYiIWRFREREVAwYMaMs2mpl1KlkGycvAoTnvB6VleetI6gr0BTY0s201UB0Ri9Ly\nB0mCxczMSiTLIFkCDJE0WNLeJIPn8xrVmQdcmC5PAhZERKTlk9O7ugYDQ4DFEfEq8JKko9JtxgMr\nMzwHMzNrQdesdhwRtZKuBOYDXYC7ImKFpOuByoiYRzJofq+kKuAfJGFDWm8uSUjUAldERF266y8A\ns9Nweg64OKtzMDOzlim5AOjYKioqorKystTNMDNrNyQtjYiKQuq2t8F2MzPbwzhIzMysKA4SMzMr\nioPEzMyK4iAxM7OiOEjMzKwoDhIzMyuKg8TMzIriIDEzs6I4SMzMrCgOEjMzK4qDxMzMiuIgMTOz\nojhIzMysKA4SMzMrioPEzMyK4iAxM7OiOEjMzKwoDhIzMyuKg8TMzIriIDEzs6IUFCSS3i+pe7p8\nqqSrJPXLtmlmZtYeFHpF8hBQJ+lIYBZwKHB/Zq0yM7N2o9Ag2R4RtcC5wB0R8W/AwS1tJGmCpNWS\nqiRNz7O+u6SfpesXSSrLWXdNWr5a0kdyytdIekrSMkmVBbbfzMwy0rXAeu9KmgJcCJydlnVrbgNJ\nXYCZwIeBamCJpHkRsTKn2iXAxog4UtJk4EbgU5LKgcnAMOAQ4I+SPhARdel24yJifYFtNzOzDBV6\nRXIxcDIwIyKelzQYuLeFbUYBVRHxXERsA+YAExvVmQjcky4/CIyXpLR8TkS8ExHPA1Xp/szMbA9T\nUJBExMqIuCoiHpC0H9AnIm5sYbOBwEs576vTsrx10q6zzUD/FrYN4PeSlkqa1tTBJU2TVCmpsqam\npoWmmpnZ7ir0rq0/S9pX0v7A48CPJN2SbdOadEpEjATOBK6Q9KF8lSJiVkRURETFgAED2raFZmad\nSKFdW30j4nXg48BPI+JE4PQWtnmZ5O6ueoPSsrx1JHUF+gIbmts2Iuq/vgY8jLu8zMxKqtAg6Srp\nYOA84FcFbrMEGCJpsKS9SQbP5zWqM49kAB9gErAgIiItn5ze1TUYGAIsltRLUh8ASb2AM4CnC2yP\nmZlloNC7tq4H5gN/jYglko4Anm1ug4iolXRlul0X4K6IWCHpeqAyIuYBdwL3SqoC/kESNqT15gIr\ngVrgioiok3Qg8HAyHk9X4P6I+N0unrOZmbUiJRcAHVtFRUVUVvojJ2ZmhZK0NCIqCqlb6GD7IEkP\nS3otfT0kaVBxzTQzs46g0DGSu0nGLQ5JX79My8zMrJMrNEgGRMTdEVGbvn4C+J5aMzMrOEg2SDpf\nUpf0dT7JbbpmZtbJFRoknyW59fdVYC3JrboXZdQmMzNrRwp9RMoLEXFORAyIiPdFxD8Dn8i4bWZm\n1g4UM0Pil1utFWZm1m4VEyRqtVaYmVm7VUyQdPxPMpqZWYuafUSKpDfIHxgC9smkRWZm1q40GyQR\n0aetGmJmZu1TMV1bZmZmDhIzMyuOg8TMzIriIDEzs6I4SMzMrCgOEjMzK4qDxMzMiuIgMTOzojhI\nzMysKA4SMzMrioPEzMyK4iAxM7OiZBokkiZIWi2pStL0POu7S/pZun6RpLKcddek5aslfaTRdl0k\nPSHpV1m238zMWpZZkEjqAswEzgTKgSmSyhtVuwTYGBFHArcCN6bblgOTgWHABOD76f7qfRFYlVXb\nzcyscFlekYwCqiLiuYjYBswBJjaqMxG4J11+EBgvSWn5nIh4JyKeB6rS/SFpEHAW8OMM225mZgXK\nMkgGAi/lvK9Oy/LWiYhaYDPQv4VtbwP+Hdje3MElTZNUKamypqZmd8/BzMxa0K4G2yV9DHgtIpa2\nVDciZkVERURUDBgwoA1aZ2bWOWUZJC8Dh+a8H5SW5a0jqSvQF9jQzLajgXMkrSHpKjtN0n1ZNN7M\nzAqTZZAsAYZIGixpb5LB83mN6swDLkyXJwELIiLS8snpXV2DgSHA4oi4JiIGRURZur8FEXF+hudg\nZmYtaHbO9mJERK2kK4H5QBfgrohYIel6oDIi5gF3AvdKqgL+QRIOpPXmAiuBWuCKiKjLqq1mZrb7\nlFwAdGwVFRVRWVlZ6maYmbUbkpZGREUhddvVYLuZme15HCTNqK6GTnDBZmZWlMzGSNq77dth+HDY\nay845RQYMyZ5jRgB3bqVunVmZnsOB0kTamvhv/4LHn00ef3iF0l5z55w8sk7guWkk5IyM7POyoPt\nBVq7Fh57bEewPPlk0u3VtSuccMKOYBk9Gvr3b6WGm5mVyK4MtjtIdtPmzfC3v+0IlsWLYdu2ZN2w\nYUmo1HeJHXZYqx7azCxzDpJG2uL237ffhiVLdgTL3/4Gr7+erDvssB1XLGPGwNChIGXaHDOzouxK\nkHiMpJX06LEjKADq6mD58h3B8sc/wuzZybr+/T2Ab2Ydh69I2kgEVFXtCJZHH4W//z1Z16tXMmjv\nAXwz21O4a6uRPSFI8il0AP+UU2D//UvdWjPrTBwkjeypQdJYIQP49a9DD21+X2bW8dXVQU0NrFuX\n/9WlC9x99+7t20HSSHsJksYaD+D/9a/wxhvJusMP3zlYjj7aA/hmHcG77zYfDvWvV1+F9evzP32j\nRw848EB4//vhT3/avXY4SBppr0HSWOMB/EcfTf5BgQfwzfZk27bBa6+1HAzr1sGGDfn30bNnEg6N\nXwcd9N6yPn2K/8PSQdJIRwmSxjyAb1Y677xTWDCsWwcbN+bfR+/ehYdD795te34OkkY6apDk88or\nOw/gL1/uAXyzQr31VsuhUP/avDn/Pvbdt7BgOPDAPfuPOwdJI50pSBrbtGnnAfwlSzyAb51DRBIM\nmzcnr40bmw+Gdet2jEE21q9fYeHwvvfBPvu07XlmxUHSSGcOksbefju5Gyz3E/i5A/innJL8h+jR\nY8ere/ed3zdV1ri8e3ffAGC7JyL5t1ofAps27Vhu6ZVbt7a26WPsv3/h4dC9e9ud+57Cn2y3JvXo\nAR/6UPKC5D9a7gD+n/+c/Ed8663kUfrF6t5994OoNep26+Ywa2uNQ6CQX/j5Xu++2/xxpKQbqW/f\nHa+DD07uYMwtq3/tt9+OcBgwAPbeu22+H52Br0isSbW1yS+Et99OBhbrl9uyrNh/nlJhQdStWzKO\n1K3bzsv5ylprudC6Xbq0zs+zUI1DYHeuBloKAXhvCPTtm3Qh5QuBfK8+fZL5giwbviKx3TJ7Nlx3\nHbz4YvKgyRkzYOrUtr9bpF7EzmGWVVht3Jgc5913k1dLy3V1bft9kFo/pKTkoaL5wqB+DK05jUPg\nwAPhAx/I/ws/Xzg4BDoWB4kBSYhMmwZbtybvX3gheQ9JmJRC/S/Qbt2SXzx7ivqAKyR0mlre3e12\nZR/vvANvvpm/TkTyPe3bNxkDaCoEmroSaOurJNuzuWvLACgrS8KjscMPhzVr2ro1ZlZqu9K15YtL\nA5LurF0pNzOrl2mQSJogabWkKknT86zvLuln6fpFkspy1l2Tlq+W9JG0rIekxZKelLRC0reybH9n\n0tQsjp7d0cxaklmQSOoCzATOBMqBKZLKG1W7BNgYEUcCtwI3ptuWA5OBYcAE4Pvp/t4BTouI44Dj\ngQmSTsrqHDqTGTPe+ynbnj1ZQMdsAAAJEElEQVSTcjOz5mR5RTIKqIqI5yJiGzAHmNiozkTgnnT5\nQWC8JKXlcyLinYh4HqgCRkViS1q/W/rq+IM8bWDqVJg1KxkTkZKvs2aVbqDdzNqPLO/aGgi8lPO+\nGjixqToRUStpM9A/Lf/fRtsOhIYrnaXAkcDMiFiU7+CSpgHTAA5z/0xBpk51cJjZrmt3g+0RURcR\nxwODgFGSjmmi3qyIqIiIigEDBrRtI83MOpEsg+RlIPcxgIPSsrx1JHUF+gIbCtk2IjYBC0nGUMzM\nrESyDJIlwBBJgyXtTTJ4Pq9RnXnAhenyJGBBJB9smQdMTu/qGgwMARZLGiCpH4CkfYAPA89keA5m\nZtaCzMZI0jGPK4H5QBfgrohYIel6oDIi5gF3AvdKqgL+QRI2pPXmAiuBWuCKiKiTdDBwTzpOshcw\nNyJ+ldU5mJlZy/zJdjMzew9/st3MzNqMg8TMzIriIDEzs6I4SMzMrCgOEjMzK4qDxMzMiuIgMTOz\nojhIrFObPTuZHXKvvZKvs2eXukVm7Y/nbLdOa0+cp96sPfIViXVa1123I0Tqbd2alJtZ4Rwk1ml5\nnnqz1uEgsU7L89SbtQ4HiXVanqferHU4SKzT8jz1Zq3Dd21Zp+Z56s2K5ysSMzMrioPEzMyK4iAx\nM7OiOEjMOhE/Esay4MF2s07Cj4SxrPiKxKyT8CNhLCsOErNOwo+Esaw4SMw6CT8SxrKSaZBImiBp\ntaQqSdPzrO8u6Wfp+kWSynLWXZOWr5b0kbTsUEkLJa2UtELSF7Nsv1lH4kfCWFYyCxJJXYCZwJlA\nOTBFUnmjapcAGyPiSOBW4MZ023JgMjAMmAB8P91fLfAvEVEOnARckWefZpaHHwljWcnyimQUUBUR\nz0XENmAOMLFRnYnAPenyg8B4SUrL50TEOxHxPFAFjIqItRHxOEBEvAGsAgZmeA5mHcrUqbBmDWzf\nnnztDCHiW56zl2WQDAReynlfzXt/6TfUiYhaYDPQv5Bt026wEcCifAeXNE1SpaTKmpqa3T4JM2u/\n6m95fuEFiNhxy7PDpHW1y8F2Sb2Bh4AvRcTr+epExKyIqIiIigEDBrRtA81sj+BbnttGlkHyMnBo\nzvtBaVneOpK6An2BDc1tK6kbSYjMjoj/zqTlZtYh+JbntpFlkCwBhkgaLGlvksHzeY3qzAMuTJcn\nAQsiItLyyeldXYOBIcDidPzkTmBVRNySYdvNrAPorLc8t/W4UGZBko55XAnMJxkUnxsRKyRdL+mc\ntNqdQH9JVcCXgenptiuAucBK4HfAFRFRB4wGPgOcJmlZ+vpoVudgZu1bZ7zluRTjQkouADq2ioqK\nqKysLHUzzKwEZs9OxkRefDG5Epkxo2PfrVZWloRHY4cfntypVyhJSyOioqC6DhIzs45jr72SK5HG\npOS270LtSpC0y7u2zMwsv1KMCzlIzMw6kFKMCzlIzMw6kFI8CscTW5mZdTBTp7btDQW+IjEzs6I4\nSMzMrCgOEjMzK4qDxMzMiuIgMTOzonSKT7ZLqgHyPDSgIAcA61uxOe2Bz7nj62znCz7nXXV4RBQ0\nB0enCJJiSKos9DEBHYXPuePrbOcLPucsuWvLzMyK4iAxM7OiOEhaNqvUDSgBn3PH19nOF3zOmfEY\niZmZFcVXJGZmVhQHiZmZFcVB0gRJEyStllQlaXqp29MWJN0l6TVJT5e6LW1B0qGSFkpaKWmFpC+W\nuk1Zk9RD0mJJT6bn/K1St6mtSOoi6QlJvyp1W9qCpDWSnpK0TFKmU8R6jCQPSV2A/wM+DFQDS4Ap\nEbGypA3LmKQPAVuAn0bEMaVuT9YkHQwcHBGPS+oDLAX+uSP/nCUJ6BURWyR1Ax4DvhgR/1vipmVO\n0peBCmDfiPhYqduTNUlrgIqIyPxDmL4iyW8UUBURz0XENmAOMLHEbcpcRDwC/KPU7WgrEbE2Ih5P\nl98AVgEDS9uqbEViS/q2W/rq8H9NShoEnAX8uNRt6YgcJPkNBF7KeV9NB/8F09lJKgNGAItK25Ls\npV08y4DXgD9ERIc/Z+A24N+B7aVuSBsK4PeSlkqaluWBHCTW6UnqDTwEfCkiXi91e7IWEXURcTww\nCBglqUN3Y0r6GPBaRCwtdVva2CkRMRI4E7gi7brOhIMkv5eBQ3PeD0rLrINJxwkeAmZHxH+Xuj1t\nKSI2AQuBCaVuS8ZGA+ekYwZzgNMk3VfaJmUvIl5Ov74GPEzSZZ8JB0l+S4AhkgZL2huYDMwrcZus\nlaUDz3cCqyLillK3py1IGiCpX7q8D8kNJc+UtlXZiohrImJQRJSR/F9eEBHnl7hZmZLUK72BBEm9\ngDOAzO7GdJDkERG1wJXAfJIB2LkRsaK0rcqepAeA/wGOklQt6ZJStyljo4HPkPyFuix9fbTUjcrY\nwcBCSctJ/mD6Q0R0itthO5kDgcckPQksBn4dEb/L6mC+/dfMzIriKxIzMyuKg8TMzIriIDEzs6I4\nSMzMrCgOEjMzK4qDxGw3SarLuW14WWs+JVpSWWd5CrO1f11L3QCzduyt9FEjZp2ar0jMWlk6D8RN\n6VwQiyUdmZaXSVogabmkP0k6LC0/UNLD6RwhT0r6p3RXXST9KJ035PfpJ9GRdFU6h8pySXNKdJpm\nDRwkZrtvn0ZdW5/KWbc5Io4Fvkfy5FmAO4B7ImI4MBu4PS2/HfhLRBwHjATqn6IwBJgZEcOATcAn\n0vLpwIh0P5dldXJmhfIn2812k6QtEdE7T/ka4LSIeC59KOSrEdFf0nqSibTeTcvXRsQBkmqAQRHx\nTs4+ykgeXzIkff8VoFtEfFvS70gmIPs58POc+UXMSsJXJGbZiCaWd8U7Oct17BjTPAuYSXL1skSS\nxzqtpBwkZtn4VM7X/0mX/0by9FmAqcCj6fKfgMuhYdKpvk3tVNJewKERsRD4CtAXeM9VkVlb8l8y\nZrtvn3SmwXq/i4j6W4D3S5+w+w4wJS37AnC3pH8DaoCL0/IvArPSpy3XkYTK2iaO2QW4Lw0bAben\n84qYlYzHSMxaWTpGUhER60vdFrO24K4tMzMriq9IzMysKL4iMTOzojhIzMysKA4SMzMrioPEzMyK\n4iAxM7Oi/H+DGcJM2rk86QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f15eea8f240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(range(len(loss_values)), loss_values, 'bo', label='Training loss')           \n",
    "plt.plot(range(len(val_loss_values)), val_loss_values, 'b', label='Validation loss')      \n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLC8nCzMzy8vJwszM8nKyMDOzvP4/pEzEhR36kSYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f15ee3e2390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()    \n",
    "\n",
    "f1_values = history_dict['f1']\n",
    "val_f1_values = history_dict['val_f1']\n",
    "\n",
    "plt.plot(range(len(f1_values)), f1_values, 'bo', label='Training f1')\n",
    "plt.plot(range(len(val_f1_values)), val_f1_values, 'b', label='Validation f1')\n",
    "plt.title('Training and validation batch-level f1-micro')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1-micro')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_file(array,name):\n",
    "    df = pd.DataFrame(data = array.tolist(),columns=[i for i in range(1,y_train.shape[1]+1)])\n",
    "    df.to_csv(os.path.join(DATADIR, name+'.csv.gz'),compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict([meta_train, title_train, desc_train, x_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_prob,\"train_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_prob.copy()\n",
    "y_pred[y_pred>=P_THRESHOLD] = 1\n",
    "y_pred[y_pred<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro: (0.96101276636134969, 0.93542519589557627, 0.94804636178225421, None)\n",
      "macro: (0.97192183890335904, 0.95786911729383484, 0.96419190633929608, None)\n",
      "weightedmacro: (0.96047532903629307, 0.93542519589557627, 0.94706484670334179, None)\n"
     ]
    }
   ],
   "source": [
    "print('micro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='micro', sample_weight=None)))\n",
    "print('macro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='macro', sample_weight=None)))\n",
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='weighted', sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_dev = model.predict([meta_dev, title_dev, desc_dev, x_dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_prob_dev,\"dev_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dev = y_prob_dev.copy()\n",
    "y_pred_dev[y_pred_dev>=P_THRESHOLD] = 1\n",
    "y_pred_dev[y_pred_dev<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro: (0.85979850777726252, 0.81233820542434987, 0.83539482306684132, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro: (0.77115728139098116, 0.8235161808311745, 0.78697729773375458, None)\n",
      "weightedmacro: (0.85840256264091908, 0.81233820542434987, 0.83125011124312775, None)\n"
     ]
    }
   ],
   "source": [
    "print('micro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='micro', sample_weight=None)))\n",
    "print('macro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='macro', sample_weight=None)))\n",
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='weighted', sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weightedmacro: (array([ 0.75      ,  0.82608696,  0.78723404,  0.63265306,  0.75      ,\n",
      "        0.97916667,  0.75      ,  0.5625    ,  0.73381295,  1.        ,\n",
      "        1.        ,  0.99012346,  1.        ,  1.        ,  0.68333333,\n",
      "        0.        ,  0.77272727,  0.81818182,  1.        ,  0.84090909,\n",
      "        0.87980769,  0.7591623 ,  0.87725632,  1.        ,  0.83333333,\n",
      "        1.        ,  0.66666667,  0.75      ,  1.        ,  0.76470588,\n",
      "        0.8       ,  0.76744186,  0.        ,  0.875     ,  0.        ,\n",
      "        0.69565217,  0.85362096,  0.89473684,  0.73333333,  0.80186916,\n",
      "        0.8       ,  0.64556962,  0.        ,  0.87234043,  0.86440678,\n",
      "        0.8       ,  0.99925981,  0.78      ,  0.83333333,  0.33333333,\n",
      "        0.88      ,  0.71641791,  0.        ,  1.        ,  0.77777778,\n",
      "        1.        ,  0.88888889,  1.        ,  0.        ,  0.91691395,\n",
      "        0.72727273,  0.85620915,  0.93023256,  0.88888889,  0.68421053,\n",
      "        0.75409836,  1.        ,  0.82553191,  0.75714286,  0.        ,\n",
      "        1.        ,  0.66666667,  0.83333333,  1.        ,  0.625     ,\n",
      "        0.75      ,  0.78723404,  0.94495413,  0.82253521,  0.        ,\n",
      "        0.83732057,  0.86486486,  0.75      ,  0.87261146,  0.88581315,\n",
      "        1.        ,  1.        ,  0.75287356,  1.        ,  1.        ,\n",
      "        0.8       ,  0.81481481,  0.5       ,  0.88110403,  0.71856287,\n",
      "        1.        ,  0.97727273,  0.92307692,  0.63888889,  0.83333333,\n",
      "        0.9088729 ,  0.81818182,  1.        ,  0.90540541,  0.91666667,\n",
      "        0.84745763,  0.        ,  0.44444444,  0.88235294,  0.66666667,\n",
      "        0.47368421,  1.        ,  0.5       ,  1.        ,  1.        ,\n",
      "        1.        ,  0.625     ,  0.82918149,  0.82608696,  0.85454545,\n",
      "        0.75862069,  0.90909091,  0.92929293,  0.97037037,  0.5       ,\n",
      "        0.69767442,  0.87610619,  0.66666667,  0.85714286,  0.875     ,\n",
      "        0.        ,  1.        ,  0.86845466,  0.5       ,  0.86636971,\n",
      "        0.93333333,  1.        ,  0.76470588,  0.6       ,  1.        ,\n",
      "        0.85436893,  0.77777778,  0.87412587,  0.74352941,  0.86956522,\n",
      "        0.5       ,  0.90909091,  1.        ,  1.        ,  0.91320293,\n",
      "        0.        ,  1.        ,  0.72222222,  0.98214286,  0.88888889,\n",
      "        0.7173913 ,  0.8       ,  1.        ,  0.55555556,  0.92125984,\n",
      "        0.90909091,  0.80084746,  0.88636364,  0.84848485,  0.68115942,\n",
      "        0.91463415,  0.85436893,  0.87640449,  0.66666667,  0.        ,\n",
      "        0.70588235,  1.        ,  0.72307692,  0.78787879,  0.8203125 ,\n",
      "        0.75      ,  0.77777778,  0.        ,  0.66666667,  0.91666667,\n",
      "        0.84615385,  0.82608696,  0.82352941,  0.90833333,  1.        ,\n",
      "        0.71428571,  0.6       ,  0.84088269,  0.78571429,  0.85714286,\n",
      "        1.        ,  1.        ,  0.5       ,  1.        ,  0.69716088,\n",
      "        1.        ,  0.63953488,  0.        ,  0.89473684,  0.71111111,\n",
      "        0.95555556,  0.        ,  1.        ,  0.95175439,  0.87974684,\n",
      "        0.67391304,  0.72222222,  0.88709677,  0.8440367 ,  1.        ,\n",
      "        0.85714286,  0.66666667,  0.75      ,  0.66666667]), array([ 1.        ,  0.95      ,  0.77894737,  0.88571429,  0.9375    ,\n",
      "        0.97916667,  0.4351145 ,  0.75      ,  0.7311828 ,  1.        ,\n",
      "        1.        ,  0.98284314,  1.        ,  1.        ,  0.83673469,\n",
      "        0.        ,  1.        ,  0.8852459 ,  1.        ,  0.84090909,\n",
      "        0.79025293,  0.66820276,  0.86785714,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  0.97058824,  0.        ,  1.        ,  0.        ,\n",
      "        0.69565217,  0.85099846,  0.93969849,  0.86842105,  0.67987322,\n",
      "        0.94117647,  0.425     ,  0.        ,  0.63076923,  0.5257732 ,\n",
      "        1.        ,  0.99852071,  0.5       ,  0.90909091,  1.        ,\n",
      "        0.88      ,  0.8372093 ,  0.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.85833333,\n",
      "        0.94117647,  0.61792453,  1.        ,  1.        ,  1.        ,\n",
      "        0.66666667,  1.        ,  0.6006192 ,  0.71621622,  0.        ,\n",
      "        0.95402299,  0.90909091,  1.        ,  1.        ,  1.        ,\n",
      "        0.65346535,  1.        ,  0.8442623 ,  0.79347826,  0.        ,\n",
      "        0.80645161,  0.91428571,  1.        ,  0.80588235,  0.89877121,\n",
      "        1.        ,  1.        ,  0.56223176,  1.        ,  1.        ,\n",
      "        1.        ,  0.95652174,  1.        ,  0.86458333,  0.75471698,\n",
      "        1.        ,  0.93478261,  0.96      ,  0.44230769,  0.71428571,\n",
      "        0.84222222,  0.49450549,  1.        ,  0.89333333,  0.91666667,\n",
      "        0.69444444,  0.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  0.98113208,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.77408638,  0.6440678 ,  0.75806452,\n",
      "        0.73333333,  0.90909091,  0.82142857,  0.95970696,  1.        ,\n",
      "        0.47244094,  0.98019802,  1.        ,  1.        ,  1.        ,\n",
      "        0.        ,  1.        ,  0.90305445,  0.72222222,  0.83476395,\n",
      "        0.88421053,  1.        ,  0.92857143,  1.        ,  1.        ,\n",
      "        0.6875    ,  1.        ,  0.81699346,  0.78217822,  0.83333333,\n",
      "        0.90909091,  1.        ,  1.        ,  1.        ,  0.87573271,\n",
      "        0.        ,  1.        ,  0.78787879,  0.91059603,  0.97560976,\n",
      "        0.43421053,  0.94117647,  1.        ,  1.        ,  0.936     ,\n",
      "        0.82352941,  0.71590909,  0.82978723,  1.        ,  0.62666667,\n",
      "        0.79365079,  0.81860465,  0.80412371,  1.        ,  0.        ,\n",
      "        1.        ,  1.        ,  0.55078125,  0.83870968,  0.70469799,\n",
      "        0.85714286,  1.        ,  0.        ,  1.        ,  1.        ,\n",
      "        0.84615385,  1.        ,  0.84848485,  0.80147059,  0.8       ,\n",
      "        1.        ,  0.71428571,  0.77267876,  0.91666667,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  0.47121535,\n",
      "        1.        ,  0.63218391,  0.        ,  1.        ,  0.88888889,\n",
      "        0.89583333,  0.        ,  1.        ,  0.90041494,  0.74731183,\n",
      "        0.75609756,  1.        ,  0.97633136,  0.77310924,  1.        ,\n",
      "        0.94736842,  1.        ,  1.        ,  1.        ]), array([ 0.85714286,  0.88372093,  0.78306878,  0.73809524,  0.83333333,\n",
      "        0.97916667,  0.55072464,  0.64285714,  0.73249551,  1.        ,\n",
      "        1.        ,  0.98646986,  1.        ,  1.        ,  0.75229358,\n",
      "        0.        ,  0.87179487,  0.8503937 ,  1.        ,  0.84090909,\n",
      "        0.83262918,  0.71078431,  0.87253142,  1.        ,  0.90909091,\n",
      "        1.        ,  0.8       ,  0.85714286,  1.        ,  0.86666667,\n",
      "        0.88888889,  0.85714286,  0.        ,  0.93333333,  0.        ,\n",
      "        0.69565217,  0.85230769,  0.91666667,  0.79518072,  0.73584906,\n",
      "        0.86486486,  0.51256281,  0.        ,  0.73214286,  0.65384615,\n",
      "        0.88888889,  0.99889012,  0.609375  ,  0.86956522,  0.5       ,\n",
      "        0.88      ,  0.77211796,  0.        ,  1.        ,  0.875     ,\n",
      "        1.        ,  0.94117647,  1.        ,  0.        ,  0.8866571 ,\n",
      "        0.82051282,  0.71780822,  0.96385542,  0.94117647,  0.8125    ,\n",
      "        0.70769231,  1.        ,  0.6953405 ,  0.73611111,  0.        ,\n",
      "        0.97647059,  0.76923077,  0.90909091,  1.        ,  0.76923077,\n",
      "        0.6984127 ,  0.88095238,  0.89177489,  0.8077455 ,  0.        ,\n",
      "        0.82159624,  0.88888889,  0.85714286,  0.83792049,  0.89224514,\n",
      "        1.        ,  1.        ,  0.64373464,  1.        ,  1.        ,\n",
      "        0.88888889,  0.88      ,  0.66666667,  0.87276551,  0.73619632,\n",
      "        1.        ,  0.95555556,  0.94117647,  0.52272727,  0.76923077,\n",
      "        0.87427912,  0.61643836,  1.        ,  0.89932886,  0.91666667,\n",
      "        0.76335878,  0.        ,  0.61538462,  0.9375    ,  0.8       ,\n",
      "        0.64285714,  0.99047619,  0.66666667,  1.        ,  1.        ,\n",
      "        1.        ,  0.76923077,  0.80068729,  0.72380952,  0.8034188 ,\n",
      "        0.74576271,  0.90909091,  0.87203791,  0.96500921,  0.66666667,\n",
      "        0.56338028,  0.92523364,  0.8       ,  0.92307692,  0.93333333,\n",
      "        0.        ,  1.        ,  0.88541667,  0.59090909,  0.85027322,\n",
      "        0.90810811,  1.        ,  0.83870968,  0.75      ,  1.        ,\n",
      "        0.76190476,  0.875     ,  0.84459459,  0.76236429,  0.85106383,\n",
      "        0.64516129,  0.95238095,  1.        ,  1.        ,  0.8940754 ,\n",
      "        0.        ,  1.        ,  0.75362319,  0.94501718,  0.93023256,\n",
      "        0.54098361,  0.86486486,  1.        ,  0.71428571,  0.92857143,\n",
      "        0.86419753,  0.756     ,  0.85714286,  0.91803279,  0.65277778,\n",
      "        0.84985836,  0.83610451,  0.83870968,  0.8       ,  0.        ,\n",
      "        0.82758621,  1.        ,  0.62527716,  0.8125    ,  0.75812274,\n",
      "        0.8       ,  0.875     ,  0.        ,  0.8       ,  0.95652174,\n",
      "        0.84615385,  0.9047619 ,  0.8358209 ,  0.8515625 ,  0.88888889,\n",
      "        0.83333333,  0.65217391,  0.80533927,  0.84615385,  0.92307692,\n",
      "        1.        ,  1.        ,  0.66666667,  1.        ,  0.56234097,\n",
      "        1.        ,  0.63583815,  0.        ,  0.94444444,  0.79012346,\n",
      "        0.92473118,  0.        ,  1.        ,  0.92537313,  0.80813953,\n",
      "        0.71264368,  0.83870968,  0.92957746,  0.80701754,  1.        ,\n",
      "        0.9       ,  0.8       ,  0.85714286,  0.8       ]), array([   6,   20,   95,   35,   16,   48,  131,   12,  279,    2,    2,\n",
      "        816,    4,    2,   49,    0,   17,   61,    1,  132, 1621,  217,\n",
      "        280,    2,    5,    6,    4,    3,    1,   13,   16,   34,    0,\n",
      "         14,    0,   46,  651,  597,   38,  631,   17,  120,    0,  130,\n",
      "         97,    4, 1352,   78,   11,    1,   25,  172,    0,    4,   14,\n",
      "          1,    8,    1,    0,  360,   17,  212,   40,    8,   13,   69,\n",
      "          3,  323,  148,    0,   87,   22,    5,   15,    5,  101,   37,\n",
      "        122,  368,    0,  434,   35,   12,  170, 1709,    1,    4,  233,\n",
      "          1,    2,    4,   23,    1,  480,  159,   18,   46,   25,   52,\n",
      "        105,  450,   91,    3,   75,   12,   72,    0,    8,   15,    2,\n",
      "          9,   53,   14,    1,    1,    1,    5,  301,   59,   62,   30,\n",
      "         22,  112,  273,    1,  127,  101,    2,    6,    7,    0,    5,\n",
      "        753,   18,  932,  190,    1,   14,    9,    5,  128,   21,  153,\n",
      "        404,  120,   11,   10,    1,    3,  853,    0,    1,   33,  302,\n",
      "         41,   76,   34,    3,   10,  375,  170,  264,   94,   28,   75,\n",
      "        189,  430,  194,    2,    0,   12,    5,  256,   31,  149,    7,\n",
      "          7,    0,   16,   11,   13,   19,   33,  136,   25,    5,   21,\n",
      "        937,   12,   12,    9,    1,    1,    3,  938,   13,   87,    0,\n",
      "         17,   36,   96,    0,    1,  241,  186,   41,   13,  169,  238,\n",
      "          2,   19,    2,    3,    8]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average=None, sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_train,\"true_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_dev,\"true_dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(data_to_tag): \n",
    "    filename = data_to_tag+\"_arrays.npz\"\n",
    "    arrays = np.load(os.path.join(DATADIR,filename))\n",
    "    \n",
    "    print('Set up arrays for new_content: {}'.format(arrays.files))\n",
    "    x_predict = arrays['x']\n",
    "    meta_predict = arrays['meta'].all().todense()\n",
    "    title_predict = arrays['title'].all().todense()\n",
    "    desc_predict = arrays['desc'].all().todense()\n",
    "    \n",
    "    print('x_arrays.shape = {}'.format(x_predict.shape))\n",
    "    print('meta_arrays.shape = {}'.format(meta_predict.shape))\n",
    "    print('title_arrays.shape = {}'.format(title_predict.shape))\n",
    "    print('desc_arrays.shape = {}'.format(desc_predict.shape))\n",
    "    \n",
    "    print('Predict on untagged content')\n",
    "    y_pred_new = model.predict([meta_predict, title_predict, desc_predict, x_predict])\n",
    "    \n",
    "    to_file(y_pred_new, data_to_tag+\"_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/2018-07-10/new_arrays.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-6254809fe7fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"new\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-c09186d52066>\u001b[0m in \u001b[0;36mget_predictions\u001b[0;34m(data_to_tag)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_to_tag\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_arrays.npz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATADIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Set up arrays for new_content: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/2018-07-10/new_arrays.npz'"
     ]
    }
   ],
   "source": [
    "get_predictions(\"new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_predictions(\"level1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "keep_output": true,
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
