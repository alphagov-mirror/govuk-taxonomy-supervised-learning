{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from nltk import word_tokenize,sent_tokenize,pos_tag_sents,pos_tag\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR=os.getenv('DATADIR')\n",
    "DATAPATH = os.path.join(DATADIR, 'labelled_level2.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATAPATH,compression='gzip')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 UTILS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index(x):\n",
    "    index_dict = {}\n",
    "    index_dict['index'] = 0\n",
    "    for i,elem in enumerate(x):\n",
    "        index_dict[elem] = i+1\n",
    "    return index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = build_index(data.columns)\n",
    "print(ind['combined_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filter target Part of Speech tags and punctuation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_junk(word):\n",
    "    return len(word) < 2\n",
    "\n",
    "def is_aux(word):\n",
    "    m = re.match(\"\\\\b[iI]s\\\\b|\\\\b[aA](m|re)\\\\b|\\\\b[bB](een|e)\\\\b|\\\\b[hH](ave|as)\\\\b|\\\\b[wW](as|ere|ill|ould)\\\\b\",word)\n",
    "    return bool(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"been\"\n",
    "print(is_aux(test))\n",
    "test2 = \"\"\n",
    "print(is_junk(test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_text(x):\n",
    "    keep_text =\"\"\n",
    "    sent_pos = pos_tag(word_tokenize(x))\n",
    "    for word,tag in sent_pos:\n",
    "        if not is_junk(word) and (tag.startswith(\"NN\") or (tag.startswith(\"VB\") and \n",
    "                                                           not is_aux(word)) or tag.startswith(\"JJ\")):\n",
    "            keep_text += word + \" \"\n",
    "    return keep_text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Filter all text fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reduced_title'] = data['title'].map(reduce_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reduced_desc'] = data['description'].map(reduce_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reduced_body'] = data['body'].map(reduce_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reduced_combined'] = data['combined_text'].map(reduce_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Rename and drop unfiltered columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['combined_text'] = data['reduced_combined'] \n",
    "data['title'] = data['reduced_title'] \n",
    "data['body'] = data['reduced_body']\n",
    "data['description'] = data['reduced_desc'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['reduced_combined','reduced_title', 'reduced_body','reduced_desc'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Write to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'labelled_level2_filtered_all_beta.csv.gz'\n",
    "OUTPUT= os.path.join(DATADIR, file)\n",
    "data.to_csv(OUTPUT,compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taxon-sl",
   "language": "python",
   "name": "taxon-sl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
