{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Untagged data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data were written out from the clean_content.py script where the taxons column was empty. \n",
    "- Here we assume the taxon column was empty because the content item has not been tagged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in untagged content to describe content with no taxons\n",
    "untagged = pd.read_csv('../../data/untagged_content.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57337 rows in the untagged content data\n",
      "There are 57123 unique content items in the untagged content data\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} rows in the untagged content data\".\n",
    "      format(untagged.shape[0]))\n",
    "print(\"There are {} unique content items in the untagged content data\".\n",
    "      format(untagged.content_id.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'base_path', 'content_id', 'description', 'details',\n",
       "       'document_type', 'first_published_at', 'locale',\n",
       "       'primary_publishing_organisation', 'publishing_app', 'taxons', 'title',\n",
       "       'body'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untagged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'pandas._libs.tslib.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "#convert string dates to timestamp for time series analyses (see below)\n",
    "print(type(untagged['first_published_at'][0]))\n",
    "untagged['first_published_at'] = pd.to_datetime(untagged['first_published_at'])\n",
    "print(type(untagged['first_published_at'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use timestamp as index in untagged data for plots\n",
    "untagged.index = untagged['first_published_at'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxon data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taxons data is a row for each taxon with columns for the taxon_id/taxon title at each level. So, for example, if an item has only been tagged to level1 then level2 and subsequent levels will be missing. If an item was tagged to level3, the level2 and level1 columns have been filled recursively. \n",
    "\n",
    "A taxon in taxons is identified through content_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in taxon file which was cleaned from raw using clean_taxons.py\n",
    "taxons = pd.read_csv('../../data/clean_taxons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'base_path', 'content_id', 'taxon_name', 'level1',\n",
       "       'level2tax_id', 'level3tax_id', 'level4tax_id', 'level1taxon',\n",
       "       'level2taxon', 'level3taxon', 'level4taxon'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxons.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxons = taxons[['base_path','content_id','taxon_name','level1taxon','level2taxon','level3taxon','level4taxon']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This section needs to be moved to clean_taxons.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For top taxons (level1) ensure that taxon)name is in level1taxon column instead of Nan\n",
    "taxons['level1taxon'] = taxons['level1taxon'].fillna(taxons['taxon_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to combine boolean series into one\n",
    "\n",
    "def conjunction(*conditions):\n",
    "    return functools.reduce(np.logical_and, conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy of taxons for working with\n",
    "taxonslevels = taxons.copy()\n",
    "#define the condition \n",
    "cond = conjunction(taxonslevels['level2taxon'].isna(), taxonslevels['level1taxon'] != taxonslevels['taxon_name'])\n",
    "#change the values of the column if the condition is met to the taxon-name, otherwise the original string\n",
    "taxonslevels['level2taxon'] = np.where(cond, taxonslevels['taxon_name'], taxonslevels['level2taxon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = conjunction(taxons['level2taxon'] != taxons['taxon_name'], taxons['level3taxon'].isna(), taxons['level2taxon'].notnull())\n",
    "taxonslevels['level3taxon'] = np.where(cond, taxonslevels['taxon_name'], taxonslevels['level3taxon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = conjunction(taxons['level3taxon'] != taxons['taxon_name'], taxons['level2taxon'] != taxons['taxon_name'], taxons['level4taxon'].isna(), taxons['level3taxon'].notnull())\n",
    "taxonslevels['level4taxon'] = np.where(cond, taxonslevels['taxon_name'], taxonslevels['level4taxon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column for last taxon level\n",
    "taxonslevels['level5taxon'] = np.nan\n",
    "cond = conjunction(taxons['level4taxon'] != taxons['taxon_name'], taxons['level3taxon'] != taxons['taxon_name'], taxons['level2taxon'] != taxons['taxon_name'], taxons['level4taxon'].notnull())\n",
    "taxonslevels['level5taxon'] = np.where(cond, taxonslevels['taxon_name'], taxonslevels['level5taxon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy the working df back to taxons\n",
    "taxons = taxonslevels.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data were created in clean_content.py so that each row represents a single content-taxon pair. There can be multiple rows for a content item (content_id) if it has been tagged to multiple taxons (taxon_id).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in content items file which was cleaned from raw using clean_content.py\n",
    "\n",
    "content = pd.read_csv('../../data/clean_content.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'base_path', 'content_id', 'description', 'details',\n",
       "       'document_type', 'first_published_at', 'locale',\n",
       "       'primary_publishing_organisation', 'publishing_app', 'title', 'body',\n",
       "       'combined_text', 'variable', 'taxon_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(335615, 15)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140103"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.content_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All content with no filtering by taxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcontent_taxons = pd.merge(\n",
    "    left=content, \n",
    "    right=taxons, \n",
    "    left_on='taxon_id', #which taxon is the content item tagged to\n",
    "    right_on='content_id', #what is the id of that taxon\n",
    "    how='outer', #keep everything for checking merge\n",
    "    indicator=True #so we can filter by match type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336967, 24)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allcontent_taxons.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tidy column names\n",
    "allcontent_taxons.rename(columns={'base_path_x': 'base_path', \n",
    "                               'content_id_x': 'content_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both          232526\n",
      "left_only     103089\n",
      "right_only      1352\n",
      "Name: _merge, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(allcontent_taxons['_merge'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54370"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allcontent_taxons[allcontent_taxons._merge == 'left_only'].content_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1352, 24)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_taxons=allcontent_taxons[allcontent_taxons._merge == 'right_only']\n",
    "empty_taxons.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All content with no filtering by taxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intersection of join only\n",
    "allcontent_taxons = allcontent_taxons[allcontent_taxons._merge == 'both']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232526, 24)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allcontent_taxons.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates if both content_id and taxon_id are the same. \n",
    "allcontent_taxons = allcontent_taxons.drop_duplicates(subset = ['content_id', 'taxon_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232149, 24)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allcontent_taxons.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128577"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allcontent_taxons.content_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter by taxon to exclude specific taxons from prediction activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current approach: Take out World and Corporate top taxons   \n",
    "Must consider that the data which we will predict on needs to come from the same population as training data and it is hard to filter the unlabelled data to remove World & Corporate (unless they are perfectly predicted by a meta var such as documnet type). It may be safer to keep them in the training data, predict on all data and act differently if World/Corporate is predicted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4530, 8)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxons.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxons shape after deleting 'World' top taxons: (2028, 8)\n"
     ]
    }
   ],
   "source": [
    "taxons = taxons[taxons.level1taxon != 'World']\n",
    "print(\"Taxons shape after deleting 'World' top taxons: {}\".format(taxons.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxons shape after deleting 'corporate information' top taxons: (2027, 8)\n"
     ]
    }
   ],
   "source": [
    "taxons = taxons[taxons.level1taxon != 'Corporate information']\n",
    "print(\"Taxons shape after deleting 'corporate information' top taxons: {}\".format(taxons.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it possible that corporate information has already been excluded from the taxons file? Need to re-consider this approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_taxons = pd.merge(\n",
    "    left=content, \n",
    "    right=taxons, \n",
    "    left_on='taxon_id', \n",
    "    right_on='content_id', \n",
    "    how='outer', \n",
    "    indicator=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both          229461\n",
      "left_only     106154\n",
      "right_only       105\n",
      "Name: _merge, dtype: int64\n",
      "There are 229461 tagged content items/taxon combinations with a matching taxon\n",
      "There are 106154 content items/taxon combinations without a matching taxon. Are these untagged content?\n",
      "There are 105 /taxons with nothing tagged to them\n"
     ]
    }
   ],
   "source": [
    "print(content_taxons['_merge'].value_counts())\n",
    "print(\"There are {} tagged content items/taxon combinations with a matching taxon\"\n",
    "      .format(content_taxons['_merge'].value_counts()[2]))\n",
    "print(\"There are {} content items/taxon combinations without a matching taxon. Are these untagged content?\"\n",
    "      .format(content_taxons['_merge'].value_counts()[0]))\n",
    "print(\"There are {} /taxons with nothing tagged to them\"\n",
    "      .format(content_taxons['_merge'].value_counts()[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_taxons_notworld=content_old_taxons = content_taxons[['base_path_y', 'content_id_y',\n",
    "       'taxon_name', 'level1taxon', 'level2taxon', 'level3taxon',\n",
    "       'level4taxon', 'level5taxon']][content_taxons._merge == 'right_only']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the left_only content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to add this to untagged data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_old_taxons = content_taxons[['base_path_x', 'content_id_x', 'document_type', 'first_published_at', 'locale',\n",
    "       'primary_publishing_organisation', 'publishing_app', 'title', 'taxon_id']][content_taxons._merge == 'left_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_path_x</th>\n",
       "      <th>content_id_x</th>\n",
       "      <th>document_type</th>\n",
       "      <th>first_published_at</th>\n",
       "      <th>locale</th>\n",
       "      <th>primary_publishing_organisation</th>\n",
       "      <th>publishing_app</th>\n",
       "      <th>title</th>\n",
       "      <th>taxon_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/vehicle-tax</td>\n",
       "      <td>fa748fae-3de4-4266-ae85-0797ada3f40c</td>\n",
       "      <td>transaction</td>\n",
       "      <td>2016-02-29T09:24:10.000+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>publisher</td>\n",
       "      <td>tax your vehicle</td>\n",
       "      <td>948b6dd4-45b3-45ab-a5c6-5dbce75542a6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/check-vehicle-tax</td>\n",
       "      <td>0889f128-e479-465f-b3e1-a3db6a3879cf</td>\n",
       "      <td>transaction</td>\n",
       "      <td>2016-02-29T09:24:10.000+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>publisher</td>\n",
       "      <td>check if a vehicle is taxed</td>\n",
       "      <td>948b6dd4-45b3-45ab-a5c6-5dbce75542a6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/check-mot-history</td>\n",
       "      <td>ad5110e0-fa62-49d3-923f-d50101f12014</td>\n",
       "      <td>transaction</td>\n",
       "      <td>2016-02-29T09:24:10.000+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>publisher</td>\n",
       "      <td>check the mot history of a vehicle</td>\n",
       "      <td>948b6dd4-45b3-45ab-a5c6-5dbce75542a6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/check-mot-status</td>\n",
       "      <td>dc57162b-59f4-4d0f-9b83-a67f74ffccf5</td>\n",
       "      <td>transaction</td>\n",
       "      <td>2016-02-29T09:24:10.000+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>publisher</td>\n",
       "      <td>check the mot status of a vehicle</td>\n",
       "      <td>948b6dd4-45b3-45ab-a5c6-5dbce75542a6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/vehicle-tax-refund</td>\n",
       "      <td>fff88e3b-ae66-43e4-afd0-6fc1f227b452</td>\n",
       "      <td>answer</td>\n",
       "      <td>2016-02-29T09:24:10.000+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>publisher</td>\n",
       "      <td>cancel your vehicle tax and get a refund</td>\n",
       "      <td>948b6dd4-45b3-45ab-a5c6-5dbce75542a6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           base_path_x                          content_id_x document_type  \\\n",
       "0         /vehicle-tax  fa748fae-3de4-4266-ae85-0797ada3f40c   transaction   \n",
       "1   /check-vehicle-tax  0889f128-e479-465f-b3e1-a3db6a3879cf   transaction   \n",
       "2   /check-mot-history  ad5110e0-fa62-49d3-923f-d50101f12014   transaction   \n",
       "3    /check-mot-status  dc57162b-59f4-4d0f-9b83-a67f74ffccf5   transaction   \n",
       "4  /vehicle-tax-refund  fff88e3b-ae66-43e4-afd0-6fc1f227b452        answer   \n",
       "\n",
       "              first_published_at locale primary_publishing_organisation  \\\n",
       "0  2016-02-29T09:24:10.000+00:00     en                             NaN   \n",
       "1  2016-02-29T09:24:10.000+00:00     en                             NaN   \n",
       "2  2016-02-29T09:24:10.000+00:00     en                             NaN   \n",
       "3  2016-02-29T09:24:10.000+00:00     en                             NaN   \n",
       "4  2016-02-29T09:24:10.000+00:00     en                             NaN   \n",
       "\n",
       "  publishing_app                                     title  \\\n",
       "0      publisher                          tax your vehicle   \n",
       "1      publisher               check if a vehicle is taxed   \n",
       "2      publisher        check the mot history of a vehicle   \n",
       "3      publisher         check the mot status of a vehicle   \n",
       "4      publisher  cancel your vehicle tax and get a refund   \n",
       "\n",
       "                               taxon_id  \n",
       "0  948b6dd4-45b3-45ab-a5c6-5dbce75542a6  \n",
       "1  948b6dd4-45b3-45ab-a5c6-5dbce75542a6  \n",
       "2  948b6dd4-45b3-45ab-a5c6-5dbce75542a6  \n",
       "3  948b6dd4-45b3-45ab-a5c6-5dbce75542a6  \n",
       "4  948b6dd4-45b3-45ab-a5c6-5dbce75542a6  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_old_taxons.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2010 taxons represented in the 106154 content item/taxon combinations which have no corresponding taxon in the taxon data\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} taxons represented in the {} content item/taxon combinations which have no corresponding taxon in the taxon data\"\n",
    "      .format(content_old_taxons.taxon_id.nunique(), content_old_taxons.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 content items/taxon combinations with missing taxon because these were removed during taxon_clean.py\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} content items/taxon combinations with missing taxon because these were removed during taxon_clean.py\"\n",
    "      .format(content_old_taxons[content_old_taxons.taxon_id.isnull()].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save out for devs to check reason these do not have a match in taxon file\n",
    "#content_only_taxons.to_csv('../../data/content_with_taxonid_no_matching_taxon.csv', \n",
    "                           #index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('../../data/taxonid_no_matching_taxon.gz', \n",
    "#            content_only_taxons.taxon_id.unique(),fmt='%5s', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devs did some spot checks on these and some of these taxons were not part of the topic taxonomy so did not have a match in the topic taxonomy file. Others are in the World branch of the taxonomy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to add these to untaggedd population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy the content-taxon df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(335720, 24)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_taxons.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tidy columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'base_path_x', 'content_id_x', 'description', 'details',\n",
       "       'document_type', 'first_published_at', 'locale',\n",
       "       'primary_publishing_organisation', 'publishing_app', 'title', 'body',\n",
       "       'combined_text', 'variable', 'taxon_id', 'base_path_y', 'content_id_y',\n",
       "       'taxon_name', 'level1taxon', 'level2taxon', 'level3taxon',\n",
       "       'level4taxon', 'level5taxon', '_merge'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_taxons.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop some cols\n",
    "content_taxons = content_taxons.drop(['Unnamed: 0', 'variable', 'base_path_y', \n",
    "                                      'content_id_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename some cols\n",
    "content_taxons.rename(columns={'base_path_x': 'base_path', \n",
    "                               'content_id_x': 'content_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter content-taxons data:\n",
    "- remove duplicates\n",
    "- remove mismatches from merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 335720 rows in the data before filtering\n",
      "There are 140103 unique content items in the data before filtering\n"
     ]
    }
   ],
   "source": [
    "#count duplicates\n",
    "print(\"There are {} rows in the data before filtering\".\n",
    "      format(content_taxons.shape[0]))\n",
    "print(\"There are {} unique content items in the data before filtering\".\n",
    "      format(content_taxons.content_id.nunique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 229461 rows in the taxon-level data after filtering out mismatches\n",
      "There are 127320 unique content items in the taxon-level data after filtering out mismatches\n",
      "There were 106259 rows dropped because of mismatching\n",
      "There were 12783 unique content items dropped because of mismatching\n"
     ]
    }
   ],
   "source": [
    "# Drop any rows which were not perfectly matched in taxons and content\n",
    "\n",
    "content_taxons_filtered = content_taxons[content_taxons._merge == 'both']\n",
    "\n",
    "print(\"There are {} rows in the taxon-level data after filtering out mismatches\".\n",
    "      format(content_taxons_filtered.shape[0]))\n",
    "print(\"There are {} unique content items in the taxon-level data after filtering out mismatches\".\n",
    "      format(content_taxons_filtered.content_id.nunique()))\n",
    "print(\"There were {} rows dropped because of mismatching\"\n",
    "      .format(content_taxons.shape[0] - content_taxons_filtered.shape[0]))\n",
    "print(\"There were {} unique content items dropped because of mismatching\"\n",
    "      .format(content_taxons.content_id.nunique() - content_taxons_filtered.content_id.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing mismatches, there were 956 duplicates content items, both with matching content_id and taxon_id\n",
      "After removing mismatches, there were 377 duplicates content items, both with matching content_id and taxon_id\n"
     ]
    }
   ],
   "source": [
    "print(\"Before removing mismatches, there were {} duplicates content items, both with matching content_id \"\n",
    "      \"and taxon_id\"\n",
    "      .format(content_taxons[content_taxons.duplicated(['content_id', 'taxon_id'])].shape[0]))\n",
    "print(\"After removing mismatches, there were {} duplicates content items, both with matching \"\n",
    "      \"content_id and taxon_id\"\n",
    "      .format(content_taxons_filtered[content_taxons_filtered.\n",
    "                                      duplicated(['content_id', 'taxon_id'])].shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates\n",
    "content_taxons_dedup = content_taxons_filtered.drop_duplicates(subset = ['content_id', 'taxon_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 377 additional rows dropped due to duplicate content_id/taxon_id combination\n",
      "There were 0 additional content items dropped due to duplicate content_id/taxon_id combination\n"
     ]
    }
   ],
   "source": [
    "print(\"There were {} additional rows dropped due to duplicate content_id/taxon_id combination\"\n",
    "      .format(content_taxons_filtered.shape[0] - content_taxons_dedup.shape[0]))\n",
    "print(\"There were {} additional content items dropped due to duplicate content_id/taxon_id combination\"\n",
    "      .format(content_taxons_filtered.content_id.nunique() - content_taxons_dedup.content_id.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229084, 20)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assert content_taxons_dedup.shape == (2029084, 18)\n",
    "content_taxons_dedup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#content_taxons_dedup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out dataframes for analyses\n",
    "- allcontent_taxons: all deduplicated labelled content with no filtering by taxon\n",
    "- content_taxons_dedup: Deduplicated labelled content without World/Corporate taxons\n",
    "- taxons: cleaner taxons data from that produced by clean_taxons.py\n",
    "- content_old_taxons: content items with a taxon id which is not contained within the topic taxonomy taxons\n",
    "- empty_taxons: Taxons with no content tagged to them, which are not World taxons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcontent_taxons.to_csv('../../data/labelled.csv', index=False)\n",
    "\n",
    "content_taxons_dedup.to_csv('../../data/filtered.csv', index=False)\n",
    "                            \n",
    "taxons.to_csv('../../data/taxons_cleaner.csv', index=False)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_old_taxons.to_csv('../../data/old_tags.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_taxons_notworld.to_csv('../../data/empty_taxons.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "keep_output": true,
  "kernelspec": {
   "display_name": "tax_SL",
   "language": "python",
   "name": "tax_sl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
