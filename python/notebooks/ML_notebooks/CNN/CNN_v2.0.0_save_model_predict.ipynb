{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional NN to classify govuk content to level2 taxons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on:\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load requirements and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.utils import to_categorical, layer_utils, plot_model\n",
    "\n",
    "from keras.layers import (Embedding, Input, Dense, Dropout, \n",
    "                          Activation, Conv1D, MaxPooling1D, Flatten, concatenate, Reshape)\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.callbacks import TensorBoard, Callback, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score \n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import functools\n",
    "\n",
    "import h5py\n",
    "\n",
    "from scipy import sparse\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environmental vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATADIR = os.getenv('DATADIR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print data version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm running on data extracted from content store on /data/2018-03-22\n"
     ]
    }
   ],
   "source": [
    "print('algorithm running on data extracted from content store on {}'.format(DATADIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuition for POS_RATIO is that it penalises the prediction of zero for everything, which is attractive to the model because the multilabel y matrix is super sparse. \n",
    "\n",
    "Increasing POS_RATIO should penalise predicting zeros more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MAX_NB_WORDS\n",
    "MAX_SEQUENCE_LENGTH =1000\n",
    "EMBEDDING_DIM = 100 # keras embedding layer output_dim = Dimension of the dense embedding\n",
    "P_THRESHOLD = 0.5 #Threshold for probability of being assigned to class\n",
    "POS_RATIO = 0.5 #ratio of positive to negative for each class in weighted binary cross entropy loss function\n",
    "NUM_WORDS=20000 #keras tokenizer num_words: None or int. Maximum number of words to work with \n",
    "#(if set, tokenization will be restricted to the top num_words most common words in the dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = np.load(os.path.join(DATADIR, 'train_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'meta', 'title', 'desc', 'y', 'content_id']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (178688, 1000)\n",
      "meta_train.shape = (178688, 529)\n",
      "title_train.shape = (178688, 10000)\n",
      "desc_train.shape = (178688, 10000)\n",
      "y_train.shape = (178688, 217)\n"
     ]
    }
   ],
   "source": [
    "x_train = train['x']\n",
    "meta_train = train['meta'].all().todense()\n",
    "title_train = train['title'].all().todense()\n",
    "desc_train = train['desc'].all().todense()\n",
    "y_train = train['y'].all().todense()\n",
    "\n",
    "print('x_train.shape = {}'.format(x_train.shape))\n",
    "print('meta_train.shape = {}'.format(meta_train.shape))\n",
    "print('title_train.shape = {}'.format(title_train.shape))\n",
    "print('desc_train.shape = {}'.format(desc_train.shape))\n",
    "print('y_train.shape = {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dev = np.load(os.path.join(DATADIR, 'dev_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_dev.shape = (12961, 1000)\n",
      "meta_dev.shape = (12961, 529)\n",
      "title_dev.shape = (12961, 10000)\n",
      "desc_dev.shape = (12961, 10000)\n",
      "y_dev.shape = (12961, 217)\n"
     ]
    }
   ],
   "source": [
    "x_dev = dev['x']\n",
    "meta_dev = dev['meta'].all().todense()\n",
    "title_dev = dev['title'].all().todense()\n",
    "desc_dev = dev['desc'].all().todense()\n",
    "y_dev = dev['y'].all().todense()\n",
    "\n",
    "print('x_dev.shape = {}'.format(x_dev.shape))\n",
    "print('meta_dev.shape = {}'.format(meta_dev.shape))\n",
    "print('title_dev.shape = {}'.format(title_dev.shape))\n",
    "print('desc_dev.shape = {}'.format(desc_dev.shape))\n",
    "print('y_dev.shape = {}'.format(y_dev.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = np.load(os.path.join(DATADIR, 'test_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test.shape = (12962, 1000)\n",
      "meta_test.shape = (12962, 529)\n",
      "title_test.shape = (12962, 10000)\n",
      "desc_test.shape = (12962, 10000)\n",
      "y_test.shape = (12962, 217)\n"
     ]
    }
   ],
   "source": [
    "x_test = test['x']\n",
    "meta_test = test['meta'].all().todense()\n",
    "title_test = test['title'].all().todense()\n",
    "desc_test = test['desc'].all().todense()\n",
    "y_test = test['y'].all().todense()\n",
    "\n",
    "print('x_test.shape = {}'.format(x_test.shape))\n",
    "print('meta_test.shape = {}'.format(meta_test.shape))\n",
    "print('title_test.shape = {}'.format(title_test.shape))\n",
    "print('desc_test.shape = {}'.format(desc_test.shape))\n",
    "print('y_test.shape = {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### previous shapes in old data \n",
    "Shape of x_train: (150870, 1000)\n",
    "Shape of metax_train: (150870, 436)\n",
    "Shape of titlex_train: (150870, 10000)\n",
    "Shape of descx_train: (150870, 10000)\n",
    "Shape of y_train: (150870, 210)\n",
    "\n",
    "Shape of x_dev: (9234, 1000)\n",
    "Shape of meta_dev: (9234, 436)\n",
    "Shape of titlex_dev: (9234, 10000)\n",
    "Shape of descx_dev: (9234, 10000)\n",
    "Shape of y_dev: (9234, 210)\n",
    "\n",
    "Shape of x_test: (9234, 1000)\n",
    "Shape of metax_test: (9234, 436)\n",
    "Shape of titlex_test: (9234, 10000)\n",
    "Shape of descx_test: (9234, 10000)\n",
    "Shape of y_test: (9234, 210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing the Embedding layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "def load_tokenizer_from_file(filename):\n",
    "    \n",
    "    tokenizer = Tokenizer()\n",
    "\n",
    "    with open(filename, 'r') as infile:\n",
    "        tokenizer_data = json.load(infile)\n",
    "\n",
    "    tokenizer.word_counts = OrderedDict(tokenizer_data['word_counts'])\n",
    "    tokenizer.word_docs = tokenizer_data['word_docs']\n",
    "    tokenizer.word_index = tokenizer_data['word_index']\n",
    "    tokenizer.document_count = tokenizer_data['document_count']\n",
    "    tokenizer.index_docs = tokenizer_data['index_docs']\n",
    "\n",
    "    return tokenizer\n",
    "\n",
    "tokenizer_combined_text = load_tokenizer_from_file(os.path.join(DATADIR, \"combined_text_tokenizer.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(tokenizer_combined_text.word_index) + 1, \n",
    "                            EMBEDDING_DIM, \n",
    "                            input_length=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Embedding layer should be fed sequences of integers, i.e. a 2D input of shape (samples, indices). These input sequences should be padded so that they all have the same length in a batch of input data (although an Embedding layer is capable of processing sequence of heterogenous length, if you don't pass an explicit input_length argument to the layer).\n",
    "\n",
    "All that the Embedding layer does is to map the integer inputs to the vectors found at the corresponding index in the embedding matrix, i.e. the sequence [1, 2] would be converted to [embeddings[1], embeddings[2]]. This means that the output of the Embedding layer will be a 3D tensor of shape (samples, sequence_length, embedding_dim)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate class weights for unbalanced datasets.\n",
    "paramter to model.fit = __class_weight__: Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
    "\n",
    "Implement class_weight from sklearn:\n",
    "\n",
    "- Import the module \n",
    "\n",
    "`from sklearn.utils import class_weight`\n",
    "- calculate the class weight, If ‘balanced’, class weights will be given by n_samples / (n_classes * np.bincount(y)):\n",
    "\n",
    "`class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)`\n",
    "\n",
    "- change it to a dict in order to work with Keras.\n",
    "\n",
    "`class_weight_dict = dict(enumerate(class_weight))`\n",
    "\n",
    "- Add to model fitting\n",
    "\n",
    "`model.fit(X_train, y_train, class_weight=class_weight)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "# class_weight_dict = dict(enumerate(class_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.00756\n",
      "8.01512\n"
     ]
    }
   ],
   "source": [
    "class WeightedBinaryCrossEntropy(object):\n",
    "\n",
    "    def __init__(self, pos_ratio):\n",
    "        neg_ratio = 1. - pos_ratio\n",
    "        #self.pos_ratio = tf.constant(pos_ratio, tf.float32)\n",
    "        self.pos_ratio = pos_ratio\n",
    "        #self.weights = tf.constant(neg_ratio / pos_ratio, tf.float32)\n",
    "        self.weights = neg_ratio / pos_ratio\n",
    "        self.__name__ = \"weighted_binary_crossentropy({0})\".format(pos_ratio)\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        return self.weighted_binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "    def weighted_binary_crossentropy(self, y_true, y_pred):\n",
    "            # Transform to logits\n",
    "            epsilon = tf.convert_to_tensor(K.common._EPSILON, y_pred.dtype.base_dtype)\n",
    "            y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
    "            y_pred = tf.log(y_pred / (1 - y_pred))\n",
    "\n",
    "            cost = tf.nn.weighted_cross_entropy_with_logits(y_true, y_pred, self.weights)\n",
    "            return K.mean(cost * self.pos_ratio, axis=-1)\n",
    "    \n",
    "y_true_arr = np.array([0,1,0,1], dtype=\"float32\")\n",
    "y_pred_arr = np.array([0,0,1,1], dtype=\"float32\")\n",
    "y_true = tf.constant(y_true_arr)\n",
    "y_pred = tf.constant(y_pred_arr)\n",
    "\n",
    "with tf.Session().as_default(): \n",
    "    print(WeightedBinaryCrossEntropy(0.5)(y_true, y_pred).eval())\n",
    "    print(binary_crossentropy(y_true, y_pred).eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### difficulty getting global precision/recall metrics . CAUTION interpreting monitoring metrics\n",
    "fcholltet: \"Basically these are all global metrics that were approximated\n",
    "batch-wise, which is more misleading than helpful. This was mentioned in\n",
    "the docs but it's much cleaner to remove them altogether. It was a mistake\n",
    "to merge them in the first place.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    \"\"\"Use Recall  and precision metrics to calculate harmonic mean (F1 score).\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1 = 2*((precision*recall)/(precision+recall))\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a 1D convnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NB_CLASSES = y_train.shape[1]\n",
    "NB_METAVARS = meta_train.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='wordindex') #MAX_SEQUENCE_LENGTH\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Dropout(0.2, name = 'dropout_embedded')(embedded_sequences)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv0')(x)\n",
    "\n",
    "x = MaxPooling1D(5, name = 'max_pool0')(x)\n",
    "\n",
    "x = Dropout(0.5, name = 'dropout0')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv1')(x)\n",
    "\n",
    "x = MaxPooling1D(5 , name = 'max_pool1')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv2')(x)\n",
    "\n",
    "x = MaxPooling1D(35, name = 'global_max_pool')(x)  # global max pooling\n",
    "\n",
    "x = Flatten()(x) #reduce dimensions from 3 to 2; convert to vector + FULLYCONNECTED\n",
    "\n",
    "meta_input = Input(shape=(NB_METAVARS,), name='meta')\n",
    "meta_hidden = Dense(128, activation='relu', name = 'hidden_meta')(meta_input)\n",
    "meta_hidden = Dropout(0.2, name = 'dropout_meta')(meta_hidden)\n",
    "\n",
    "\n",
    "title_input = Input(shape=(title_train.shape[1],), name='titles')\n",
    "title_hidden = Dense(128, activation='relu', name = 'hidden_title')(title_input)\n",
    "title_hidden = Dropout(0.2, name = 'dropout_title')(title_hidden)\n",
    "\n",
    "desc_input = Input(shape=(desc_train.shape[1],), name='descs')\n",
    "desc_hidden = Dense(128, activation='relu', name = 'hidden_desc')(desc_input)\n",
    "desc_hidden = Dropout(0.2, name = 'dropout_desc')(desc_hidden)\n",
    "\n",
    "concatenated = concatenate([meta_hidden, title_hidden, desc_hidden, x])\n",
    "\n",
    "x = Dense(400, activation='relu', name = 'fully_connected0')(concatenated)\n",
    "\n",
    "x = Dropout(0.2, name = 'dropout1')(x)\n",
    "\n",
    "x = Dense(NB_CLASSES, activation='sigmoid', name = 'fully_connected1')(x)\n",
    "\n",
    "# # The Model class turns an input tensor and output tensor into a model\n",
    "# This creates Keras model instance, will use this instance to train/test the model.\n",
    "model = Model(inputs=[meta_input, title_input, desc_input, sequence_input], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "wordindex (InputLayer)          (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 100)    34893500    wordindex[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_embedded (Dropout)      (None, 1000, 100)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv1D)                  (None, 996, 128)     64128       dropout_embedded[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pool0 (MaxPooling1D)        (None, 199, 128)     0           conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout0 (Dropout)              (None, 199, 128)     0           max_pool0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv1D)                  (None, 195, 128)     82048       dropout0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pool1 (MaxPooling1D)        (None, 39, 128)      0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "meta (InputLayer)               (None, 529)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "titles (InputLayer)             (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "descs (InputLayer)              (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv1D)                  (None, 35, 128)      82048       max_pool1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hidden_meta (Dense)             (None, 128)          67840       meta[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "hidden_title (Dense)            (None, 128)          1280128     titles[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "hidden_desc (Dense)             (None, 128)          1280128     descs[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pool (MaxPooling1D)  (None, 1, 128)       0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_meta (Dropout)          (None, 128)          0           hidden_meta[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_title (Dropout)         (None, 128)          0           hidden_title[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_desc (Dropout)          (None, 128)          0           hidden_desc[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           global_max_pool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           dropout_meta[0][0]               \n",
      "                                                                 dropout_title[0][0]              \n",
      "                                                                 dropout_desc[0][0]               \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fully_connected0 (Dense)        (None, 400)          205200      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 400)          0           fully_connected0[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fully_connected1 (Dense)        (None, 216)          86616       dropout1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 38,042,037\n",
      "Trainable params: 38,042,037\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard callbacks /metrics /monitor training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **Size of these files is killing storage during training. Is it histograms?**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tb = TensorBoard(log_dir='./learn_embedding_logs', histogram_freq=1, write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = os.path.join(DATADIR, 'model_checkpoint.hdf5')\n",
    "\n",
    "cp = ModelCheckpoint(\n",
    "                     filepath = CHECKPOINT_PATH, \n",
    "                     monitor='val_loss', \n",
    "                     verbose=0, \n",
    "                     save_best_only=False, \n",
    "                     save_weights_only=False, \n",
    "                     mode='auto', \n",
    "                     period=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "#model.fit(x, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 & 3. Train & compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 178688 samples, validate on 12961 samples\n",
      "Epoch 1/10\n",
      "178688/178688 [==============================] - 188s 1ms/step - loss: 0.0086 - binary_accuracy: 0.9951 - f1: nan - val_loss: 0.0040 - val_binary_accuracy: 0.9973 - val_f1: 0.7767\n",
      "Epoch 2/10\n",
      "178688/178688 [==============================] - 183s 1ms/step - loss: 0.0030 - binary_accuracy: 0.9980 - f1: 0.8666 - val_loss: 0.0036 - val_binary_accuracy: 0.9976 - val_f1: 0.8072\n",
      "Epoch 3/10\n",
      "178688/178688 [==============================] - 183s 1ms/step - loss: 0.0023 - binary_accuracy: 0.9985 - f1: 0.9005 - val_loss: 0.0034 - val_binary_accuracy: 0.9977 - val_f1: 0.8158\n",
      "Epoch 4/10\n",
      "178688/178688 [==============================] - 183s 1ms/step - loss: 0.0019 - binary_accuracy: 0.9987 - f1: 0.9173 - val_loss: 0.0033 - val_binary_accuracy: 0.9978 - val_f1: 0.8271\n",
      "Epoch 5/10\n",
      "178688/178688 [==============================] - 183s 1ms/step - loss: 0.0017 - binary_accuracy: 0.9989 - f1: 0.9267 - val_loss: 0.0034 - val_binary_accuracy: 0.9978 - val_f1: 0.8284\n",
      "Epoch 6/10\n",
      "178688/178688 [==============================] - 183s 1ms/step - loss: 0.0016 - binary_accuracy: 0.9990 - f1: 0.9326 - val_loss: 0.0037 - val_binary_accuracy: 0.9979 - val_f1: 0.8296\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=WeightedBinaryCrossEntropy(POS_RATIO),\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['binary_accuracy', f1])\n",
    "\n",
    "# This `fit` call will be distributed on 8 GPUs.\n",
    "# Since the batch size is 256, each GPU will process 32 samples.\n",
    "history = model.fit(\n",
    "    {'meta': meta_train, 'titles': title_train, 'descs': desc_train, 'wordindex': x_train},\n",
    "    y_train, \n",
    "    validation_data=([meta_dev, title_dev, desc_dev, x_dev], y_dev), \n",
    "    epochs=10, batch_size=128, callbacks=[early_stopping]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_binary_accuracy', 'val_f1', 'loss', 'binary_accuracy', 'f1'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDsIWsiOWPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fca0df462e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(range(len(loss_values)), loss_values, 'bo', label='Training loss')           \n",
    "plt.plot(range(len(val_loss_values)), val_loss_values, 'b', label='Validation loss')      \n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XucVXW9//HXG+QiIKBAqYwIqSUX\nEXBESQmNNPScJM2jIGZYRppaWR7DLPNQlr/ymFkeDTtqKsnxWBqVZh7FFK8MKiigQYrIJUS8IiqC\nn98f3zWwGWdmD7DX7Lm8n4/Hfux1+a61P2vvmf3Z3+93re9SRGBmZlafNuUOwMzMmj4nCzMzK8rJ\nwszMinKyMDOzopwszMysKCcLMzMrysmimZDUVtJaSX1KWbacJO0tqeTnbkv6lKQlBfPPShrZkLLb\n8Fq/lvSdbd2+nv3+UNL1pd5vLa+zVZ9BXp9ZLa+zTNJhdazrJOnPkl6XdHMjxJLLZ9zc7FDuAFoq\nSWsLZjsB7wIbs/mvRMS0rdlfRGwEupS6bGsQER8rxX4knQacHBGHFez7tFLsu5Rqi7OFORHYBegR\nERsk9QauBiqBXYE9ImJZqV6sKX7G5eCaRU4iokv1A1gKfKZg2QcShSQnbrOG2RN4NiI2ZPPvA3cA\nx5cvpC1JaiOpRX2/tqiDaU6yZob/kXSzpDeBkyWNkPSIpNckrZR0haR2WfkdJIWkvtn8Tdn6OyW9\nKelhSf22tmy2/ihJf8+q9b+Q9KCkiXXE3ZAYvyJpsaRXJV1RsG1bST+TtEbSc8CYet6fCyRNr7Hs\nSkmXZdOnSVqYHc8/sl/Tde1rU5NG1oRxYxbbfOCAGmW/K+m5bL/zJR2TLd8P+CUwMmvie7ngvb2o\nYPvTs2NfI+l2Sbs15L2pw46S/jeLpSqLYVvj7JS990uzz/l+SR0K9ndK9j6tljS5SFyF71d3Sddl\nfwvLJE3Jvih3lPSGpH0Lyu4q6W1JPbL5YyTNzf6WZkka1IDXuxj4DjAhO74vRMTKiLgKmNPAmE+T\n9Lfsb/e17PM4SNKXJL0oaZWkkwvK1/yMj5P0ZHZ8iyUdmS2fJekHkh4G3gL6SKqQ9CdJr0haJOmL\nDXtnm6CI8CPnB7AE+FSNZT8E1gOfISXtHYEDgYNIzYMfAf4OnJWV3wEIoG82fxPwMqnq3Q74H+Cm\nbSj7IeBNYGy27pvAe8DEOo6lITH+AegG9AVeqT524CxgPlAB9ADuT3+Ctb7OR4C1QOeCfb8EVGbz\nn8nKCPgk8DYwOFv3KWBJwb6WAYdl05cC9wE7k36hLqhR9gRgt+wzOSmL4cPZutOA+2rEeRNwUTZ9\nZBbjEKAj8F/AvQ15b2o5/h9mn8Ox2ecyGVgM7LCNcf4KuCfbpi1waLbfvbO4rs5iHkZqMt2njrj2\nLvzMgD9mx9kJ+DDpC/tL2bobgP8oKPt14E8Ff0ersue2wBeBfwDta35mdbw319eyvGN2LBVF/h9P\ny97bz2evfQnwAnAF0AE4Gngd6FTLZ/xx4DVgdPbe7wF8LFs3i/S/3j97b3cAHgR+UfDevgyMKvd3\n0jZ9j5U7gNbwoO5kcW+R7c4F/jebri0BXF1Q9hjg6W0o+0XggYJ1AlZSR7JoYIwHF6z/PXBuNn0/\ncFrBuqOpI1lk6x8BTsqmjyI1PdRV9k/Amdl0fcliaeFnAXy1sGwt+30a+Jdsuliy+A3wo4J1XUn9\nVBXF3ptaXveHwKyC+bakRDRia+PMtn0XGFjLdtXJYteCZY8Dx9fxOpuSBdCblKQ7FKz/PHB3Nj0G\n+HvBukcLPs9rgO/X2Pc/gENqfmZ1vDfX17J8a5LFwoL5odl2PQqWvQ4MquUz/m/gp3XsdxZwYcF8\nP1JS6lyw7KfArxvyv9XUHm6GKq8XC2ck7at0lsc/Jb0BTAF61rP9Pwum11F/p3ZdZXcvjCP7Fqiz\nc7CBMTbotUi/5urzW2B8Nn1SNl8dx79KejSr3r9G+lVf33tVbbf6YpA0saBp5DVg3wbuF9Lxbdpf\nRLwBvEr6Uq22NZ9Z4eeyEVievcbWxvlhoD3py7hWEfGBuLT5rLrqx+41NtuT9Et8VUEcV2avB/B/\nQHdJB0jaCxhAqllVb/vt6u2ybXdjy/dqu0k6rCD+uQWrVhVMvw1sjIg1NZbV9tnsQT3vI1v+be0O\nvBwRbxUse4ESH2NjcbIor5qnIP6K9Atx74joClxI+qWfp5WkX74ASBL1/zFvT4wrSf9s1Yqd2nsL\n8Cmls13GkiULSTsCtwI/JjW9dAf+2sA4/llXDJI+AlwFnEH6ldkdeKZgv8VOGV1B+hKs3t9OpOau\n5Q2Iqzab4lTqLO0NrNiGOFeRmjz32poXj4iNUXCiRkSsqFHkRVJi2SUiumePrhExONt+A/C/pIR/\nEjCj4IvzRVITVfeCR6eIuGVrYmzAMdxXEP/+Jdjli9T/Pha+9yuAnpI6Fyzrw7b/PZSVk0XTshOp\n+vuWpP7AVxrhNf8EDJP0GaUzsr4O9MopxluAb0jqnXVyfru+wtmv3VnA9aQmqEXZqg6kX8qrgY2S\n/pXUhtzQGL6Tdcz2IfWjVOtC+mdfTcqbXyb9Yq+2CqhQ1qFfi5uBL0kanHUe/5jUxLetp3EOlzQ2\ne71zSX1Ls7c2zqxWcj1wedbJ3FbSIfUcR4NExIvA34BLJXXNOrb3lvSJgmK/JZ3qukXNkNQMdaak\nA5V0yf4GC79YG0xSR9LfBUAHFXTel9h/A6dJOjw73gpJtZ6aHRHPA1XAjyR1kDQEOJXUrNXsOFk0\nLd8CvkD6UvgVqSM6VxGxivTPfBmwhvSr6QlSG3epY7yK1Mn6FOlL79YGbPNbUh/Epi+aiHgNOAe4\njdRJfDwp6TXE90k1nCXAnaRO2Or9ziN1Rj6WlfkYqZ292t3AIlKzS2GzTfX2fyE1y92Wbd8HmNDA\nuGpzG3Ay6RhPBI6LiA3bGOc5wEJSB/QrwI8oTa31ZKAz6USBV0k1iV0L1j8EbCD9APlr9cKIeIRU\nM7oq2+7v2b62WvYj521SxzOkEwHeqnuLbRcRDwFfJnWGvw7MZMuaak0nAvuQarS3At+JiPvyiC1v\nyjpdzIB0eiup+nx8RDxQ7njMrGlwzcKQNCZrlukAfI90BsdjZQ7LzJoQJwuDdM79c6Q28E8Dx0ZE\nXc1QZtYK5doMJWkM8HPSed6/johLaqzfE7iW1J75Cmk8m2UF67uS2kJvj4jCjkgzM2tEudUssrbv\nK0kXUw0AxksaUKPYpcAN2al2U0hnjxT6AelCLjMzK6M8B68bDiyOiOcAlMb5GUuqKVQbQBpeAtJZ\nBbdXr5B0AOninr+QhqmoV8+ePaNv374lCdzMrLWYM2fOyxFR3+nyQL7JojdbXs24jDSmUKG5wHGk\npqpjgZ2y8+9fBf6TdCrdp+p6AUmTgEkAffr0oaqqqmTBm5m1BpKKjaQAlL+D+1xglKQngFGkKxs3\nksbruaPYxUwRMTUiKiOislevoonRzMy2UZ41i+VsebFKBTUuc8+GDzgOQFIX4HMR8ZqkEaQhlr9K\nulq1vaS1EdHgoZPNzKx08kwWs4F9lO6bsBwYR7rkfxNJPYFXIuJ94HzSmVFExISCMhNJw1I7UZiZ\nlUluySLS7Q7PAu4inTp7bUTMlzQFqIqIGcBhwI+V7ul7P3BmKWN47733WLZsGe+8804pd2vboGPH\njlRUVNCu3XYNR2RmZdJihvuorKyMmh3czz//PDvttBM9evQgDaZq5RARrFmzhjfffJN+/foV38DM\nGo2kORFR9IzTcndw5+qdd95xomgCJNGjRw/X8MxKbNo06NsX2rRJz9Om5fdaefZZNAlOFE2DPwez\n0po2DSZNgnXr0vwLL6R5gAnbM9ZxHVp0zcLMrKW64ILNiaLaunVpeR6cLHK0Zs0ahgwZwpAhQ9h1\n113p3bv3pvn169c3aB+nnnoqzz77bL1lrrzySqaVqP553333MXDgwE0xfvrTn6Z79+589rOfLcn+\nzaw0li7duuXbq8U3Q22NadNSVl66FPr0gYsv3r7qXI8ePXjyyScBuOiii+jSpQvnnnvuFmU23Qy9\nTe15+7rrriv6OmeeWbqTyG666Sa+973vMW7cOCKC8847jzfffJPrr7++ZK9hZtuvT5/U9FTb8jy4\nZpGpbv974QWI2Nz+l0eH0eLFixkwYAATJkxg4MCBrFy5kkmTJlFZWcnAgQOZMmXKprKHHnooTz75\nJBs2bKB79+5MnjyZ/fffnxEjRvDSSy8B8N3vfpfLL798U/nJkyczfPhwPvaxj/HQQw8B8NZbb/G5\nz32OAQMGcPzxx1NZWbkpkVW7+uqr+f3vf8/555/PKaecgiRGjx5Nly613bfezMrp4ouhU6ctl3Xq\nlJbnwcki09jtf8888wznnHMOCxYsoHfv3lxyySVUVVUxd+5c7r77bhYsWPCBbV5//XVGjRrF3Llz\nGTFiBNdee22t+44IHnvsMX76059uSjy/+MUv2HXXXVmwYAHf+973eOKJJz6w3emnn87RRx/Nz372\nM2644YYPrDezpmPCBJg6FfbcE6T0PHVqPp3b4GSxSWO3/+21115UVm4+tfnmm29m2LBhDBs2jIUL\nF9aaLHbccUeOOuooAA444ACWLFlS676PO+64D5SZNWsW48aNA2D//fdn4MCBJTwaMyuHCRNgyRJ4\n//30nFeiACeLTepq58ur/a9z586bphctWsTPf/5z7r33XubNm8eYMWNqvSahffv2m6bbtm3Lhg0b\nat13hw4dipYxa2ka85qD1sjJItPY7X+F3njjDXbaaSe6du3KypUrueuuu0r+Gocccgi33HILAE89\n9VStNRez5qox+xxbK58NlamuvpXybKiGGjZsGAMGDGDfffdlzz335JBDDin5a5x99tmccsopDBgw\nYNOjW7duRbcbMWIEixcvZu3atVRUVPCb3/yG0aNHlzw+s+1RX59jY/wPtwYtemyohQsX0r9//zJF\n1LRs2LCBDRs20LFjRxYtWsSRRx7JokWL2GGHxvu94M/D8tKmTapR1CSl9nyrW0PHhnLNopVYu3Yt\no0ePZsOGDUQEv/rVrxo1UZjlqbGvOWiN/G3RSnTv3p05c+aUOwyzXFx88ZbjJEHj9Tm2Fu7gNrNm\nr7GvOWiNXLMwsxZhwgQnhzzlWrOQNEbSs5IWS/rAbVEl7SnpHknzJN0nqSJbPkTSw5LmZ+tOzDNO\nMzOrX27JQlJb4ErgKGAAMF7SgBrFLgVuiIjBwBTgx9nydcApETEQGANcLql7XrGamVn98qxZDAcW\nR8RzEbEemA6MrVFmAHBvNj2zen1E/D0iFmXTK4CXgF45xpqLww8//AMX2F1++eWcccYZ9W5XPXDf\nihUrOP7442stc9hhh1HzVOGaLr/8ctYV9PgdffTRvPbaaw0JvV6rV6/moIMOYujQoTzwwANccMEF\n7LHHHh5w0KwFyzNZ9AZeLJhfli0rNBc4Lps+FthJUo/CApKGA+2Bf9R8AUmTJFVJqlq9enXJAi+V\n8ePHM3369C2WTZ8+nfHjxzdo+913351bb711m1+/ZrK444476N59+yto99xzD/vttx9PPPEEI0eO\n5DOf+QyPPfbYdu/XzJqucp8NdS4wStITwChgObCxeqWk3YAbgVMj4gOX1kTE1IiojIjKXr2aXsXj\n+OOP589//vOmGx0tWbKEFStWMHLkyE3XPQwbNoz99tuPP/zhDx/YfsmSJQwaNAiAt99+m3HjxtG/\nf3+OPfZY3n777U3lzjjjjE3Dm3//+98H4IorrmDFihUcfvjhHH744QD07duXl19+GYDLLruMQYMG\nMWjQoE3Dmy9ZsoT+/fvz5S9/mYEDB3LkkUdu8ToATz75JOeddx5/+MMfGDJkCG+//TYHH3wwu+22\nW4nfPdseHifJSi3Ps6GWA3sUzFdkyzbJmpiOA5DUBfhcRLyWzXcF/gxcEBGPbG8w3/gG1Lh9w3Yb\nMgSy79la7bLLLgwfPpw777yTsWPHMn36dE444QQk0bFjR2677Ta6du3Kyy+/zMEHH8wxxxxT572q\nr7rqKjp16sTChQuZN28ew4YN27Tu4osvZpdddmHjxo2MHj2aefPm8bWvfY3LLruMmTNn0rNnzy32\nNWfOHK677joeffRRIoKDDjqIUaNGsfPOO7No0SJuvvlmrrnmGk444QR+97vfcfLJJxcc8xCmTJlC\nVVUVv/zlL7fvDbRcNPa9ma11yLNmMRvYR1I/Se2BccCMwgKSekqqjuF84NpseXvgNlLn97a3wzQB\nhU1RhU1QEcF3vvMdBg8ezKc+9SmWL1/OqlWr6tzP/fffv+lLe/DgwQwePHjTultuuYVhw4YxdOhQ\n5s+fX3SQwFmzZnHsscfSuXNnunTpwnHHHccDDzwAQL9+/RgyZAhQ/zDo1nQ19r1ZrHXIrWYRERsk\nnQXcBbQFro2I+ZKmAFURMQM4DPixpADuB6rvD3oC8Amgh6SJ2bKJEbHNdYP6agB5Gjt2LOeccw6P\nP/4469at44ADDgBg2rRprF69mjlz5tCuXTv69u1b67DkxTz//PNceumlzJ49m5133pmJEydu036q\nVQ9vDmmI85rNUNb0Nfa9Wax1yLXPIiLuiIiPRsReEXFxtuzCLFEQEbdGxD5ZmdMi4t1s+U0R0S4i\nhhQ8StyI1Di6dOnC4Ycfzhe/+MUtOrZff/11PvShD9GuXTtmzpzJC7UNbFPgE5/4BL/97W8BePrp\np5k3bx6Qhjfv3Lkz3bp1Y9WqVdx5552bttlpp5148803P7CvkSNHcvvtt7Nu3TreeustbrvtNkaO\nHFmKw7UmoLHvzWKtQ7k7uFuF8ePHM3fu3C2SxYQJE6iqqmK//fbjhhtuYN999613H2eccQZr166l\nf//+XHjhhZtqKPvvvz9Dhw5l33335aSTTtpiePNJkyYxZsyYTR3c1YYNG8bEiRMZPnw4Bx10EKed\ndhpDhw7d5uM777zzqKioYN26dVRUVHDRRRdt875s+5Xz3izWcnmIcms0/jwaz7Rp5bk3izU/HqLc\nrBXzOElWam6GMjOzolp8smgpzWzNnT8Hs+atRSeLjh07smbNGn9RlVlEsGbNGjp27FjuUMxsG7Xo\nPouKigqWLVtGUxw3qrXp2LEjFRUV5Q7DzLZRi04W7dq1o1+/fuUOw8ys2WvRzVBmZlYaThZmZlaU\nk4WZmRXlZGFmZkU5WZiZWVFOFmZmVpSThZmZFeVkYWZmReWaLCSNkfSspMWSJteyfk9J90iaJ+k+\nSRUF674gaVH2+EKecVrLNm0a9O0Lbdqk52nTyh2RWfOTW7KQ1Ba4EjgKGACMlzSgRrFLSffZHgxM\nAX6cbbsL8H3gIGA48H1JO+cVq7Vc06bBpEnwwgsQkZ4nTXLCMNtaedYshgOLI+K5iFgPTAfG1igz\nALg3m55ZsP7TwN0R8UpEvArcDYzJMVZroS64ANat23LZunVpuZk1XJ7JojfwYsH8smxZobnAcdn0\nscBOkno0cFuzopYu3brlZla7cndwnwuMkvQEMApYDmxs6MaSJkmqklTlkWWtNn36bN1yM6tdnsli\nObBHwXxFtmyTiFgREcdFxFDggmzZaw3ZNis7NSIqI6KyV69epY7fWoCLL4ZOnbZc1qlTWm5mDZdn\nspgN7COpn6T2wDhgRmEBST0lVcdwPnBtNn0XcKSknbOO7SOzZWZbZcIEmDoV9twTpPQ8darvT222\ntXK7n0VEbJB0FulLvi1wbUTMlzQFqIqIGcBhwI8lBXA/cGa27SuSfkBKOABTIuKVvGK1lm3CBCcH\ns+2llnLL0crKyqiqqip3GGZmzYqkORFRWaxcuTu4zcysGXCyMDOzopwszMysKCcLMzMrysnCzMyK\ncrIwM7OinCzMzKwoJwszMyvKycLMzIpysjAzs6KcLMzMrCgnCzMzK8rJwszMinKyMDOzopwszMys\nKCcLMzMrysnCzMyKyjVZSBoj6VlJiyVNrmV9H0kzJT0haZ6ko7Pl7ST9RtJTkhZKOj/POM3MrH65\nJQtJbYErgaOAAcB4SQNqFPsucEtEDAXGAf+VLf83oENE7AccAHxFUt+8YjUzs/rlWbMYDiyOiOci\nYj0wHRhbo0wAXbPpbsCKguWdJe0A7AisB97IMVYzM6tHnsmiN/BiwfyybFmhi4CTJS0D7gDOzpbf\nCrwFrASWApdGxCs1X0DSJElVkqpWr15d4vDNzKxauTu4xwPXR0QFcDRwo6Q2pFrJRmB3oB/wLUkf\nqblxREyNiMqIqOzVq1djxm1m1qrkmSyWA3sUzFdkywp9CbgFICIeBjoCPYGTgL9ExHsR8RLwIFCZ\nY6xmZlaPPJPFbGAfSf0ktSd1YM+oUWYpMBpAUn9SslidLf9ktrwzcDDwTI6xmplZPXJLFhGxATgL\nuAtYSDrrab6kKZKOyYp9C/iypLnAzcDEiAjSWVRdJM0nJZ3rImJeXrGamVn9lL6bm7/Kysqoqqoq\ndxhmZs2KpDkRUbSZv9wd3GZm1gw4WZiZWVFOFmZmVpSThZmZFeVkYWZmRTlZmJlZUU4WZmZW1A4N\nLSjpw8CB2exj2TAcZmbWCjSoZiHpBOAx0n0mTgAelXR8noFZfqZNg759oU2b9DxtWrkjMrOmrqE1\niwuAA6trE5J6Af9HGkrcmpFp02DSJFi3Ls2/8EKaB5gwoXxxmVnT1tA+izY1mp3WbMW21oRccMHm\nRFFt3bq03MysLg2tWfxF0l2kwf4ATiTdrMiamaVLt265mRk0MFlExL9LOg44NFs0NSJuyy8sy0uf\nPqnpqbblZmZ1KZosJLUF/i8iDgd+n39IlqeLL96yzwKgU6e03MysLkX7HSJiI/C+pG6NEI/lbMIE\nmDoV9twTpPQ8dao7t82sfg3ts1gLPCXpbuCt6oUR8bVcorJcTZjg5GBmW6ehyeL3bEMTlKQxwM+B\ntsCvI+KSGuv7AL8BumdlJkfEHdm6wcCvgK7A+6RTd9/Z2hjMzGz7NTRZ3Aq8kzVJVfdjdKhvg6zM\nlcARwDJgtqQZEbGgoNh3SbdbvUrSANIZVn0l7QDcBHw+IuZK6gG8tzUHZmZmpdPQayXuAXYsmN+R\ndFFefYYDiyPiuYhYD0wHxtYoE6SaA0A3YEU2fSQwLyLmAkTEmupEZWZmja+hyaJjRKytnsmmOxXZ\npjfwYsH8smxZoYuAkyUtI9Uqzs6WfxQISXdJelzSebW9gKRJkqokVa1evbqBh2JmZlurocniLUnD\nqmckHQC8XYLXHw9cHxEVwNHAjZLakJrHDgUmZM/HShpdc+OImBoRlRFR2atXrxKEY2ZmtWlon8U3\ngP+VtAIQsCvpKu76LAf2KJivyJYV+hIwBiAiHpbUEehJqoXcHxEvA0i6AxhGag4zM7NG1qCaRUTM\nBvYFzgBOB/pHxJwim80G9pHUT1J7YBwwo0aZpcBoAEn9gY7AauAuYD9JnbLO7lHAAszMrCzqrVlI\n+mRE3JsN9VHoo5KIiDpPp42IDZLOIn3xtwWujYj5kqYAVRExA/gWcI2kc0id3RMjIoBXJV1GSjgB\n3BERf97mozQzs+1SrBlqFHAv8Jla1gVFrr3Irpm4o8ayCwumFwCH1LHtTaTTZ83MrMzqTRYR8f3s\n+dTGCcfMzJqiBnVwS+oOnAL0LdzGw32YmbUODT0b6g7gEeAp0tAbZmbWijQ0WXSMiG/mGomZmTVZ\nDb0o70ZJX5a0m6Rdqh+5RmZmZk1GQ2sW64GfAheQzoIie/5IHkGZmVnT0tBk8S1g7+orqs3MrHVp\naDPUYmBd0VJmZtYiNbRm8RbwpKSZwLvVC33qrJlZ69DQZHF79jAzs1aoQckiIn5TPS1pWEQ8nl9I\nZmbW1DS0z6LQr0sehZmZNWnbkixU8ijMzKxJ25Zk8R8lj8LMzJq0rU4WEXE7gKR9Sx+OmZk1RdtS\ns6j215JFYWZmTVqxO+VdUdcqoHvpwzEzs6aoWM3iVOBpYE6NRxVpvKh6SRoj6VlJiyVNrmV9H0kz\nJT0haZ6ko2tZv1bSuQ09IDMzK71i11nMBp6OiIdqrpB0UX0bSmoLXAkcASwDZkuakd1Ktdp3gVsi\n4ipJA0j3zehbsP4y4M5iB2FmZvkqliyOB96pbUVE9Cuy7XBgcUQ8ByBpOjAWKEwWAXTNprsBK6pX\nSPos8DxpqBEzMyujYs1QXSJiWwcQ7A28WDC/LFtW6CLgZEnLSLWKswEkdQG+TZHTdCVNklQlqWr1\n6tXbGKaZmRVTLFlsGg9K0u9yeP3xwPURUQEcTbrJUhtSEvlZRKytb+OImBoRlRFR2atXrxzCMzMz\nKN4MVXi19tbe6Gg5sEfBfEW2rNCXgDEAEfGwpI5AT+Ag4HhJPyGddfW+pHci4pdbGYOZmZVAsWQR\ndUw3xGxgH0n9SEliHHBSjTJLgdHA9ZL6Ax2B1RExsrpA1pG+1onCzKx8iiWL/SW9Qaph7JhNk81H\nRHSta8OI2CDpLOAuoC1wbUTMlzQFqIqIGaQ78F0j6RxSMpoYEVublMzMLGdqKd/NlZWVUVVVVe4w\nzMyaFUlzIqKyWLntGe7DzMxaCScLMzMrysnCzMyKcrIwM7OinCzMzKwoJwszMyuq2HUWZmZWw8aN\nsH49vPtuelRP17Ysj+may4YMgbvvzveYnSzMrEmKgPfey+fLdXunN24s7bG2bw8dOqRHXdMdOkDX\nrrWX2Wuv0sZTGycLs1bu/ffL96VbbN+l1KZN8S/k9u1hp52KlynldLt2IBWPv9ycLMxakAhYsgQe\neCA9FiyAd96p/8s6j1/Jxb4g27eHLl2270t2a7dr27a0x9naOFmYNWPvvw9PP705OTzwAKzIbiHW\nvTsMHQq77FKaL9uG7KN9++bxK9m2npOFWTPy7rtQVbU5MTz4ILz+elrXuzd84hMwcmR6DByYml7M\nSsHJwqwJe/11eOghmDUrJYfHHtvclt+/P5xwwubksOee/lVv+XGyMGtCVq5MSaE6Ocybl5qa2raF\nYcPgzDNTYjjkEPDNIa0xOVmYlUkELFq0ZXL4xz/Suk6dYMQI+N73UnI4+GDo3Lm88Vrr5mRh1kg2\nbIC5czcnh1mzYNWqtK5nTzjY/oGZAAAPk0lEQVT0UDjjjJQchg5Np1SaNRW5JgtJY4Cfk+6U9+uI\nuKTG+j7Ab0j32W4LTI6IOyQdAVwCtAfWA/8eEffmGatZqb39Njz66Obk8NBDsHZtWte3LxxxxOb+\nhn33dX+DNW25JQtJbYErgSOAZcBsSTMiYkFBse8Ct0TEVZIGAHcAfYGXgc9ExApJg0i3Zu2dV6xm\npfDKK+nspOrkUFWVrkCWYNAg+PznNyeHiopyR2u2dfKsWQwHFkfEcwCSpgNjgcJkEUD1fby7ASsA\nIuKJgjLzSff/7hARJb6m02zbvfji5lNYZ81K1ztAaj468EA455zNndE771zeWM22V57JojfwYsH8\nMuCgGmUuAv4q6WygM/CpWvbzOeDx2hKFpEnAJIA+ffqUIGSz2kXAwoVbJocXXkjrdtoJPv5xOPHE\nlByGD4cddyxvvGalVu4O7vHA9RHxn5JGADdKGhQR7wNIGgj8P+DI2jaOiKnAVIDKyspopJitFXjv\nPXj88S0vfluzJq378IdTUqiuOQweDDuU+z/JLGd5/okvB/YomK/IlhX6EjAGICIeltQR6Am8JKkC\nuA04JSL+kWOcZqxdC488sjk5PPJI6qAG2HtvOOaYdLbSyJFp3p3R1trkmSxmA/tI6kdKEuOAk2qU\nWQqMBq6X1B/oCKyW1B34M+nsqAdzjNFaqZde2twZ/cAD8MQTaUC9Nm1g//3hy19OyeHQQ2G33cod\nrVn55ZYsImKDpLNIZzK1Ba6NiPmSpgBVETED+BZwjaRzSJ3dEyMisu32Bi6UdGG2yyMj4qW84rWW\na/16ePbZ1KxUffHbs8+mdR06wEEHweTJKTGMGAHdupU3XrOmSBEto6m/srIyqqqqyh2GlVEELF8O\nTz2Vhsmofn7mmdQHAWkk1kMOSc1Jhx4KlZUpYZi1VpLmRERlsXLulrNmae3adKpqdUKoTg6vvrq5\nTEVF6nw++uj0PHgwDBjgkVjNtoWThTVpGzem8ZIKE8K8efDcc5vLdOmSLnr7t3+D/fZLSWG//Xxt\ng1kpOVlYk7F69ZYJ4amnYP78zWcltWkD++yTRl+dOHFzUujb17UFs7w5WVije+eddIFbzcTwz39u\nLtOrV0oGp5++ubYwYIAvdjMrFycLy01Eusq5Zofz3/+++b7PHTqkO7p9+tObawqDB6cL38ys6XCy\nsJJ4/fWUDAo7nJ9+Gt54Y3OZvn1TIjjuuM0dznvv7aufzZoD/5vaVtmwIdUManY4L126uUy3bikR\nnHzy5trCoEHQtWvd+zWzps3JwmoVkfoQavYrLFiQLnKDVCP42MfSdQunn745Meyxh4fDMGtpnCyM\ndevSWUeFiWHevM0D5wHsvntKBEccsblfYd99fUGbWWvhZNEKvfoqXH01zJmTksLixakmAenez4MG\nwbHHbnnNQo8e5Y3ZzMrLyaIViYBbb4Wzz04D6e21V0oGEyZsTgwf+YivWTCzD3KyaCVefBG++lX4\n05/SRW133glDh5Y7KjNrLvwbsoXbuBGuuCJd0HbvvfCf/wmPPupEYWZbxzWLFmzevHRfhsceSxe9\nXXUV9OtX7qjMrDlyzaIFevtt+M534IAD4PnnYdq01OzkRGFm28o1ixbm3nvhK19JZzhNnAiXXuoz\nmcxs++Vas5A0RtKzkhZLmlzL+j6SZkp6QtI8SUcXrDs/2+5ZSZ/OM86WYM0a+OIXYfTodNbTPffA\nddc5UZhZaeSWLCS1Ba4EjgIGAOMlDahR7LvALRExlHSP7v/Kth2QzQ8ExgD/le3PaoiAm2+G/v3h\nxhvh/PPThXWf/GS5IzOzliTPmsVwYHFEPBcR64HpwNgaZQKoHjGoG7Aimx4LTI+IdyPieWBxtj8r\nsGRJugvcSSelQfrmzIEf/cjDeJtZ6eWZLHoDLxbML8uWFboIOFnSMuAO4Oyt2BZJkyRVSapavXp1\nqeJu8jZsgMsuS0N7P/AA/Pzn8PDD6aI6M7M8lPtsqPHA9RFRARwN3CipwTFFxNSIqIyIyl69euUW\nZFPyxBNw8MHwrW/B4Yengf2+9jVo60Y6M8tRnsliObBHwXxFtqzQl4BbACLiYaAj0LOB27Yq69bB\neefBgQfCsmXwP/8Df/wj9OlT7sjMrDXIM1nMBvaR1E9Se1KH9YwaZZYCowEk9Scli9VZuXGSOkjq\nB+wDPJZjrE3a3Xenwf1++lM49dR0S9ITTvAw4GbWeHK7ziIiNkg6C7gLaAtcGxHzJU0BqiJiBvAt\n4BpJ55A6uydGRADzJd0CLAA2AGdGxMa8Ym2qVq9OzU033ggf/Sjcdx+MGlXuqMysNVJUj03dzFVW\nVkZVVVW5wyiJiJQgvvnNdLvSyZPhggugY8dyR2ZmLY2kORFRWaycr+BuYp57Lt117u67YcQImDo1\nNUGZmZVTuc+GssyGDfCTn6TE8Mgj8MtfwqxZThRm1jS4ZtEEVFWl0WGffBLGjk2JoqKi3FGZmW3m\nmkUZrV2b+iUOOghWrYLf/Q5uu82JwsyaHtcsyuTOO+GMM+CFF1IfxY9/DN27lzsqM7PauWbRyFat\ngvHj05hOnTql4TquusqJwsyaNieLRhKRhgzv3x9+/3u46KI0dMehh5Y7MjOz4twM1QgWLUo3JJo5\nMyWHqVNT0jAzay5cs8jRe++lIcP32y8NH3711fC3vzlRmFnz45pFTh59NJ0O+9RT8LnPwRVXwO67\nlzsqM7Nt45pFib35ZhoyfMQIeOUVuP12uPVWJwoza95csyihP/4RvvpVWL4czjwTLr4YunYtvp2Z\nWVPnmkUJrFyZhgw/5hjo1g0efBB+8QsnCjNrOZwstsP778M116QO6xkz4Ic/hMcfT01QZmYtiZuh\nttEzz6TTYe+/P91jYurUdM8JM7OWyDWLrbR+PfzgB7D//jBvHvz61+n6CScKM2vJXLPYCg8+CJMm\nwYIFcOKJcPnlsOuu5Y7KzCx/udYsJI2R9KykxZIm17L+Z5KezB5/l/RawbqfSJovaaGkK6Ty3XH6\n9dfTWU6HHppOjf3Tn2D6dCcKM2s9cqtZSGoLXAkcASwDZkuaERELqstExDkF5c8GhmbTHwcOAQZn\nq2cBo4D78oq3LrfdBmedBf/8J3zjG6kJqkuXxo7CzKy88qxZDAcWR8RzEbEemA6Mraf8eODmbDqA\njkB7oAPQDliVY6wfsHw5HHdcevTsme5e97OfOVGYWeuUZ7LoDbxYML8sW/YBkvYE+gH3AkTEw8BM\nYGX2uCsiFtay3SRJVZKqVq9eXZKg338/DRk+YEC658Qll6Q72R14YEl2b2bWLDWVs6HGAbdGxEYA\nSXsD/YEKUoL5pKSRNTeKiKkRURkRlb169druIObPh5EjU//EgQemcZ2+/W1o1267d21m1qzlmSyW\nA3sUzFdky2ozjs1NUADHAo9ExNqIWAvcCeR2qds778CFF8LQoen6ieuvh7vvhr33zusVzcyalzyT\nxWxgH0n9JLUnJYQZNQtJ2hfYGXi4YPFSYJSkHSS1I3Vuf6AZqhSefx6GDEkd1yecAAsXwhe+AOU7\n98rMrOnJLVlExAbgLOAu0hf9LRExX9IUSccUFB0HTI+IKFh2K/AP4ClgLjA3Iv6YR5y9e6caxJ13\nwk03wYc+lMermJk1b9ryO7r5qqysjKqqqnKHYWbWrEiaExGVxco1lQ5uMzNrwpwszMysKCcLMzMr\nysnCzMyKcrIwM7OinCzMzKwoJwszMyvKycLMzIpqMRflSVoNvLAdu+gJvFyicJqL1nbMre14wcfc\nWmzPMe8ZEUVHYm0xyWJ7SapqyFWMLUlrO+bWdrzgY24tGuOY3QxlZmZFOVmYmVlRThabTS13AGXQ\n2o65tR0v+Jhbi9yP2X0WZmZWlGsWZmZWlJOFmZkV1eqThaQxkp6VtFjS5HLHkzdJ10p6SdLT5Y6l\nsUjaQ9JMSQskzZf09XLHlDdJHSU9Jmludsz/Ue6YGoOktpKekPSncsfSWCQtkfSUpCcl5XYHuFbd\nZyGpLfB34AhgGem+4eMjYkFZA8uRpE8Aa4EbImJQueNpDJJ2A3aLiMcl7QTMAT7bwj9nAZ0jYm12\nH/tZwNcj4pEyh5YrSd8EKoGuEfGv5Y6nMUhaAlRGRK4XIrb2msVwYHFEPBcR64HpwNgyx5SriLgf\neKXccTSmiFgZEY9n02+S7gnfu7xR5SuStdlsu+zRon8ZSqoA/gX4dbljaYlae7LoDbxYML+MFv4l\n0tpJ6gsMBR4tbyT5y5pkngReAu6OiJZ+zJcD5wHvlzuQRhbAXyXNkTQprxdp7cnCWhFJXYDfAd+I\niDfKHU/eImJjRAwBKoDhklpss6OkfwVeiog55Y6lDA6NiGHAUcCZWVNzybX2ZLEc2KNgviJbZi1M\n1m7/O2BaRPy+3PE0poh4DZgJjCl3LDk6BDgma7+fDnxS0k3lDalxRMTy7Pkl4DZS83rJtfZkMRvY\nR1I/Se2BccCMMsdkJZZ19v43sDAiLit3PI1BUi9J3bPpHUkncTxT3qjyExHnR0RFRPQl/R/fGxEn\nlzms3EnqnJ20gaTOwJFALmc6tupkEREbgLOAu0idnrdExPzyRpUvSTcDDwMfk7RM0pfKHVMjOAT4\nPOnX5pPZ4+hyB5Wz3YCZkuaRfhTdHRGt5nTSVuTDwCxJc4HHgD9HxF/yeKFWfeqsmZk1TKuuWZiZ\nWcM4WZiZWVFOFmZmVpSThZmZFeVkYWZmRTlZmBUhaWPBKbdPlnJ0Ykl9W9MIwNZ87VDuAMyagbez\nYTPMWi3XLMy2UXYfgZ9k9xJ4TNLe2fK+ku6VNE/SPZL6ZMs/LOm27B4TcyV9PNtVW0nXZPed+Gt2\nxTWSvpbdg2OepOllOkwzwMnCrCF2rNEMdWLButcjYj/gl6RRTwF+AfwmIgYD04ArsuVXAH+LiP2B\nYUD1aAH7AFdGxEDgNeBz2fLJwNBsP6fndXBmDeEruM2KkLQ2IrrUsnwJ8MmIeC4bqPCfEdFD0suk\nmy29ly1fGRE9Ja0GKiLi3YJ99CUNxbFPNv9toF1E/FDSX0g3qroduL3g/hRmjc41C7PtE3VMb413\nC6Y3srkv8V+AK0m1kNmS3MdoZeNkYbZ9Tix4fjibfog08inABOCBbPoe4AzYdGOibnXtVFIbYI+I\nmAl8G+gGfKB2Y9ZY/EvFrLgdszvOVftLRFSfPrtzNrLru8D4bNnZwHWS/h1YDZyaLf86MDUb6Xcj\nKXGsrOM12wI3ZQlFwBXZfSnMysJ9FmbbKOuzqIyIl8sdi1ne3AxlZmZFuWZhZmZFuWZhZmZFOVmY\nmVlRThZmZlaUk4WZmRXlZGFmZkX9f8N6MiSLoL0jAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd297670dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()    \n",
    "\n",
    "f1_values = history_dict['f1']\n",
    "val_f1_values = history_dict['val_f1']\n",
    "\n",
    "plt.plot(range(len(f1_values)), f1_values, 'bo', label='Training f1')\n",
    "plt.plot(range(len(val_f1_values)), val_f1_values, 'b', label='Validation f1')\n",
    "plt.title('Training and validation batch-level f1-micro')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1-micro')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_file(array,name):\n",
    "    df = pd.DataFrame(data = array.tolist(),columns=[i for i in range(1,y_train.shape[1]+1)])\n",
    "    df.to_csv(os.path.join(DATADIR, name+'.csv.gz'),compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_1226_2203_'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_run = time.strftime(\"_%H%M_%d%m_\")\n",
    "date_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict([meta_train, title_train, desc_train, x_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_prob,\"train_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_prob.copy()\n",
    "y_pred[y_pred>=P_THRESHOLD] = 1\n",
    "y_pred[y_pred<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro: (0.96347198054810057, 0.95291433312590745, 0.95816407503906587, None)\n",
      "macro: (0.97666338542739761, 0.97172978587476855, 0.97391915634452175, None)\n",
      "weightedmacro: (0.96371897115557026, 0.95291433312590745, 0.95794135222692289, None)\n"
     ]
    }
   ],
   "source": [
    "print('micro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='micro', sample_weight=None)))\n",
    "print('macro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='macro', sample_weight=None)))\n",
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='weighted', sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_dev = model.predict([meta_dev, title_dev, desc_dev, x_dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_prob_dev,\"dev_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dev = y_prob_dev.copy()\n",
    "y_pred_dev[y_pred_dev>=P_THRESHOLD] = 1\n",
    "y_pred_dev[y_pred_dev<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro: (0.84424717546691264, 0.81516112873601598, 0.82944924253150221, None)\n",
      "macro: (0.76120767687062862, 0.81163101605414345, 0.77781893358457876, None)\n",
      "weightedmacro: (0.8481166647481343, 0.81516112873601598, 0.82882896784708981, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('micro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='micro', sample_weight=None)))\n",
    "print('macro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='macro', sample_weight=None)))\n",
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='weighted', sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weightedmacro: (array([ 1.        ,  1.        ,  0.98876404,  0.72222222,  1.        ,\n",
      "        0.61666667,  0.6       ,  0.83443709,  0.        ,  0.94444444,\n",
      "        1.        ,  0.99410377,  1.        ,  0.75      ,  0.66666667,\n",
      "        0.        ,  0.75675676,  1.        ,  1.        ,  0.82269504,\n",
      "        0.88140417,  0.71100917,  0.82758621,  0.        ,  0.85714286,\n",
      "        1.        ,  0.875     ,  1.        ,  1.        ,  1.        ,\n",
      "        0.77777778,  0.76923077,  1.        ,  0.        ,  0.54054054,\n",
      "        0.81957774,  0.5       ,  0.86206897,  0.76347305,  0.84210526,\n",
      "        0.81666667,  1.        ,  0.63829787,  0.83428571,  1.        ,\n",
      "        1.        ,  0.6969697 ,  1.        ,  0.        ,  0.76923077,\n",
      "        0.848     ,  1.        ,  1.        ,  0.55555556,  1.        ,\n",
      "        1.        ,  1.        ,  0.        ,  0.93624161,  0.45454545,\n",
      "        0.77777778,  0.90909091,  0.42857143,  0.66666667,  0.82857143,\n",
      "        1.        ,  0.78021978,  0.65116279,  0.        ,  1.        ,\n",
      "        0.51851852,  0.        ,  1.        ,  0.75      ,  0.81355932,\n",
      "        0.86486486,  0.88372093,  0.83333333,  0.        ,  0.86080586,\n",
      "        0.        ,  0.8125    ,  0.75      ,  0.89256198,  0.86101296,\n",
      "        0.5       ,  1.        ,  0.67515924,  1.        ,  1.        ,\n",
      "        0.85714286,  0.7037037 ,  0.        ,  0.86686391,  0.75572519,\n",
      "        0.85      ,  1.        ,  1.        ,  0.91176471,  0.86111111,\n",
      "        0.65853659,  0.74390244,  0.96      ,  0.63888889,  1.        ,\n",
      "        0.76923077,  1.        ,  0.81632653,  0.5       ,  0.71428571,\n",
      "        0.76923077,  0.        ,  0.83333333,  0.88888889,  1.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.88888889,  0.8411215 ,\n",
      "        0.78431373,  0.76470588,  0.55882353,  0.72727273,  0.93846154,\n",
      "        0.97630332,  1.        ,  0.78378378,  0.5       ,  0.86792453,\n",
      "        0.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.83606557,  0.7826087 ,  0.81747573,  0.83168317,  0.        ,\n",
      "        0.875     ,  1.        ,  1.        ,  1.        ,  0.83050847,\n",
      "        0.94117647,  0.79464286,  0.90740741,  0.69230769,  1.        ,\n",
      "        1.        ,  0.66666667,  0.93783304,  0.        ,  1.        ,\n",
      "        0.        ,  0.7       ,  0.95686275,  0.66666667,  1.        ,\n",
      "        1.        ,  0.78571429,  0.93133047,  0.84705882,  0.79865772,\n",
      "        0.79245283,  0.70588235,  0.85      ,  0.90789474,  0.84615385,\n",
      "        0.82142857,  1.        ,  0.        ,  0.63636364,  0.        ,\n",
      "        0.79508197,  0.95      ,  0.82758621,  0.75      ,  1.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.88      ,  0.71428571,\n",
      "        0.73333333,  0.90740741,  0.85714286,  0.6       ,  0.78694158,\n",
      "        1.        ,  0.82568807,  0.88888889,  0.6       ,  1.        ,\n",
      "        1.        ,  0.62436548,  0.625     ,  0.65454545,  0.33333333,\n",
      "        1.        ,  0.9       ,  0.95890411,  1.        ,  0.        ,\n",
      "        0.93181818,  0.84848485,  0.63636364,  0.80769231,  0.85074627,\n",
      "        0.77777778,  1.        ,  1.        ,  0.        ,  1.        ,\n",
      "        1.        ,  0.89473684]), array([ 1.        ,  1.        ,  0.82242991,  0.92857143,  1.        ,\n",
      "        0.60655738,  1.        ,  0.62376238,  0.        ,  0.94444444,\n",
      "        1.        ,  0.99176471,  1.        ,  1.        ,  0.75      ,\n",
      "        0.        ,  1.        ,  1.        ,  1.        ,  0.82857143,\n",
      "        0.77223608,  0.68584071,  0.91803279,  0.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.74074074,\n",
      "        0.81957774,  1.        ,  0.89285714,  0.68733154,  1.        ,\n",
      "        0.51041667,  1.        ,  0.50847458,  0.8742515 ,  1.        ,\n",
      "        0.99806202,  0.82142857,  1.        ,  0.        ,  0.76923077,\n",
      "        0.75177305,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.        ,  0.871875  ,  1.        ,\n",
      "        0.65497076,  1.        ,  1.        ,  1.        ,  0.725     ,\n",
      "        1.        ,  0.61471861,  0.73043478,  0.        ,  0.92045455,\n",
      "        1.        ,  0.        ,  1.        ,  1.        ,  0.67605634,\n",
      "        1.        ,  0.88372093,  0.77966102,  0.        ,  0.87360595,\n",
      "        0.        ,  0.86666667,  1.        ,  0.76056338,  0.83352338,\n",
      "        1.        ,  1.        ,  0.57297297,  1.        ,  1.        ,\n",
      "        1.        ,  0.95      ,  0.        ,  0.83954155,  0.81147541,\n",
      "        0.79069767,  1.        ,  1.        ,  0.93939394,  0.96875   ,\n",
      "        0.79411765,  0.70930233,  0.82978723,  0.79310345,  1.        ,\n",
      "        0.90909091,  1.        ,  0.95238095,  1.        ,  1.        ,\n",
      "        1.        ,  0.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.        ,  1.        ,  1.        ,  1.        ,  0.74074074,\n",
      "        0.93023256,  0.61904762,  0.82608696,  1.        ,  0.87142857,\n",
      "        0.92792793,  1.        ,  0.71311475,  1.        ,  0.91089109,\n",
      "        0.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.75      ,  1.        ,  0.842     ,  0.84848485,  0.        ,\n",
      "        0.875     ,  1.        ,  1.        ,  1.        ,  0.765625  ,\n",
      "        0.94117647,  0.73553719,  0.81666667,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.8488746 ,  0.        ,  1.        ,\n",
      "        0.        ,  0.80769231,  0.94573643,  0.48571429,  1.        ,\n",
      "        1.        ,  1.        ,  0.87854251,  0.75      ,  0.71686747,\n",
      "        0.89361702,  1.        ,  0.64150943,  0.86792453,  0.752443  ,\n",
      "        0.85185185,  1.        ,  0.        ,  1.        ,  0.        ,\n",
      "        0.58787879,  0.95      ,  0.70588235,  1.        ,  1.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.91666667,  1.        ,\n",
      "        1.        ,  0.80991736,  1.        ,  0.9       ,  0.78156997,\n",
      "        1.        ,  0.69230769,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  0.67805954,  1.        ,  0.8372093 ,  1.        ,\n",
      "        1.        ,  0.85714286,  0.88607595,  1.        ,  0.        ,\n",
      "        0.93714286,  0.75675676,  0.60869565,  1.        ,  0.86363636,\n",
      "        0.71794872,  1.        ,  0.84615385,  0.        ,  1.        ,\n",
      "        1.        ,  0.93793103]), array([ 1.        ,  1.        ,  0.89795918,  0.8125    ,  1.        ,\n",
      "        0.61157025,  0.75      ,  0.71388102,  0.        ,  0.94444444,\n",
      "        1.        ,  0.99293286,  1.        ,  0.85714286,  0.70588235,\n",
      "        0.        ,  0.86153846,  1.        ,  1.        ,  0.82562278,\n",
      "        0.82321666,  0.6981982 ,  0.87046632,  0.        ,  0.92307692,\n",
      "        1.        ,  0.93333333,  1.        ,  1.        ,  1.        ,\n",
      "        0.875     ,  0.86956522,  1.        ,  0.        ,  0.625     ,\n",
      "        0.81957774,  0.66666667,  0.87719298,  0.72340426,  0.91428571,\n",
      "        0.62820513,  1.        ,  0.56603774,  0.85380117,  1.        ,\n",
      "        0.99903007,  0.75409836,  1.        ,  0.        ,  0.76923077,\n",
      "        0.79699248,  1.        ,  1.        ,  0.71428571,  1.        ,\n",
      "        1.        ,  1.        ,  0.        ,  0.90291262,  0.625     ,\n",
      "        0.71111111,  0.95238095,  0.6       ,  0.8       ,  0.77333333,\n",
      "        1.        ,  0.68765133,  0.68852459,  0.        ,  0.95857988,\n",
      "        0.68292683,  0.        ,  1.        ,  0.85714286,  0.73846154,\n",
      "        0.92753623,  0.88372093,  0.8056042 ,  0.        ,  0.86715867,\n",
      "        0.        ,  0.83870968,  0.85714286,  0.82129278,  0.84704519,\n",
      "        0.66666667,  1.        ,  0.61988304,  1.        ,  1.        ,\n",
      "        0.92307692,  0.80851064,  0.        ,  0.85298399,  0.7826087 ,\n",
      "        0.81927711,  1.        ,  1.        ,  0.92537313,  0.91176471,\n",
      "        0.72      ,  0.72619048,  0.89015692,  0.70769231,  1.        ,\n",
      "        0.83333333,  1.        ,  0.87912088,  0.66666667,  0.83333333,\n",
      "        0.86956522,  0.        ,  0.90909091,  0.94117647,  1.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.94117647,  0.78774617,\n",
      "        0.85106383,  0.68421053,  0.66666667,  0.84210526,  0.9037037 ,\n",
      "        0.95150115,  1.        ,  0.74678112,  0.66666667,  0.88888889,\n",
      "        0.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.79069767,  0.87804878,  0.82955665,  0.84      ,  0.        ,\n",
      "        0.875     ,  1.        ,  1.        ,  1.        ,  0.79674797,\n",
      "        0.94117647,  0.7639485 ,  0.85964912,  0.81818182,  1.        ,\n",
      "        1.        ,  0.8       ,  0.89113924,  0.        ,  1.        ,\n",
      "        0.        ,  0.75      ,  0.95126706,  0.56198347,  1.        ,\n",
      "        1.        ,  0.88      ,  0.90416667,  0.79558011,  0.75555556,\n",
      "        0.84      ,  0.82758621,  0.7311828 ,  0.88745981,  0.79655172,\n",
      "        0.83636364,  1.        ,  0.        ,  0.77777778,  0.        ,\n",
      "        0.67595819,  0.95      ,  0.76190476,  0.85714286,  1.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.89795918,  0.83333333,\n",
      "        0.84615385,  0.8558952 ,  0.92307692,  0.72      ,  0.78424658,\n",
      "        1.        ,  0.75313808,  0.94117647,  0.75      ,  1.        ,\n",
      "        1.        ,  0.65010571,  0.76923077,  0.73469388,  0.5       ,\n",
      "        1.        ,  0.87804878,  0.92105263,  1.        ,  0.        ,\n",
      "        0.93447293,  0.8       ,  0.62222222,  0.89361702,  0.85714286,\n",
      "        0.74666667,  1.        ,  0.91666667,  0.        ,  1.        ,\n",
      "        1.        ,  0.91582492]), array([   2,    6,  107,   14,   72,   61,   12,  202,    0,   36,    1,\n",
      "        850,    4,    3,   48,    0,   28,    1,    1,  140, 1203,  226,\n",
      "        183,    0,    6,    3,    7,    4,    5,   10,    7,   20,    5,\n",
      "          0,   27,  521,    3,   28,  371,   16,   96,    1,   59,  167,\n",
      "          6, 1032,   28,   12,    0,   26,  141,    2,    4,    5,    1,\n",
      "          4,    1,    0,  320,    5,  171,   10,    3,    6,   40,    1,\n",
      "        231,  115,    0,   88,   14,    0,    4,    3,   71,   32,   86,\n",
      "        295,    0,  269,    0,   30,   12,  142,  877,    2,    1,  185,\n",
      "          2,    4,    6,   20,    0,  349,  366,   86,    7,   17,   33,\n",
      "         32,   34,   86,  376,   29,    1,   11,    8,   42,    2,    5,\n",
      "         10,    0,   10,    8,    4,    0,    2,    1,    8,  243,   43,\n",
      "         42,   23,   16,   70,  222,    2,  122,    2,  101,    0,    2,\n",
      "          3,    1,    3,  476,   18,  500,   99,    0,    8,    2,    2,\n",
      "          4,   64,   17,  121,   60,    9,    4,    1,    2,  622,    0,\n",
      "          1,    0,   26,  258,   70,   19,    3,   11,  247,   96,  166,\n",
      "         47,   12,   53,  159,  307,   81,    3,    0,    7,    0,  165,\n",
      "         20,  136,    3,    6,    0,    4,    5,   24,    5,   22,  121,\n",
      "          6,   20,  586,   11,  130,    8,   12,    1,    2,  907,    5,\n",
      "         43,    1,    5,   21,   79,    3,    0,  175,  148,   23,   21,\n",
      "         66,  156,    1,   13,    0,    6,    2,  145]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average=None, sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_train,\"true_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_dev,\"true_dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(data_to_tag): \n",
    "    filename = data_to_tag+\"_arrays.npz\"\n",
    "    arrays = np.load(os.path.join(DATADIR,filename))\n",
    "    \n",
    "    print('Set up arrays for new_content: {}'.format(arrays.files))\n",
    "    x_predict = arrays['x']\n",
    "    meta_predict = arrays['meta'].all().todense()\n",
    "    title_predict = arrays['title'].all().todense()\n",
    "    desc_predict = arrays['desc'].all().todense()\n",
    "    \n",
    "    print('x_arrays.shape = {}'.format(x_predict.shape))\n",
    "    print('meta_arrays.shape = {}'.format(meta_predict.shape))\n",
    "    print('title_arrays.shape = {}'.format(title_predict.shape))\n",
    "    print('desc_arrays.shape = {}'.format(desc_predict.shape))\n",
    "    \n",
    "    print('Predict on untagged content')\n",
    "    y_pred_new = model.predict([meta_predict, title_predict, desc_predict, x_predict])\n",
    "    \n",
    "    to_file(y_pred_new, data_to_tag+\"_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up arrays for new_content: ['x', 'meta', 'title', 'desc', 'content_id']\n",
      "x_arrays.shape = (56568, 1000)\n",
      "meta_arrays.shape = (56568, 529)\n",
      "title_arrays.shape = (56568, 10000)\n",
      "desc_arrays.shape = (56568, 10000)\n",
      "Predict on untagged content\n"
     ]
    }
   ],
   "source": [
    "get_predictions(\"new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_predictions_1226_2203_\n"
     ]
    }
   ],
   "source": [
    "print(\"new_predictions\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up arrays for new_content: ['x', 'meta', 'title', 'desc', 'content_id']\n",
      "x_arrays.shape = (17937, 1000)\n",
      "meta_arrays.shape = (17937, 529)\n",
      "title_arrays.shape = (17937, 10000)\n",
      "desc_arrays.shape = (17937, 10000)\n",
      "Predict on untagged content\n"
     ]
    }
   ],
   "source": [
    "get_predictions(\"level1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level1_predictions_1226_2203_\n"
     ]
    }
   ],
   "source": [
    "print(\"level1_predictions\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "keep_output": true,
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
