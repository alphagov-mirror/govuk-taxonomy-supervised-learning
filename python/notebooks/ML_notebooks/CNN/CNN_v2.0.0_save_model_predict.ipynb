{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional NN to classify govuk content to level2 taxons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on:\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load requirements and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.utils import to_categorical, layer_utils, plot_model\n",
    "\n",
    "from keras.layers import (Embedding, Input, Dense, Dropout, \n",
    "                          Activation, Conv1D, MaxPooling1D, Flatten, concatenate, Reshape)\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.callbacks import TensorBoard, Callback, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score \n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import functools\n",
    "\n",
    "import h5py\n",
    "\n",
    "from scipy import sparse\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environmental vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATADIR = os.getenv('DATADIR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print data version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm running on data extracted from content store on /data/2018-03-12\n"
     ]
    }
   ],
   "source": [
    "print('algorithm running on data extracted from content store on {}'.format(DATADIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuition for POS_RATIO is that it penalises the prediction of zero for everything, which is attractive to the model because the multilabel y matrix is super sparse. \n",
    "\n",
    "Increasing POS_RATIO should penalise predicting zeros more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MAX_NB_WORDS\n",
    "MAX_SEQUENCE_LENGTH =1000\n",
    "EMBEDDING_DIM = 100 # keras embedding layer output_dim = Dimension of the dense embedding\n",
    "P_THRESHOLD = 0.5 #Threshold for probability of being assigned to class\n",
    "POS_RATIO = 0.5 #ratio of positive to negative for each class in weighted binary cross entropy loss function\n",
    "NUM_WORDS=20000 #keras tokenizer num_words: None or int. Maximum number of words to work with \n",
    "#(if set, tokenization will be restricted to the top num_words most common words in the dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = np.load(os.path.join(DATADIR, 'train_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'meta', 'title', 'desc', 'y', 'content_id']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (175620, 1000)\n",
      "meta_train.shape = (175620, 535)\n",
      "title_train.shape = (175620, 10000)\n",
      "desc_train.shape = (175620, 10000)\n",
      "y_train.shape = (175620, 218)\n"
     ]
    }
   ],
   "source": [
    "x_train = train['x']\n",
    "meta_train = train['meta'].all().todense()\n",
    "title_train = train['title'].all().todense()\n",
    "desc_train = train['desc'].all().todense()\n",
    "y_train = train['y'].all().todense()\n",
    "\n",
    "print('x_train.shape = {}'.format(x_train.shape))\n",
    "print('meta_train.shape = {}'.format(meta_train.shape))\n",
    "print('title_train.shape = {}'.format(title_train.shape))\n",
    "print('desc_train.shape = {}'.format(desc_train.shape))\n",
    "print('y_train.shape = {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dev = np.load(os.path.join(DATADIR, 'dev_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_dev.shape = (12390, 1000)\n",
      "meta_dev.shape = (12390, 535)\n",
      "title_dev.shape = (12390, 10000)\n",
      "desc_dev.shape = (12390, 10000)\n",
      "y_dev.shape = (12390, 218)\n"
     ]
    }
   ],
   "source": [
    "x_dev = dev['x']\n",
    "meta_dev = dev['meta'].all().todense()\n",
    "title_dev = dev['title'].all().todense()\n",
    "desc_dev = dev['desc'].all().todense()\n",
    "y_dev = dev['y'].all().todense()\n",
    "\n",
    "print('x_dev.shape = {}'.format(x_dev.shape))\n",
    "print('meta_dev.shape = {}'.format(meta_dev.shape))\n",
    "print('title_dev.shape = {}'.format(title_dev.shape))\n",
    "print('desc_dev.shape = {}'.format(desc_dev.shape))\n",
    "print('y_dev.shape = {}'.format(y_dev.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = np.load(os.path.join(DATADIR, 'test_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test.shape = (12390, 1000)\n",
      "meta_test.shape = (12390, 535)\n",
      "title_test.shape = (12390, 10000)\n",
      "desc_test.shape = (12390, 10000)\n",
      "y_test.shape = (12390, 218)\n"
     ]
    }
   ],
   "source": [
    "x_test = test['x']\n",
    "meta_test = test['meta'].all().todense()\n",
    "title_test = test['title'].all().todense()\n",
    "desc_test = test['desc'].all().todense()\n",
    "y_test = test['y'].all().todense()\n",
    "\n",
    "print('x_test.shape = {}'.format(x_test.shape))\n",
    "print('meta_test.shape = {}'.format(meta_test.shape))\n",
    "print('title_test.shape = {}'.format(title_test.shape))\n",
    "print('desc_test.shape = {}'.format(desc_test.shape))\n",
    "print('y_test.shape = {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### previous shapes in old data \n",
    "Shape of x_train: (150870, 1000)\n",
    "Shape of metax_train: (150870, 436)\n",
    "Shape of titlex_train: (150870, 10000)\n",
    "Shape of descx_train: (150870, 10000)\n",
    "Shape of y_train: (150870, 210)\n",
    "\n",
    "Shape of x_dev: (9234, 1000)\n",
    "Shape of meta_dev: (9234, 436)\n",
    "Shape of titlex_dev: (9234, 10000)\n",
    "Shape of descx_dev: (9234, 10000)\n",
    "Shape of y_dev: (9234, 210)\n",
    "\n",
    "Shape of x_test: (9234, 1000)\n",
    "Shape of metax_test: (9234, 436)\n",
    "Shape of titlex_test: (9234, 10000)\n",
    "Shape of descx_test: (9234, 10000)\n",
    "Shape of y_test: (9234, 210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing the Embedding layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "def load_tokenizer_from_file(filename):\n",
    "    \n",
    "    tokenizer = Tokenizer()\n",
    "\n",
    "    with open(filename, 'r') as infile:\n",
    "        tokenizer_data = json.load(infile)\n",
    "\n",
    "    tokenizer.word_counts = OrderedDict(tokenizer_data['word_counts'])\n",
    "    tokenizer.word_docs = tokenizer_data['word_docs']\n",
    "    tokenizer.word_index = tokenizer_data['word_index']\n",
    "    tokenizer.document_count = tokenizer_data['document_count']\n",
    "    tokenizer.index_docs = tokenizer_data['index_docs']\n",
    "\n",
    "    return tokenizer\n",
    "\n",
    "tokenizer_combined_text = load_tokenizer_from_file(os.path.join(DATADIR, \"combined_text_tokenizer.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(tokenizer_combined_text.word_index) + 1, \n",
    "                            EMBEDDING_DIM, \n",
    "                            input_length=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Embedding layer should be fed sequences of integers, i.e. a 2D input of shape (samples, indices). These input sequences should be padded so that they all have the same length in a batch of input data (although an Embedding layer is capable of processing sequence of heterogenous length, if you don't pass an explicit input_length argument to the layer).\n",
    "\n",
    "All that the Embedding layer does is to map the integer inputs to the vectors found at the corresponding index in the embedding matrix, i.e. the sequence [1, 2] would be converted to [embeddings[1], embeddings[2]]. This means that the output of the Embedding layer will be a 3D tensor of shape (samples, sequence_length, embedding_dim)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate class weights for unbalanced datasets.\n",
    "paramter to model.fit = __class_weight__: Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
    "\n",
    "Implement class_weight from sklearn:\n",
    "\n",
    "- Import the module \n",
    "\n",
    "`from sklearn.utils import class_weight`\n",
    "- calculate the class weight, If ‘balanced’, class weights will be given by n_samples / (n_classes * np.bincount(y)):\n",
    "\n",
    "`class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)`\n",
    "\n",
    "- change it to a dict in order to work with Keras.\n",
    "\n",
    "`class_weight_dict = dict(enumerate(class_weight))`\n",
    "\n",
    "- Add to model fitting\n",
    "\n",
    "`model.fit(X_train, y_train, class_weight=class_weight)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "# class_weight_dict = dict(enumerate(class_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.00756\n",
      "8.01512\n"
     ]
    }
   ],
   "source": [
    "class WeightedBinaryCrossEntropy(object):\n",
    "\n",
    "    def __init__(self, pos_ratio):\n",
    "        neg_ratio = 1. - pos_ratio\n",
    "        #self.pos_ratio = tf.constant(pos_ratio, tf.float32)\n",
    "        self.pos_ratio = pos_ratio\n",
    "        #self.weights = tf.constant(neg_ratio / pos_ratio, tf.float32)\n",
    "        self.weights = neg_ratio / pos_ratio\n",
    "        self.__name__ = \"weighted_binary_crossentropy({0})\".format(pos_ratio)\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        return self.weighted_binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "    def weighted_binary_crossentropy(self, y_true, y_pred):\n",
    "            # Transform to logits\n",
    "            epsilon = tf.convert_to_tensor(K.common._EPSILON, y_pred.dtype.base_dtype)\n",
    "            y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
    "            y_pred = tf.log(y_pred / (1 - y_pred))\n",
    "\n",
    "            cost = tf.nn.weighted_cross_entropy_with_logits(y_true, y_pred, self.weights)\n",
    "            return K.mean(cost * self.pos_ratio, axis=-1)\n",
    "    \n",
    "y_true_arr = np.array([0,1,0,1], dtype=\"float32\")\n",
    "y_pred_arr = np.array([0,0,1,1], dtype=\"float32\")\n",
    "y_true = tf.constant(y_true_arr)\n",
    "y_pred = tf.constant(y_pred_arr)\n",
    "\n",
    "with tf.Session().as_default(): \n",
    "    print(WeightedBinaryCrossEntropy(0.5)(y_true, y_pred).eval())\n",
    "    print(binary_crossentropy(y_true, y_pred).eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### difficulty getting global precision/recall metrics . CAUTION interpreting monitoring metrics\n",
    "fcholltet: \"Basically these are all global metrics that were approximated\n",
    "batch-wise, which is more misleading than helpful. This was mentioned in\n",
    "the docs but it's much cleaner to remove them altogether. It was a mistake\n",
    "to merge them in the first place.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    \"\"\"Use Recall  and precision metrics to calculate harmonic mean (F1 score).\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1 = 2*((precision*recall)/(precision+recall))\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a 1D convnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NB_CLASSES = y_train.shape[1]\n",
    "NB_METAVARS = meta_train.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='wordindex') #MAX_SEQUENCE_LENGTH\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Dropout(0.2, name = 'dropout_embedded')(embedded_sequences)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv0')(x)\n",
    "\n",
    "x = MaxPooling1D(5, name = 'max_pool0')(x)\n",
    "\n",
    "x = Dropout(0.5, name = 'dropout0')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv1')(x)\n",
    "\n",
    "x = MaxPooling1D(5 , name = 'max_pool1')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv2')(x)\n",
    "\n",
    "x = MaxPooling1D(35, name = 'global_max_pool')(x)  # global max pooling\n",
    "\n",
    "x = Flatten()(x) #reduce dimensions from 3 to 2; convert to vector + FULLYCONNECTED\n",
    "\n",
    "meta_input = Input(shape=(NB_METAVARS,), name='meta')\n",
    "meta_hidden = Dense(128, activation='relu', name = 'hidden_meta')(meta_input)\n",
    "meta_hidden = Dropout(0.2, name = 'dropout_meta')(meta_hidden)\n",
    "\n",
    "\n",
    "title_input = Input(shape=(title_train.shape[1],), name='titles')\n",
    "title_hidden = Dense(128, activation='relu', name = 'hidden_title')(title_input)\n",
    "title_hidden = Dropout(0.2, name = 'dropout_title')(title_hidden)\n",
    "\n",
    "desc_input = Input(shape=(desc_train.shape[1],), name='descs')\n",
    "desc_hidden = Dense(128, activation='relu', name = 'hidden_desc')(desc_input)\n",
    "desc_hidden = Dropout(0.2, name = 'dropout_desc')(desc_hidden)\n",
    "\n",
    "concatenated = concatenate([meta_hidden, title_hidden, desc_hidden, x])\n",
    "\n",
    "x = Dense(400, activation='relu', name = 'fully_connected0')(concatenated)\n",
    "\n",
    "x = Dropout(0.2, name = 'dropout1')(x)\n",
    "\n",
    "x = Dense(NB_CLASSES, activation='sigmoid', name = 'fully_connected1')(x)\n",
    "\n",
    "# # The Model class turns an input tensor and output tensor into a model\n",
    "# This creates Keras model instance, will use this instance to train/test the model.\n",
    "model = Model(inputs=[meta_input, title_input, desc_input, sequence_input], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "wordindex (InputLayer)          (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 100)    34223100    wordindex[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_embedded (Dropout)      (None, 1000, 100)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv1D)                  (None, 996, 128)     64128       dropout_embedded[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pool0 (MaxPooling1D)        (None, 199, 128)     0           conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout0 (Dropout)              (None, 199, 128)     0           max_pool0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv1D)                  (None, 195, 128)     82048       dropout0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pool1 (MaxPooling1D)        (None, 39, 128)      0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "meta (InputLayer)               (None, 535)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "titles (InputLayer)             (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "descs (InputLayer)              (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv1D)                  (None, 35, 128)      82048       max_pool1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hidden_meta (Dense)             (None, 128)          68608       meta[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "hidden_title (Dense)            (None, 128)          1280128     titles[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "hidden_desc (Dense)             (None, 128)          1280128     descs[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pool (MaxPooling1D)  (None, 1, 128)       0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_meta (Dropout)          (None, 128)          0           hidden_meta[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_title (Dropout)         (None, 128)          0           hidden_title[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_desc (Dropout)          (None, 128)          0           hidden_desc[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           global_max_pool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           dropout_meta[0][0]               \n",
      "                                                                 dropout_title[0][0]              \n",
      "                                                                 dropout_desc[0][0]               \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fully_connected0 (Dense)        (None, 400)          205200      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 400)          0           fully_connected0[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fully_connected1 (Dense)        (None, 218)          87418       dropout1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 37,372,806\n",
      "Trainable params: 37,372,806\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard callbacks /metrics /monitor training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **Size of these files is killing storage during training. Is it histograms?**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tb = TensorBoard(log_dir='./learn_embedding_logs', histogram_freq=1, write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = os.path.join(DATADIR, 'model_checkpoint.hdf5')\n",
    "\n",
    "cp = ModelCheckpoint(\n",
    "                     filepath = CHECKPOINT_PATH, \n",
    "                     monitor='val_loss', \n",
    "                     verbose=0, \n",
    "                     save_best_only=False, \n",
    "                     save_weights_only=False, \n",
    "                     mode='auto', \n",
    "                     period=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "#model.fit(x, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 & 3. Train & compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 175620 samples, validate on 12390 samples\n",
      "Epoch 1/10\n",
      "175620/175620 [==============================] - 181s 1ms/step - loss: 0.0086 - binary_accuracy: 0.9952 - f1: nan - val_loss: 0.0040 - val_binary_accuracy: 0.9973 - val_f1: 0.7714\n",
      "Epoch 2/10\n",
      "175620/175620 [==============================] - 179s 1ms/step - loss: 0.0029 - binary_accuracy: 0.9980 - f1: 0.8702 - val_loss: 0.0034 - val_binary_accuracy: 0.9977 - val_f1: 0.8095\n",
      "Epoch 3/10\n",
      "175620/175620 [==============================] - 179s 1ms/step - loss: 0.0022 - binary_accuracy: 0.9985 - f1: 0.9037 - val_loss: 0.0033 - val_binary_accuracy: 0.9977 - val_f1: 0.8209\n",
      "Epoch 4/10\n",
      "175620/175620 [==============================] - 179s 1ms/step - loss: 0.0019 - binary_accuracy: 0.9988 - f1: 0.9196 - val_loss: 0.0033 - val_binary_accuracy: 0.9979 - val_f1: 0.8280\n",
      "Epoch 5/10\n",
      "175620/175620 [==============================] - 179s 1ms/step - loss: 0.0017 - binary_accuracy: 0.9989 - f1: 0.9299 - val_loss: 0.0034 - val_binary_accuracy: 0.9979 - val_f1: 0.8303\n",
      "Epoch 6/10\n",
      "175620/175620 [==============================] - 179s 1ms/step - loss: 0.0015 - binary_accuracy: 0.9990 - f1: 0.9360 - val_loss: 0.0035 - val_binary_accuracy: 0.9979 - val_f1: 0.8316\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=WeightedBinaryCrossEntropy(POS_RATIO),\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['binary_accuracy', f1])\n",
    "\n",
    "# This `fit` call will be distributed on 8 GPUs.\n",
    "# Since the batch size is 256, each GPU will process 32 samples.\n",
    "history = model.fit(\n",
    "    {'meta': meta_train, 'titles': title_train, 'descs': desc_train, 'wordindex': x_train},\n",
    "    y_train, \n",
    "    validation_data=([meta_dev, title_dev, desc_dev, x_dev], y_dev), \n",
    "    epochs=10, batch_size=128, callbacks=[early_stopping]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_binary_accuracy', 'val_f1', 'loss', 'binary_accuracy', 'f1'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd07a825668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(range(len(loss_values)), loss_values, 'bo', label='Training loss')           \n",
    "plt.plot(range(len(val_loss_values)), val_loss_values, 'b', label='Validation loss')      \n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYmZmeXEiMTOzvPx/CW3yeBoTqUgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd079cd3518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()    \n",
    "\n",
    "f1_values = history_dict['f1']\n",
    "val_f1_values = history_dict['val_f1']\n",
    "\n",
    "plt.plot(range(len(f1_values)), f1_values, 'bo', label='Training f1')\n",
    "plt.plot(range(len(val_f1_values)), val_f1_values, 'b', label='Validation f1')\n",
    "plt.title('Training and validation batch-level f1-micro')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1-micro')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_file(array,name):\n",
    "    df = pd.DataFrame(data = array.tolist(),columns=[i for i in range(1,y_train.shape[1]+1)])\n",
    "    df.to_csv(os.path.join(DATADIR, name+'.csv.gz'),compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_1726_1203_'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_run = time.strftime(\"_%H%M_%d%m_\")\n",
    "date_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict([meta_train, title_train, desc_train, x_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_prob,\"train_results\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_prob.copy()\n",
    "y_pred[y_pred>=P_THRESHOLD] = 1\n",
    "y_pred[y_pred<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro: (0.96982080580490126, 0.95028285644010824, 0.95995242725361796, None)\n",
      "macro: (0.97952570577508635, 0.97164109411071753, 0.97518938390701149, None)\n",
      "weightedmacro: (0.96969200010914558, 0.95028285644010824, 0.95939265335117363, None)\n"
     ]
    }
   ],
   "source": [
    "print('micro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='micro', sample_weight=None)))\n",
    "print('macro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='macro', sample_weight=None)))\n",
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='weighted', sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_dev = model.predict([meta_dev, title_dev, desc_dev, x_dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_prob_dev,\"dev_results\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dev = y_prob_dev.copy()\n",
    "y_pred_dev[y_pred_dev>=P_THRESHOLD] = 1\n",
    "y_pred_dev[y_pred_dev<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro: (0.85547355473554731, 0.80872093023255809, 0.83144052600119545, None)\n",
      "macro: (0.73534006609310076, 0.7859479742417822, 0.75019336121687819, None)\n",
      "weightedmacro: (0.85730461885311171, 0.80872093023255809, 0.82884073909017519, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('micro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='micro', sample_weight=None)))\n",
    "print('macro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='macro', sample_weight=None)))\n",
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='weighted', sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weightedmacro: (array([ 1.        ,  1.        ,  0.97142857,  0.78571429,  1.        ,\n",
      "        0.625     ,  0.6       ,  0.75625   ,  1.        ,  0.91304348,\n",
      "        1.        ,  0.99655568,  1.        ,  0.        ,  0.825     ,\n",
      "        1.        ,  0.82758621,  1.        ,  0.        ,  0.77464789,\n",
      "        0.88712522,  0.64646465,  0.81192661,  0.        ,  0.66666667,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.63636364,  0.92592593,  0.625     ,  0.        ,  0.69565217,\n",
      "        0.84708738,  0.5       ,  0.66666667,  0.77039275,  0.88235294,\n",
      "        0.77272727,  0.        ,  0.66666667,  0.80116959,  1.        ,\n",
      "        1.        ,  0.51428571,  0.90909091,  0.        ,  0.8       ,\n",
      "        0.79881657,  1.        ,  1.        ,  0.28571429,  1.        ,\n",
      "        0.66666667,  1.        ,  1.        ,  0.91509434,  0.5       ,\n",
      "        0.7768595 ,  0.8125    ,  0.7       ,  0.5       ,  0.69444444,\n",
      "        0.5       ,  0.80916031,  0.70873786,  1.        ,  1.        ,\n",
      "        0.76190476,  0.        ,  1.        ,  1.        ,  0.66129032,\n",
      "        0.83333333,  0.93243243,  0.82733813,  0.        ,  0.8959276 ,\n",
      "        0.        ,  0.95      ,  0.65      ,  0.90977444,  0.89528193,\n",
      "        1.        ,  0.        ,  0.77857143,  0.5       ,  1.        ,\n",
      "        0.85714286,  0.69565217,  0.        ,  0.86666667,  0.85198556,\n",
      "        0.7962963 ,  0.5       ,  1.        ,  0.90909091,  0.82608696,\n",
      "        0.78787879,  0.86813187,  0.93197279,  0.7037037 ,  1.        ,\n",
      "        0.88888889,  1.        ,  0.825     ,  0.        ,  0.57142857,\n",
      "        0.7826087 ,  0.        ,  0.6       ,  0.81818182,  1.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.75      ,  0.79146919,\n",
      "        0.55769231,  0.71153846,  0.73076923,  0.85714286,  0.91428571,\n",
      "        0.99148936,  1.        ,  0.82758621,  0.        ,  0.9266055 ,\n",
      "        0.        ,  1.        ,  1.        ,  1.        ,  0.66666667,\n",
      "        0.75051546,  0.73333333,  0.83411215,  0.84536082,  0.        ,\n",
      "        1.        ,  1.        ,  0.        ,  1.        ,  0.92982456,\n",
      "        0.91304348,  0.78070175,  0.95918367,  0.38461538,  1.        ,\n",
      "        0.        ,  0.        ,  0.88712871,  0.        ,  1.        ,\n",
      "        0.        ,  0.82758621,  0.97297297,  0.70588235,  0.92857143,\n",
      "        1.        ,  0.66666667,  0.92924528,  0.8045977 ,  0.89361702,\n",
      "        0.85714286,  0.7       ,  0.83333333,  0.92      ,  0.85251799,\n",
      "        0.89473684,  0.5       ,  0.        ,  0.52941176,  1.        ,\n",
      "        0.73109244,  0.875     ,  0.93333333,  0.75      ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.80952381,  0.66666667,\n",
      "        0.9047619 ,  0.89655172,  0.83333333,  0.51851852,  0.8596882 ,\n",
      "        1.        ,  0.        ,  0.7628866 ,  0.8       ,  0.71428571,\n",
      "        0.83333333,  1.        ,  0.68372703,  1.        ,  0.625     ,\n",
      "        1.        ,  0.9       ,  0.8125    ,  0.98571429,  0.        ,\n",
      "        1.        ,  0.91780822,  0.85714286,  0.775     ,  0.61538462,\n",
      "        0.88607595,  0.83707865,  0.        ,  0.76190476,  1.        ,\n",
      "        1.        ,  0.83333333,  0.9197861 ]), array([ 1.        ,  1.        ,  0.87931034,  0.91666667,  1.        ,\n",
      "        0.63829787,  1.        ,  0.71597633,  1.        ,  0.875     ,\n",
      "        1.        ,  0.99086758,  1.        ,  0.        ,  0.75      ,\n",
      "        1.        ,  0.96      ,  1.        ,  0.        ,  0.87301587,\n",
      "        0.79968203,  0.68085106,  0.83886256,  0.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.8       ,\n",
      "        0.78959276,  1.        ,  0.8       ,  0.67105263,  1.        ,\n",
      "        0.36956522,  0.        ,  0.47826087,  0.88961039,  1.        ,\n",
      "        0.99894958,  0.81818182,  1.        ,  0.        ,  0.95238095,\n",
      "        0.82822086,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.88719512,  0.9       ,\n",
      "        0.59119497,  1.        ,  1.        ,  0.8       ,  0.67567568,\n",
      "        1.        ,  0.50961538,  0.73737374,  1.        ,  0.93846154,\n",
      "        0.94117647,  0.        ,  1.        ,  1.        ,  0.5942029 ,\n",
      "        0.96153846,  0.82142857,  0.80701754,  0.        ,  0.78884462,\n",
      "        0.        ,  0.76      ,  1.        ,  0.76582278,  0.82415254,\n",
      "        1.        ,  0.        ,  0.55050505,  1.        ,  1.        ,\n",
      "        1.        ,  0.94117647,  0.        ,  0.8643617 ,  0.78929766,\n",
      "        0.64179104,  1.        ,  1.        ,  1.        ,  0.95      ,\n",
      "        0.7027027 ,  0.79      ,  0.84567901,  0.82608696,  1.        ,\n",
      "        1.        ,  1.        ,  0.89189189,  0.        ,  1.        ,\n",
      "        1.        ,  0.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.        ,  1.        ,  0.        ,  1.        ,  0.71982759,\n",
      "        0.85294118,  0.67272727,  0.9047619 ,  1.        ,  0.84210526,\n",
      "        0.9748954 ,  1.        ,  0.56692913,  0.        ,  0.94392523,\n",
      "        0.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.85046729,  1.        ,  0.82258065,  0.9010989 ,  0.        ,\n",
      "        1.        ,  1.        ,  0.        ,  1.        ,  0.63855422,\n",
      "        0.95454545,  0.84761905,  0.79661017,  1.        ,  1.        ,\n",
      "        0.        ,  0.        ,  0.86153846,  0.        ,  1.        ,\n",
      "        0.        ,  0.85714286,  0.94736842,  0.46153846,  1.        ,\n",
      "        1.        ,  1.        ,  0.92488263,  0.77777778,  0.73255814,\n",
      "        0.93333333,  1.        ,  0.56603774,  0.84662577,  0.7745098 ,\n",
      "        0.7816092 ,  1.        ,  0.        ,  1.        ,  1.        ,\n",
      "        0.63970588,  0.77777778,  0.66141732,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.89473684,  1.        ,\n",
      "        0.79166667,  0.79591837,  1.        ,  0.93333333,  0.69927536,\n",
      "        1.        ,  0.        ,  0.74747475,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.58870056,  1.        ,  0.60606061,\n",
      "        1.        ,  1.        ,  1.        ,  0.92      ,  0.        ,\n",
      "        1.        ,  0.95035461,  0.69565217,  0.83783784,  1.        ,\n",
      "        0.83333333,  0.84180791,  0.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.95555556]), array([ 1.        ,  1.        ,  0.92307692,  0.84615385,  1.        ,\n",
      "        0.63157895,  0.75      ,  0.73556231,  1.        ,  0.89361702,\n",
      "        1.        ,  0.99370349,  1.        ,  0.        ,  0.78571429,\n",
      "        1.        ,  0.88888889,  1.        ,  0.        ,  0.82089552,\n",
      "        0.84113712,  0.66321244,  0.82517483,  0.        ,  0.8       ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.77777778,  0.96153846,  0.76923077,  0.        ,  0.74418605,\n",
      "        0.81733021,  0.66666667,  0.72727273,  0.71729958,  0.9375    ,\n",
      "        0.5       ,  0.        ,  0.55696203,  0.84307692,  1.        ,\n",
      "        0.99947451,  0.63157895,  0.95238095,  0.        ,  0.86956522,\n",
      "        0.81325301,  1.        ,  1.        ,  0.44444444,  1.        ,\n",
      "        0.8       ,  1.        ,  1.        ,  0.90092879,  0.64285714,\n",
      "        0.67142857,  0.89655172,  0.82352941,  0.61538462,  0.68493151,\n",
      "        0.66666667,  0.62536873,  0.72277228,  1.        ,  0.96825397,\n",
      "        0.84210526,  0.        ,  1.        ,  1.        ,  0.6259542 ,\n",
      "        0.89285714,  0.87341772,  0.81705151,  0.        ,  0.83898305,\n",
      "        0.        ,  0.84444444,  0.78787879,  0.83161512,  0.858246  ,\n",
      "        1.        ,  0.        ,  0.64497041,  0.66666667,  1.        ,\n",
      "        0.92307692,  0.8       ,  0.        ,  0.86551265,  0.81944444,\n",
      "        0.7107438 ,  0.66666667,  1.        ,  0.95238095,  0.88372093,\n",
      "        0.74285714,  0.82722513,  0.88673139,  0.76      ,  1.        ,\n",
      "        0.94117647,  1.        ,  0.85714286,  0.        ,  0.72727273,\n",
      "        0.87804878,  0.        ,  0.75      ,  0.9       ,  1.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.85714286,  0.75395034,\n",
      "        0.6744186 ,  0.69158879,  0.80851064,  0.92307692,  0.87671233,\n",
      "        0.98312236,  1.        ,  0.6728972 ,  0.        ,  0.93518519,\n",
      "        0.        ,  1.        ,  1.        ,  1.        ,  0.8       ,\n",
      "        0.7973713 ,  0.84615385,  0.82830626,  0.87234043,  0.        ,\n",
      "        1.        ,  1.        ,  0.        ,  1.        ,  0.75714286,\n",
      "        0.93333333,  0.81278539,  0.87037037,  0.55555556,  1.        ,\n",
      "        0.        ,  0.        ,  0.87414634,  0.        ,  1.        ,\n",
      "        0.        ,  0.84210526,  0.96      ,  0.55813953,  0.96296296,\n",
      "        1.        ,  0.8       ,  0.92705882,  0.79096045,  0.80511182,\n",
      "        0.89361702,  0.82352941,  0.6741573 ,  0.88178914,  0.81164384,\n",
      "        0.83435583,  0.66666667,  0.        ,  0.69230769,  1.        ,\n",
      "        0.68235294,  0.82352941,  0.77419355,  0.85714286,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.85      ,  0.8       ,\n",
      "        0.84444444,  0.84324324,  0.90909091,  0.66666667,  0.77122877,\n",
      "        1.        ,  0.        ,  0.75510204,  0.88888889,  0.83333333,\n",
      "        0.90909091,  1.        ,  0.63266545,  1.        ,  0.61538462,\n",
      "        1.        ,  0.94736842,  0.89655172,  0.95172414,  0.        ,\n",
      "        1.        ,  0.93379791,  0.768     ,  0.80519481,  0.76190476,\n",
      "        0.85889571,  0.83943662,  0.        ,  0.86486486,  1.        ,\n",
      "        1.        ,  0.90909091,  0.9373297 ]), array([   3,    7,  116,   12,   56,   47,    6,  169,    2,   24,    2,\n",
      "        876,    1,    0,   44,    1,   25,    1,    0,  126, 1258,  188,\n",
      "        211,    0,    4,    1,    6,    3,    3,   12,    7,   25,    5,\n",
      "          0,   40,  442,    3,   25,  380,   15,   92,    0,   46,  154,\n",
      "          1,  952,   22,   10,    0,   21,  163,    2,    4,    2,    1,\n",
      "          2,    3,    1,  328,   10,  159,   13,    7,    5,   37,    1,\n",
      "        208,   99,    1,   65,   17,    0,    6,    2,   69,   26,   84,\n",
      "        285,    0,  251,    0,   25,   13,  158,  944,    4,    0,  198,\n",
      "          1,    6,    6,   17,    0,  376,  299,   67,    3,    7,   10,\n",
      "         20,   37,  100,  324,   23,    3,   16,    6,   37,    0,    4,\n",
      "         18,    0,    6,    9,    3,    0,    2,    0,    6,  232,   34,\n",
      "         55,   21,   18,   76,  239,    3,  127,    0,  107,    0,    1,\n",
      "          1,    1,    2,  428,   11,  434,   91,    0,   10,    2,    0,\n",
      "          3,   83,   22,  105,   59,    5,    1,    0,    0,  520,    0,\n",
      "          4,    0,   28,  228,   78,   13,    2,    4,  213,   90,  172,\n",
      "         45,    7,   53,  163,  306,   87,    1,    0,    9,    3,  136,\n",
      "         18,  127,    3,    6,    1,    5,    4,   19,    2,   24,   98,\n",
      "          5,   15,  552,   10,    0,   99,    4,   10,    5,    1,  885,\n",
      "          6,   33,    1,    9,   13,   75,    0,    2,  141,  138,   37,\n",
      "          8,   84,  177,    0,   16,    3,    3,    5,  180]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average=None, sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_train,\"true_train\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_dev,\"true_dev\"+date_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(data_to_tag): \n",
    "    filename = data_to_tag+\"_arrays.npz\"\n",
    "    arrays = np.load(os.path.join(DATADIR,filename))\n",
    "    \n",
    "    print('Set up arrays for new_content: {}'.format(arrays.files))\n",
    "    x_predict = arrays['x']\n",
    "    meta_predict = arrays['meta'].all().todense()\n",
    "    title_predict = arrays['title'].all().todense()\n",
    "    desc_predict = arrays['desc'].all().todense()\n",
    "    \n",
    "    print('x_arrays.shape = {}'.format(x_predict.shape))\n",
    "    print('meta_arrays.shape = {}'.format(meta_predict.shape))\n",
    "    print('title_arrays.shape = {}'.format(title_predict.shape))\n",
    "    print('desc_arrays.shape = {}'.format(desc_predict.shape))\n",
    "    \n",
    "    print('Predict on untagged content')\n",
    "    y_pred_new = model.predict([meta_predict, title_predict, desc_predict, x_predict])\n",
    "    \n",
    "    to_file(y_pred_new, data_to_tag+\"_predictions\"+date_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up arrays for new_content: ['x', 'meta', 'title', 'desc', 'content_id']\n",
      "x_arrays.shape = (87177, 1000)\n",
      "meta_arrays.shape = (87177, 535)\n",
      "title_arrays.shape = (87177, 10000)\n",
      "desc_arrays.shape = (87177, 10000)\n",
      "Predict on untagged content\n"
     ]
    }
   ],
   "source": [
    "get_predictions(\"new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up arrays for new_content: ['x', 'meta', 'title', 'desc', 'content_id']\n",
      "x_arrays.shape = (15984, 1000)\n",
      "meta_arrays.shape = (15984, 535)\n",
      "title_arrays.shape = (15984, 10000)\n",
      "desc_arrays.shape = (15984, 10000)\n",
      "Predict on untagged content\n"
     ]
    }
   ],
   "source": [
    "get_predictions(\"level1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "keep_output": true,
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
