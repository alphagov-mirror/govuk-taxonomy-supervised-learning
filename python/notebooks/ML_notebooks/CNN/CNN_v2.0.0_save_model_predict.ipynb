{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional NN to classify govuk content to level2 taxons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on:\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load requirements and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.utils import to_categorical, layer_utils, plot_model\n",
    "\n",
    "from keras.layers import (Embedding, Input, Dense, Dropout, \n",
    "                          Activation, Conv1D, MaxPooling1D, Flatten, concatenate, Reshape)\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.callbacks import TensorBoard, Callback, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score \n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import functools\n",
    "\n",
    "import h5py\n",
    "\n",
    "from scipy import sparse\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environmental vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATADIR = os.getenv('DATADIR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print data version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm running on data extracted from content store on /data/2018-03-27\n"
     ]
    }
   ],
   "source": [
    "print('algorithm running on data extracted from content store on {}'.format(DATADIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuition for POS_RATIO is that it penalises the prediction of zero for everything, which is attractive to the model because the multilabel y matrix is super sparse. \n",
    "\n",
    "Increasing POS_RATIO should penalise predicting zeros more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MAX_NB_WORDS\n",
    "MAX_SEQUENCE_LENGTH =1000\n",
    "EMBEDDING_DIM = 100 # keras embedding layer output_dim = Dimension of the dense embedding\n",
    "P_THRESHOLD = 0.5 #Threshold for probability of being assigned to class\n",
    "POS_RATIO = 0.5 #ratio of positive to negative for each class in weighted binary cross entropy loss function\n",
    "NUM_WORDS=20000 #keras tokenizer num_words: None or int. Maximum number of words to work with \n",
    "#(if set, tokenization will be restricted to the top num_words most common words in the dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = np.load(os.path.join(DATADIR, 'train_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'meta', 'title', 'desc', 'y', 'content_id']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (179166, 1000)\n",
      "meta_train.shape = (179166, 529)\n",
      "title_train.shape = (179166, 10000)\n",
      "desc_train.shape = (179166, 10000)\n",
      "y_train.shape = (179166, 216)\n"
     ]
    }
   ],
   "source": [
    "x_train = train['x']\n",
    "meta_train = train['meta'].all().todense()\n",
    "title_train = train['title'].all().todense()\n",
    "desc_train = train['desc'].all().todense()\n",
    "y_train = train['y'].all().todense()\n",
    "\n",
    "print('x_train.shape = {}'.format(x_train.shape))\n",
    "print('meta_train.shape = {}'.format(meta_train.shape))\n",
    "print('title_train.shape = {}'.format(title_train.shape))\n",
    "print('desc_train.shape = {}'.format(desc_train.shape))\n",
    "print('y_train.shape = {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dev = np.load(os.path.join(DATADIR, 'dev_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_dev.shape = (13020, 1000)\n",
      "meta_dev.shape = (13020, 529)\n",
      "title_dev.shape = (13020, 10000)\n",
      "desc_dev.shape = (13020, 10000)\n",
      "y_dev.shape = (13020, 216)\n"
     ]
    }
   ],
   "source": [
    "x_dev = dev['x']\n",
    "meta_dev = dev['meta'].all().todense()\n",
    "title_dev = dev['title'].all().todense()\n",
    "desc_dev = dev['desc'].all().todense()\n",
    "y_dev = dev['y'].all().todense()\n",
    "\n",
    "print('x_dev.shape = {}'.format(x_dev.shape))\n",
    "print('meta_dev.shape = {}'.format(meta_dev.shape))\n",
    "print('title_dev.shape = {}'.format(title_dev.shape))\n",
    "print('desc_dev.shape = {}'.format(desc_dev.shape))\n",
    "print('y_dev.shape = {}'.format(y_dev.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = np.load(os.path.join(DATADIR, 'test_arrays.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test.shape = (13022, 1000)\n",
      "meta_test.shape = (13022, 529)\n",
      "title_test.shape = (13022, 10000)\n",
      "desc_test.shape = (13022, 10000)\n",
      "y_test.shape = (13022, 216)\n"
     ]
    }
   ],
   "source": [
    "x_test = test['x']\n",
    "meta_test = test['meta'].all().todense()\n",
    "title_test = test['title'].all().todense()\n",
    "desc_test = test['desc'].all().todense()\n",
    "y_test = test['y'].all().todense()\n",
    "\n",
    "print('x_test.shape = {}'.format(x_test.shape))\n",
    "print('meta_test.shape = {}'.format(meta_test.shape))\n",
    "print('title_test.shape = {}'.format(title_test.shape))\n",
    "print('desc_test.shape = {}'.format(desc_test.shape))\n",
    "print('y_test.shape = {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### previous shapes in old data \n",
    "Shape of x_train: (150870, 1000)\n",
    "Shape of metax_train: (150870, 436)\n",
    "Shape of titlex_train: (150870, 10000)\n",
    "Shape of descx_train: (150870, 10000)\n",
    "Shape of y_train: (150870, 210)\n",
    "\n",
    "Shape of x_dev: (9234, 1000)\n",
    "Shape of meta_dev: (9234, 436)\n",
    "Shape of titlex_dev: (9234, 10000)\n",
    "Shape of descx_dev: (9234, 10000)\n",
    "Shape of y_dev: (9234, 210)\n",
    "\n",
    "Shape of x_test: (9234, 1000)\n",
    "Shape of metax_test: (9234, 436)\n",
    "Shape of titlex_test: (9234, 10000)\n",
    "Shape of descx_test: (9234, 10000)\n",
    "Shape of y_test: (9234, 210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing the Embedding layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "def load_tokenizer_from_file(filename):\n",
    "    \n",
    "    tokenizer = Tokenizer()\n",
    "\n",
    "    with open(filename, 'r') as infile:\n",
    "        tokenizer_data = json.load(infile)\n",
    "\n",
    "    tokenizer.word_counts = OrderedDict(tokenizer_data['word_counts'])\n",
    "    tokenizer.word_docs = tokenizer_data['word_docs']\n",
    "    tokenizer.word_index = tokenizer_data['word_index']\n",
    "    tokenizer.document_count = tokenizer_data['document_count']\n",
    "    tokenizer.index_docs = tokenizer_data['index_docs']\n",
    "\n",
    "    return tokenizer\n",
    "\n",
    "tokenizer_combined_text = load_tokenizer_from_file(os.path.join(DATADIR, \"combined_text_tokenizer.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(tokenizer_combined_text.word_index) + 1, \n",
    "                            EMBEDDING_DIM, \n",
    "                            input_length=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Embedding layer should be fed sequences of integers, i.e. a 2D input of shape (samples, indices). These input sequences should be padded so that they all have the same length in a batch of input data (although an Embedding layer is capable of processing sequence of heterogenous length, if you don't pass an explicit input_length argument to the layer).\n",
    "\n",
    "All that the Embedding layer does is to map the integer inputs to the vectors found at the corresponding index in the embedding matrix, i.e. the sequence [1, 2] would be converted to [embeddings[1], embeddings[2]]. This means that the output of the Embedding layer will be a 3D tensor of shape (samples, sequence_length, embedding_dim)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate class weights for unbalanced datasets.\n",
    "paramter to model.fit = __class_weight__: Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
    "\n",
    "Implement class_weight from sklearn:\n",
    "\n",
    "- Import the module \n",
    "\n",
    "`from sklearn.utils import class_weight`\n",
    "- calculate the class weight, If ‘balanced’, class weights will be given by n_samples / (n_classes * np.bincount(y)):\n",
    "\n",
    "`class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)`\n",
    "\n",
    "- change it to a dict in order to work with Keras.\n",
    "\n",
    "`class_weight_dict = dict(enumerate(class_weight))`\n",
    "\n",
    "- Add to model fitting\n",
    "\n",
    "`model.fit(X_train, y_train, class_weight=class_weight)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "# class_weight_dict = dict(enumerate(class_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.00756\n",
      "8.01512\n"
     ]
    }
   ],
   "source": [
    "class WeightedBinaryCrossEntropy(object):\n",
    "\n",
    "    def __init__(self, pos_ratio):\n",
    "        neg_ratio = 1. - pos_ratio\n",
    "        #self.pos_ratio = tf.constant(pos_ratio, tf.float32)\n",
    "        self.pos_ratio = pos_ratio\n",
    "        #self.weights = tf.constant(neg_ratio / pos_ratio, tf.float32)\n",
    "        self.weights = neg_ratio / pos_ratio\n",
    "        self.__name__ = \"weighted_binary_crossentropy({0})\".format(pos_ratio)\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        return self.weighted_binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "    def weighted_binary_crossentropy(self, y_true, y_pred):\n",
    "            # Transform to logits\n",
    "            epsilon = tf.convert_to_tensor(K.common._EPSILON, y_pred.dtype.base_dtype)\n",
    "            y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
    "            y_pred = tf.log(y_pred / (1 - y_pred))\n",
    "\n",
    "            cost = tf.nn.weighted_cross_entropy_with_logits(y_true, y_pred, self.weights)\n",
    "            return K.mean(cost * self.pos_ratio, axis=-1)\n",
    "    \n",
    "y_true_arr = np.array([0,1,0,1], dtype=\"float32\")\n",
    "y_pred_arr = np.array([0,0,1,1], dtype=\"float32\")\n",
    "y_true = tf.constant(y_true_arr)\n",
    "y_pred = tf.constant(y_pred_arr)\n",
    "\n",
    "with tf.Session().as_default(): \n",
    "    print(WeightedBinaryCrossEntropy(0.5)(y_true, y_pred).eval())\n",
    "    print(binary_crossentropy(y_true, y_pred).eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### difficulty getting global precision/recall metrics . CAUTION interpreting monitoring metrics\n",
    "fcholltet: \"Basically these are all global metrics that were approximated\n",
    "batch-wise, which is more misleading than helpful. This was mentioned in\n",
    "the docs but it's much cleaner to remove them altogether. It was a mistake\n",
    "to merge them in the first place.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    \"\"\"Use Recall  and precision metrics to calculate harmonic mean (F1 score).\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1 = 2*((precision*recall)/(precision+recall))\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a 1D convnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NB_CLASSES = y_train.shape[1]\n",
    "NB_METAVARS = meta_train.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='wordindex') #MAX_SEQUENCE_LENGTH\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Dropout(0.2, name = 'dropout_embedded')(embedded_sequences)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv0')(x)\n",
    "\n",
    "x = MaxPooling1D(5, name = 'max_pool0')(x)\n",
    "\n",
    "x = Dropout(0.5, name = 'dropout0')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv1')(x)\n",
    "\n",
    "x = MaxPooling1D(5 , name = 'max_pool1')(x)\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu', name = 'conv2')(x)\n",
    "\n",
    "x = MaxPooling1D(35, name = 'global_max_pool')(x)  # global max pooling\n",
    "\n",
    "x = Flatten()(x) #reduce dimensions from 3 to 2; convert to vector + FULLYCONNECTED\n",
    "\n",
    "meta_input = Input(shape=(NB_METAVARS,), name='meta')\n",
    "meta_hidden = Dense(128, activation='relu', name = 'hidden_meta')(meta_input)\n",
    "meta_hidden = Dropout(0.2, name = 'dropout_meta')(meta_hidden)\n",
    "\n",
    "\n",
    "title_input = Input(shape=(title_train.shape[1],), name='titles')\n",
    "title_hidden = Dense(128, activation='relu', name = 'hidden_title')(title_input)\n",
    "title_hidden = Dropout(0.2, name = 'dropout_title')(title_hidden)\n",
    "\n",
    "desc_input = Input(shape=(desc_train.shape[1],), name='descs')\n",
    "desc_hidden = Dense(128, activation='relu', name = 'hidden_desc')(desc_input)\n",
    "desc_hidden = Dropout(0.2, name = 'dropout_desc')(desc_hidden)\n",
    "\n",
    "concatenated = concatenate([meta_hidden, title_hidden, desc_hidden, x])\n",
    "\n",
    "x = Dense(400, activation='relu', name = 'fully_connected0')(concatenated)\n",
    "\n",
    "x = Dropout(0.2, name = 'dropout1')(x)\n",
    "\n",
    "x = Dense(NB_CLASSES, activation='sigmoid', name = 'fully_connected1')(x)\n",
    "\n",
    "# # The Model class turns an input tensor and output tensor into a model\n",
    "# This creates Keras model instance, will use this instance to train/test the model.\n",
    "model = Model(inputs=[meta_input, title_input, desc_input, sequence_input], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "wordindex (InputLayer)          (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 100)    35584400    wordindex[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_embedded (Dropout)      (None, 1000, 100)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv1D)                  (None, 996, 128)     64128       dropout_embedded[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pool0 (MaxPooling1D)        (None, 199, 128)     0           conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout0 (Dropout)              (None, 199, 128)     0           max_pool0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv1D)                  (None, 195, 128)     82048       dropout0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pool1 (MaxPooling1D)        (None, 39, 128)      0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "meta (InputLayer)               (None, 529)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "titles (InputLayer)             (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "descs (InputLayer)              (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv1D)                  (None, 35, 128)      82048       max_pool1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hidden_meta (Dense)             (None, 128)          67840       meta[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "hidden_title (Dense)            (None, 128)          1280128     titles[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "hidden_desc (Dense)             (None, 128)          1280128     descs[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pool (MaxPooling1D)  (None, 1, 128)       0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_meta (Dropout)          (None, 128)          0           hidden_meta[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_title (Dropout)         (None, 128)          0           hidden_title[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_desc (Dropout)          (None, 128)          0           hidden_desc[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           global_max_pool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           dropout_meta[0][0]               \n",
      "                                                                 dropout_title[0][0]              \n",
      "                                                                 dropout_desc[0][0]               \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fully_connected0 (Dense)        (None, 400)          205200      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 400)          0           fully_connected0[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fully_connected1 (Dense)        (None, 216)          86616       dropout1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 38,732,536\n",
      "Trainable params: 38,732,536\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard callbacks /metrics /monitor training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **Size of these files is killing storage during training. Is it histograms?**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tb = TensorBoard(log_dir='./learn_embedding_logs', histogram_freq=1, write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = os.path.join(DATADIR, 'model_checkpoint.hdf5')\n",
    "\n",
    "cp = ModelCheckpoint(\n",
    "                     filepath = CHECKPOINT_PATH, \n",
    "                     monitor='val_loss', \n",
    "                     verbose=0, \n",
    "                     save_best_only=False, \n",
    "                     save_weights_only=False, \n",
    "                     mode='auto', \n",
    "                     period=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "#model.fit(x, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 & 3. Train & compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 179166 samples, validate on 13020 samples\n",
      "Epoch 1/10\n",
      "179166/179166 [==============================] - 188s 1ms/step - loss: 0.0086 - binary_accuracy: 0.9951 - f1: nan - val_loss: 0.0039 - val_binary_accuracy: 0.9973 - val_f1: 0.7734\n",
      "Epoch 2/10\n",
      "179166/179166 [==============================] - 183s 1ms/step - loss: 0.0030 - binary_accuracy: 0.9980 - f1: 0.8629 - val_loss: 0.0035 - val_binary_accuracy: 0.9976 - val_f1: 0.8083\n",
      "Epoch 3/10\n",
      "179166/179166 [==============================] - 183s 1ms/step - loss: 0.0023 - binary_accuracy: 0.9985 - f1: 0.8979 - val_loss: 0.0033 - val_binary_accuracy: 0.9978 - val_f1: 0.8194\n",
      "Epoch 4/10\n",
      "179166/179166 [==============================] - 183s 1ms/step - loss: 0.0020 - binary_accuracy: 0.9987 - f1: 0.9151 - val_loss: 0.0033 - val_binary_accuracy: 0.9978 - val_f1: 0.8276\n",
      "Epoch 5/10\n",
      "179166/179166 [==============================] - 183s 1ms/step - loss: 0.0017 - binary_accuracy: 0.9989 - f1: 0.9252 - val_loss: 0.0034 - val_binary_accuracy: 0.9979 - val_f1: 0.8297\n",
      "Epoch 6/10\n",
      "179166/179166 [==============================] - 183s 1ms/step - loss: 0.0016 - binary_accuracy: 0.9989 - f1: 0.9309 - val_loss: 0.0035 - val_binary_accuracy: 0.9979 - val_f1: 0.8315\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=WeightedBinaryCrossEntropy(POS_RATIO),\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['binary_accuracy', f1])\n",
    "\n",
    "# This `fit` call will be distributed on 8 GPUs.\n",
    "# Since the batch size is 256, each GPU will process 32 samples.\n",
    "history = model.fit(\n",
    "    {'meta': meta_train, 'titles': title_train, 'descs': desc_train, 'wordindex': x_train},\n",
    "    y_train, \n",
    "    validation_data=([meta_dev, title_dev, desc_dev, x_dev], y_dev), \n",
    "    epochs=10, batch_size=128, callbacks=[early_stopping]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_binary_accuracy', 'val_f1', 'loss', 'binary_accuracy', 'f1'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzKwo/x9pZiUIZ0himQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd0d11a5c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(range(len(loss_values)), loss_values, 'bo', label='Training loss')           \n",
    "plt.plot(range(len(val_loss_values)), val_loss_values, 'b', label='Validation loss')      \n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd0d0afdf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()    \n",
    "\n",
    "f1_values = history_dict['f1']\n",
    "val_f1_values = history_dict['val_f1']\n",
    "\n",
    "plt.plot(range(len(f1_values)), f1_values, 'bo', label='Training f1')\n",
    "plt.plot(range(len(val_f1_values)), val_f1_values, 'b', label='Validation f1')\n",
    "plt.title('Training and validation batch-level f1-micro')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1-micro')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_file(array,name):\n",
    "    df = pd.DataFrame(data = array.tolist(),columns=[i for i in range(1,y_train.shape[1]+1)])\n",
    "    df.to_csv(os.path.join(DATADIR, name+'.csv.gz'),compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict([meta_train, title_train, desc_train, x_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_prob,\"train_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_prob.copy()\n",
    "y_pred[y_pred>=P_THRESHOLD] = 1\n",
    "y_pred[y_pred<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro: (0.96087221864845695, 0.95438341262663995, 0.95761682373576229, None)\n",
      "macro: (0.97612390318920661, 0.97162071199874112, 0.97359360595384603, None)\n",
      "weightedmacro: (0.96142540788192132, 0.95438341262663995, 0.95747751270259429, None)\n"
     ]
    }
   ],
   "source": [
    "print('micro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='micro', sample_weight=None)))\n",
    "print('macro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='macro', sample_weight=None)))\n",
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_train, y_pred, average='weighted', sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_dev = model.predict([meta_dev, title_dev, desc_dev, x_dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_prob_dev,\"dev_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dev = y_prob_dev.copy()\n",
    "y_pred_dev[y_pred_dev>=P_THRESHOLD] = 1\n",
    "y_pred_dev[y_pred_dev<P_THRESHOLD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro: (0.84049357559291338, 0.82211272284353887, 0.83120154496347498, None)\n",
      "macro: (0.80190499495089373, 0.85726866171762006, 0.82000987119737301, None)\n",
      "weightedmacro: (0.84541911329588237, 0.82211272284353887, 0.83002450733175637, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('micro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='micro', sample_weight=None)))\n",
    "print('macro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='macro', sample_weight=None)))\n",
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average='weighted', sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weightedmacro: (array([ 1.        ,  0.88888889,  0.93965517,  0.5       ,  1.        ,\n",
      "        0.61538462,  0.8       ,  0.70614035,  1.        ,  1.        ,\n",
      "        0.99672489,  1.        ,  1.        ,  0.8372093 ,  1.        ,\n",
      "        0.65789474,  1.        ,  0.75384615,  0.86468647,  0.85185185,\n",
      "        0.83712121,  0.        ,  0.625     ,  1.        ,  1.        ,\n",
      "        1.        ,  0.5       ,  0.93333333,  0.9375    ,  0.83333333,\n",
      "        0.85714286,  0.        ,  0.59183673,  0.79253112,  0.5       ,\n",
      "        0.81818182,  0.76129032,  0.8       ,  0.68181818,  0.        ,\n",
      "        0.74418605,  0.78431373,  0.66666667,  0.99796126,  0.9       ,\n",
      "        1.        ,  1.        ,  0.86956522,  0.75      ,  1.        ,\n",
      "        1.        ,  0.76923077,  0.        ,  0.71428571,  1.        ,\n",
      "        1.        ,  0.91958042,  0.64705882,  0.86567164,  0.78571429,\n",
      "        0.        ,  0.8       ,  0.80487805,  1.        ,  0.81879195,\n",
      "        0.78448276,  1.        ,  0.97468354,  0.65384615,  1.        ,\n",
      "        1.        ,  1.        ,  0.66129032,  0.85714286,  0.93333333,\n",
      "        0.8466899 ,  1.        ,  0.84814815,  1.        ,  0.77142857,\n",
      "        0.71428571,  0.8908046 ,  0.87451488,  0.66666667,  1.        ,\n",
      "        0.71794872,  1.        ,  1.        ,  1.        ,  0.60869565,\n",
      "        0.5       ,  0.8856305 ,  0.75375375,  0.76923077,  1.        ,\n",
      "        0.92105263,  0.88888889,  0.64444444,  0.84057971,  0.925     ,\n",
      "        0.72093023,  1.        ,  0.83333333,  0.66666667,  0.86363636,\n",
      "        1.        ,  0.66666667,  0.95238095,  1.        ,  0.55555556,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.57142857,  0.78278689,  0.6744186 ,  0.82      ,  0.66666667,\n",
      "        0.76190476,  0.89041096,  0.98222222,  1.        ,  0.82142857,\n",
      "        0.        ,  0.91752577,  1.        ,  1.        ,  0.66666667,\n",
      "        1.        ,  0.91666667,  0.83538084,  0.94736842,  0.82194617,\n",
      "        0.84615385,  1.        ,  0.83333333,  1.        ,  1.        ,\n",
      "        1.        ,  0.84615385,  0.84210526,  0.83739837,  0.75862069,\n",
      "        0.46153846,  1.        ,  1.        ,  1.        ,  0.89756944,\n",
      "        0.        ,  0.        ,  1.        ,  0.93548387,  0.95275591,\n",
      "        0.94285714,  0.77192982,  0.85714286,  1.        ,  1.        ,\n",
      "        0.90987124,  0.84269663,  0.88947368,  0.77777778,  0.66666667,\n",
      "        0.77777778,  0.85549133,  0.84246575,  0.8313253 ,  0.        ,\n",
      "        0.        ,  0.77777778,  0.        ,  0.6640625 ,  0.84615385,\n",
      "        0.75193798,  0.5       ,  0.66666667,  0.        ,  1.        ,\n",
      "        1.        ,  0.73913043,  0.91666667,  0.75      ,  0.90740741,\n",
      "        0.81818182,  0.45833333,  0.76090468,  0.8       ,  0.78082192,\n",
      "        0.8       ,  0.66666667,  0.33333333,  1.        ,  1.        ,\n",
      "        0.62026515,  0.5       ,  0.59259259,  0.75      ,  1.        ,\n",
      "        0.8       ,  0.89705882,  1.        ,  1.        ,  0.88965517,\n",
      "        0.91666667,  0.79545455,  0.8       ,  0.90163934,  0.86982249,\n",
      "        1.        ,  0.84210526,  1.        ,  1.        ,  1.        ,\n",
      "        0.93377483]), array([ 1.        ,  1.        ,  0.92372881,  0.84615385,  1.        ,\n",
      "        0.62745098,  1.        ,  0.81313131,  1.        ,  1.        ,\n",
      "        0.99347116,  1.        ,  1.        ,  0.87804878,  1.        ,\n",
      "        1.        ,  1.        ,  0.784     ,  0.83042789,  0.63888889,\n",
      "        0.88047809,  0.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  0.88235294,\n",
      "        1.        ,  0.        ,  0.85294118,  0.83406114,  1.        ,\n",
      "        0.79411765,  0.6344086 ,  1.        ,  0.48913043,  0.        ,\n",
      "        0.52459016,  0.8       ,  1.        ,  0.99796126,  0.75      ,\n",
      "        1.        ,  1.        ,  0.86956522,  0.81456954,  1.        ,\n",
      "        1.        ,  1.        ,  0.        ,  1.        ,  1.        ,\n",
      "        1.        ,  0.88552189,  1.        ,  0.59487179,  1.        ,\n",
      "        0.        ,  1.        ,  0.75      ,  1.        ,  0.5       ,\n",
      "        0.7109375 ,  1.        ,  0.95061728,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.62121212,  0.97297297,  0.8045977 ,\n",
      "        0.82094595,  1.        ,  0.90513834,  1.        ,  0.93103448,\n",
      "        1.        ,  0.88571429,  0.79529412,  1.        ,  1.        ,\n",
      "        0.53164557,  1.        ,  1.        ,  1.        ,  0.875     ,\n",
      "        1.        ,  0.81401617,  0.80707395,  0.65934066,  1.        ,\n",
      "        0.97222222,  0.94117647,  0.87878788,  0.59793814,  0.85824742,\n",
      "        0.96875   ,  1.        ,  1.        ,  1.        ,  0.79166667,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.95454545,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  0.77016129,  0.85294118,  0.6119403 ,  0.95238095,\n",
      "        1.        ,  0.90277778,  0.95258621,  1.        ,  0.54330709,\n",
      "        0.        ,  0.94680851,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.77448747,  0.94736842,  0.84110169,\n",
      "        0.92436975,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  0.77464789,  0.94117647,  0.83739837,  0.78571429,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  0.87775891,\n",
      "        0.        ,  0.        ,  1.        ,  0.82857143,  0.93436293,\n",
      "        0.89189189,  0.50574713,  1.        ,  1.        ,  1.        ,\n",
      "        0.89451477,  0.65217391,  0.75784753,  0.95454545,  0.93333333,\n",
      "        0.63636364,  0.87058824,  0.82550336,  0.76666667,  0.        ,\n",
      "        0.        ,  0.875     ,  0.        ,  0.61151079,  0.88      ,\n",
      "        0.7238806 ,  1.        ,  1.        ,  0.        ,  1.        ,\n",
      "        1.        ,  0.94444444,  1.        ,  0.92307692,  0.79674797,\n",
      "        1.        ,  0.91666667,  0.79830508,  1.        ,  0.64044944,\n",
      "        1.        ,  0.85714286,  1.        ,  1.        ,  1.        ,\n",
      "        0.73102679,  1.        ,  0.91428571,  1.        ,  1.        ,\n",
      "        0.86956522,  0.89705882,  1.        ,  1.        ,  0.92805755,\n",
      "        0.81481481,  0.83333333,  0.92307692,  0.76388889,  0.72413793,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.8757764 ]), array([ 1.        ,  0.94117647,  0.93162393,  0.62857143,  1.        ,\n",
      "        0.62135922,  0.88888889,  0.75586854,  1.        ,  1.        ,\n",
      "        0.99509537,  1.        ,  1.        ,  0.85714286,  1.        ,\n",
      "        0.79365079,  1.        ,  0.76862745,  0.84721099,  0.73015873,\n",
      "        0.85825243,  0.        ,  0.76923077,  1.        ,  1.        ,\n",
      "        1.        ,  0.66666667,  0.96551724,  0.96774194,  0.85714286,\n",
      "        0.92307692,  0.        ,  0.69879518,  0.81276596,  0.66666667,\n",
      "        0.80597015,  0.69208211,  0.88888889,  0.56962025,  0.        ,\n",
      "        0.61538462,  0.79207921,  0.8       ,  0.99796126,  0.81818182,\n",
      "        1.        ,  1.        ,  0.86956522,  0.78095238,  1.        ,\n",
      "        1.        ,  0.86956522,  0.        ,  0.83333333,  1.        ,\n",
      "        1.        ,  0.90222985,  0.78571429,  0.70516717,  0.88      ,\n",
      "        0.        ,  0.88888889,  0.77647059,  1.        ,  0.62086514,\n",
      "        0.74590164,  1.        ,  0.9625    ,  0.79069767,  1.        ,\n",
      "        1.        ,  1.        ,  0.640625  ,  0.91139241,  0.86419753,\n",
      "        0.83361921,  1.        ,  0.87571702,  1.        ,  0.84375   ,\n",
      "        0.83333333,  0.88825215,  0.83302526,  0.8       ,  1.        ,\n",
      "        0.61090909,  1.        ,  1.        ,  1.        ,  0.71794872,\n",
      "        0.66666667,  0.84831461,  0.77950311,  0.71005917,  1.        ,\n",
      "        0.94594595,  0.91428571,  0.74358974,  0.69879518,  0.89037433,\n",
      "        0.82666667,  1.        ,  0.90909091,  0.8       ,  0.82608696,\n",
      "        1.        ,  0.8       ,  0.97560976,  1.        ,  0.71428571,\n",
      "        0.97674419,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.72727273,  0.77642276,  0.75324675,  0.7008547 ,  0.78431373,\n",
      "        0.86486486,  0.89655172,  0.96717724,  1.        ,  0.65402844,\n",
      "        0.        ,  0.93193717,  1.        ,  1.        ,  0.8       ,\n",
      "        1.        ,  0.95652174,  0.80378251,  0.94736842,  0.83141361,\n",
      "        0.88353414,  1.        ,  0.90909091,  1.        ,  1.        ,\n",
      "        1.        ,  0.80882353,  0.88888889,  0.83739837,  0.77192982,\n",
      "        0.63157895,  1.        ,  1.        ,  1.        ,  0.88755365,\n",
      "        0.        ,  0.        ,  1.        ,  0.87878788,  0.94346979,\n",
      "        0.91666667,  0.61111111,  0.92307692,  1.        ,  1.        ,\n",
      "        0.90212766,  0.73529412,  0.81840194,  0.85714286,  0.77777778,\n",
      "        0.7       ,  0.86297376,  0.83389831,  0.79768786,  0.        ,\n",
      "        0.        ,  0.82352941,  0.        ,  0.63670412,  0.8627451 ,\n",
      "        0.73764259,  0.66666667,  0.8       ,  0.        ,  1.        ,\n",
      "        1.        ,  0.82926829,  0.95652174,  0.82758621,  0.84848485,\n",
      "        0.9       ,  0.61111111,  0.77915633,  0.88888889,  0.7037037 ,\n",
      "        0.88888889,  0.75      ,  0.5       ,  1.        ,  1.        ,\n",
      "        0.67110656,  0.66666667,  0.71910112,  0.85714286,  1.        ,\n",
      "        0.83333333,  0.89705882,  1.        ,  1.        ,  0.9084507 ,\n",
      "        0.8627451 ,  0.81395349,  0.85714286,  0.82706767,  0.79032258,\n",
      "        1.        ,  0.91428571,  1.        ,  1.        ,  1.        ,\n",
      "        0.90384615]), array([   2,    8,  118,   13,   53,   51,   12,  198,    1,    3,  919,\n",
      "          5,    2,   41,    1,   25,    2,  125, 1262,  216,  251,    0,\n",
      "          5,    7,    2,    3,    1,   14,   15,   17,    6,    0,   34,\n",
      "        458,    2,   34,  372,   12,   92,    0,   61,  150,    4,  981,\n",
      "         36,    4,    1,   23,  151,    2,    6,   10,    0,    5,    2,\n",
      "          1,  297,   11,  195,   11,    0,   12,   44,    5,  244,  128,\n",
      "          2,   81,   17,    1,    4,    6,   66,   37,   87,  296,    1,\n",
      "        253,    1,   29,   15,  175,  850,    2,    1,  158,    1,    4,\n",
      "          3,   16,    1,  371,  311,   91,    6,   36,   34,   33,   97,\n",
      "        388,   32,    2,   15,    2,   48,    1,    6,   20,    3,    5,\n",
      "         22,    1,    1,    2,    3,    4,  248,   34,   67,   21,   16,\n",
      "         72,  232,    4,  127,    0,   94,    2,    1,    4,    1,   11,\n",
      "        439,   19,  472,  119,    1,   10,    1,    2,    5,   71,   17,\n",
      "        123,   56,    6,    4,    1,    3,  589,    0,    0,    1,   35,\n",
      "        259,   37,   87,    6,    4,    4,  237,  115,  223,   44,   15,\n",
      "         77,  170,  298,   90,    0,    0,    8,    0,  139,   25,  134,\n",
      "          2,    4,    0,    6,    8,   18,   11,   13,  123,    9,   12,\n",
      "        590,   12,   89,    8,    7,    1,    2,    4,  896,    3,   35,\n",
      "          3,    6,   23,   68,    1,    1,  139,  162,   42,   13,   72,\n",
      "        203,    2,   16,    2,    1,    7,  161]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('weightedmacro: {}'.format(precision_recall_fscore_support(y_dev, y_pred_dev, average=None, sample_weight=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_train,\"true_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file(y_dev,\"true_dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(data_to_tag): \n",
    "    filename = data_to_tag+\"_arrays.npz\"\n",
    "    arrays = np.load(os.path.join(DATADIR,filename))\n",
    "    \n",
    "    print('Set up arrays for new_content: {}'.format(arrays.files))\n",
    "    x_predict = arrays['x']\n",
    "    meta_predict = arrays['meta'].all().todense()\n",
    "    title_predict = arrays['title'].all().todense()\n",
    "    desc_predict = arrays['desc'].all().todense()\n",
    "    \n",
    "    print('x_arrays.shape = {}'.format(x_predict.shape))\n",
    "    print('meta_arrays.shape = {}'.format(meta_predict.shape))\n",
    "    print('title_arrays.shape = {}'.format(title_predict.shape))\n",
    "    print('desc_arrays.shape = {}'.format(desc_predict.shape))\n",
    "    \n",
    "    print('Predict on untagged content')\n",
    "    y_pred_new = model.predict([meta_predict, title_predict, desc_predict, x_predict])\n",
    "    \n",
    "    to_file(y_pred_new, data_to_tag+\"_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up arrays for new_content: ['x', 'meta', 'title', 'desc', 'content_id']\n",
      "x_arrays.shape = (68049, 1000)\n",
      "meta_arrays.shape = (68049, 529)\n",
      "title_arrays.shape = (68049, 10000)\n",
      "desc_arrays.shape = (68049, 10000)\n",
      "Predict on untagged content\n"
     ]
    }
   ],
   "source": [
    "get_predictions(\"new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up arrays for new_content: ['x', 'meta', 'title', 'desc', 'content_id']\n",
      "x_arrays.shape = (18317, 1000)\n",
      "meta_arrays.shape = (18317, 529)\n",
      "title_arrays.shape = (18317, 10000)\n",
      "desc_arrays.shape = (18317, 10000)\n",
      "Predict on untagged content\n"
     ]
    }
   ],
   "source": [
    "get_predictions(\"level1\")"
   ]
  }
 ],
 "metadata": {
  "keep_output": true,
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
